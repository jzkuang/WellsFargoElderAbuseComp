{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fe324d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regular Importing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85a557a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture output\n",
    "# Keras Importing\n",
    "!pip install tensorflow\n",
    "!pip install keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdc3d649",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture output\n",
    "# Importing for seeing the missing Data\n",
    "!pip install missingno\n",
    "import missingno as msno"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1398e66",
   "metadata": {},
   "source": [
    "## Does TabNet Do Better Than Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f3a8a72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture output\n",
    "# Tabnet Importing\n",
    "!pip install pytorch_tabnet\n",
    "from pytorch_tabnet.pretraining import TabNetPretrainer\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "import pytorch_tabnet\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e82c8aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRAN_AMT</th>\n",
       "      <th>ACCT_PRE_TRAN_AVAIL_BAL</th>\n",
       "      <th>CUST_AGE</th>\n",
       "      <th>OPEN_ACCT_CT</th>\n",
       "      <th>WF_dvc_age</th>\n",
       "      <th>PWD_UPDT_TS</th>\n",
       "      <th>CARR_NAME</th>\n",
       "      <th>RGN_NAME</th>\n",
       "      <th>STATE_PRVNC_TXT</th>\n",
       "      <th>ALERT_TRGR_CD</th>\n",
       "      <th>...</th>\n",
       "      <th>CUST_STATE</th>\n",
       "      <th>PH_NUM_UPDT_TS</th>\n",
       "      <th>CUST_SINCE_DT</th>\n",
       "      <th>TRAN_TS</th>\n",
       "      <th>TRAN_DT</th>\n",
       "      <th>ACTN_CD</th>\n",
       "      <th>ACTN_INTNL_TXT</th>\n",
       "      <th>TRAN_TYPE_CD</th>\n",
       "      <th>ACTVY_DT</th>\n",
       "      <th>FRAUD_NONFRAUD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.38</td>\n",
       "      <td>23619.91</td>\n",
       "      <td>47</td>\n",
       "      <td>4</td>\n",
       "      <td>2777</td>\n",
       "      <td>1/16/2018 11:3:58</td>\n",
       "      <td>cox communications inc.</td>\n",
       "      <td>southwest</td>\n",
       "      <td>nevada</td>\n",
       "      <td>MOBL</td>\n",
       "      <td>...</td>\n",
       "      <td>NV</td>\n",
       "      <td>2/24/2021 15:55:10</td>\n",
       "      <td>1993-01-06 00:00:00</td>\n",
       "      <td>5/3/2021 18:3:58</td>\n",
       "      <td>5/3/2021</td>\n",
       "      <td>SCHPMT</td>\n",
       "      <td>P2P_COMMIT</td>\n",
       "      <td>P2P</td>\n",
       "      <td>5/3/2021</td>\n",
       "      <td>Non-Fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>45</td>\n",
       "      <td>5</td>\n",
       "      <td>2721</td>\n",
       "      <td>NaN</td>\n",
       "      <td>charter communications</td>\n",
       "      <td>southwest</td>\n",
       "      <td>california</td>\n",
       "      <td>MOBL</td>\n",
       "      <td>...</td>\n",
       "      <td>CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1971-01-07 00:00:00</td>\n",
       "      <td>1/13/2021 19:19:37</td>\n",
       "      <td>1/13/2021</td>\n",
       "      <td>SCHPMT</td>\n",
       "      <td>P2P_COMMIT</td>\n",
       "      <td>P2P</td>\n",
       "      <td>1/13/2021</td>\n",
       "      <td>Non-Fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54.84</td>\n",
       "      <td>34570.63</td>\n",
       "      <td>36</td>\n",
       "      <td>8</td>\n",
       "      <td>1531</td>\n",
       "      <td>12/22/2021 10:42:51</td>\n",
       "      <td>utah broadband llc</td>\n",
       "      <td>mountain</td>\n",
       "      <td>utah</td>\n",
       "      <td>ONLN</td>\n",
       "      <td>...</td>\n",
       "      <td>MD</td>\n",
       "      <td>5/5/2019 1:8:39</td>\n",
       "      <td>1994-02-01 00:00:00</td>\n",
       "      <td>4/8/2021 9:42:51</td>\n",
       "      <td>4/8/2021</td>\n",
       "      <td>SCHPMT</td>\n",
       "      <td>P2P_COMMIT</td>\n",
       "      <td>P2P</td>\n",
       "      <td>4/8/2021</td>\n",
       "      <td>Fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "      <td>835</td>\n",
       "      <td>2/8/2020 7:28:31</td>\n",
       "      <td>t-mobile usa  inc.</td>\n",
       "      <td>southwest</td>\n",
       "      <td>california</td>\n",
       "      <td>MOBL</td>\n",
       "      <td>...</td>\n",
       "      <td>NV</td>\n",
       "      <td>2/16/2019 6:45:37</td>\n",
       "      <td>2001-11-01 00:00:00</td>\n",
       "      <td>8/10/2021 15:28:31</td>\n",
       "      <td>8/10/2021</td>\n",
       "      <td>SCHPMT</td>\n",
       "      <td>P2P_COMMIT</td>\n",
       "      <td>P2P</td>\n",
       "      <td>8/10/2021</td>\n",
       "      <td>Non-Fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>497.08</td>\n",
       "      <td>12725.18</td>\n",
       "      <td>81</td>\n",
       "      <td>2</td>\n",
       "      <td>1095</td>\n",
       "      <td>12/28/2020 12:12:44</td>\n",
       "      <td>cogent communications</td>\n",
       "      <td>south central</td>\n",
       "      <td>texas</td>\n",
       "      <td>MOBL</td>\n",
       "      <td>...</td>\n",
       "      <td>UT</td>\n",
       "      <td>5/8/2020 10:27:6</td>\n",
       "      <td>1987-02-07 00:00:00</td>\n",
       "      <td>6/27/2021 11:12:44</td>\n",
       "      <td>6/27/2021</td>\n",
       "      <td>SCHPMT</td>\n",
       "      <td>P2P_COMMIT</td>\n",
       "      <td>P2P</td>\n",
       "      <td>6/27/2021</td>\n",
       "      <td>Fraud</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TRAN_AMT  ACCT_PRE_TRAN_AVAIL_BAL  CUST_AGE  OPEN_ACCT_CT  WF_dvc_age  \\\n",
       "0      5.38                 23619.91        47             4        2777   \n",
       "1     65.19                     0.00        45             5        2721   \n",
       "2     54.84                 34570.63        36             8        1531   \n",
       "3      0.01                     0.00        62             3         835   \n",
       "4    497.08                 12725.18        81             2        1095   \n",
       "\n",
       "           PWD_UPDT_TS                CARR_NAME       RGN_NAME  \\\n",
       "0    1/16/2018 11:3:58  cox communications inc.      southwest   \n",
       "1                  NaN   charter communications      southwest   \n",
       "2  12/22/2021 10:42:51       utah broadband llc       mountain   \n",
       "3     2/8/2020 7:28:31       t-mobile usa  inc.      southwest   \n",
       "4  12/28/2020 12:12:44    cogent communications  south central   \n",
       "\n",
       "  STATE_PRVNC_TXT ALERT_TRGR_CD  ... CUST_STATE      PH_NUM_UPDT_TS  \\\n",
       "0          nevada          MOBL  ...         NV  2/24/2021 15:55:10   \n",
       "1      california          MOBL  ...         CA                 NaN   \n",
       "2            utah          ONLN  ...         MD     5/5/2019 1:8:39   \n",
       "3      california          MOBL  ...         NV   2/16/2019 6:45:37   \n",
       "4           texas          MOBL  ...         UT    5/8/2020 10:27:6   \n",
       "\n",
       "         CUST_SINCE_DT             TRAN_TS    TRAN_DT ACTN_CD ACTN_INTNL_TXT  \\\n",
       "0  1993-01-06 00:00:00    5/3/2021 18:3:58   5/3/2021  SCHPMT     P2P_COMMIT   \n",
       "1  1971-01-07 00:00:00  1/13/2021 19:19:37  1/13/2021  SCHPMT     P2P_COMMIT   \n",
       "2  1994-02-01 00:00:00    4/8/2021 9:42:51   4/8/2021  SCHPMT     P2P_COMMIT   \n",
       "3  2001-11-01 00:00:00  8/10/2021 15:28:31  8/10/2021  SCHPMT     P2P_COMMIT   \n",
       "4  1987-02-07 00:00:00  6/27/2021 11:12:44  6/27/2021  SCHPMT     P2P_COMMIT   \n",
       "\n",
       "  TRAN_TYPE_CD   ACTVY_DT FRAUD_NONFRAUD  \n",
       "0          P2P   5/3/2021      Non-Fraud  \n",
       "1          P2P  1/13/2021      Non-Fraud  \n",
       "2          P2P   4/8/2021          Fraud  \n",
       "3          P2P  8/10/2021      Non-Fraud  \n",
       "4          P2P  6/27/2021          Fraud  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Loading\n",
    "testDf = pd.read_csv(\"WFTest.csv\")\n",
    "trainDf = pd.read_csv(\"WFTrain.csv\")\n",
    "trainDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc751abf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.380000e+00, 2.361991e+04, 4.700000e+01, ..., 1.000000e+00,\n",
       "        1.000000e+00, 1.000000e+00],\n",
       "       [6.519000e+01, 0.000000e+00, 4.500000e+01, ..., 1.000000e+00,\n",
       "        1.000000e+00, 1.000000e+00],\n",
       "       [5.484000e+01, 3.457063e+04, 3.600000e+01, ..., 1.000000e+00,\n",
       "        1.000000e+00, 1.000000e+00],\n",
       "       ...,\n",
       "       [4.930000e+02, 2.848630e+03, 5.400000e+01, ..., 1.000000e+00,\n",
       "        1.000000e+00, 1.000000e+00],\n",
       "       [4.916400e+02, 3.163250e+03, 2.100000e+01, ..., 1.000000e+00,\n",
       "        1.000000e+00, 1.000000e+00],\n",
       "       [6.020000e+00, 0.000000e+00, 6.000000e+01, ..., 1.000000e+00,\n",
       "        1.000000e+00, 1.000000e+00]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting up the Features\n",
    "numerical = ['TRAN_AMT', 'ACCT_PRE_TRAN_AVAIL_BAL','CUST_AGE',\n",
    "             'OPEN_ACCT_CT', 'WF_dvc_age', 'CUST_ZIP']\n",
    "categorical = ['CARR_NAME', 'RGN_NAME', 'STATE_PRVNC_TXT', 'ALERT_TRGR_CD',\n",
    "                  'DVC_TYPE_TXT', 'AUTHC_PRIM_TYPE_CD', 'AUTHC_SCNDRY_STAT_TXT',\n",
    "                  'CUST_STATE','ACTN_CD','ACTN_INTNL_TXT','TRAN_TYPE_CD']\n",
    "X_cat = pd.get_dummies(trainDf[categorical])\n",
    "X_num = trainDf[numerical]\n",
    "X = pd.concat([X_num, X_cat], axis = 1)\n",
    "X_mean_imputed = X.fillna(X.mean())\n",
    "X_mean_imputed_numpy = X_mean_imputed.to_numpy()\n",
    "X_mean_imputed_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd4a3dab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the Y values\n",
    "Y = trainDf[\"FRAUD_NONFRAUD\"]\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "encoded_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8baac8ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000e-02, 0.00000e+00, 2.10000e+01, ..., 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00],\n",
       "       [1.00000e-02, 1.01590e+03, 2.90000e+01, ..., 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00],\n",
       "       [1.00000e-02, 0.00000e+00, 4.20000e+01, ..., 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00],\n",
       "       ...,\n",
       "       [4.62700e+01, 0.00000e+00, 4.90000e+01, ..., 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00],\n",
       "       [8.26600e+01, 1.84563e+03, 3.70000e+01, ..., 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00],\n",
       "       [8.70000e-01, 8.64068e+03, 7.40000e+01, ..., 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Need a validation set for this, Keras can wrap tabnet and do cv but not sure needed\n",
    "x_train, x_val, y_train, y_val = train_test_split(X_mean_imputed_numpy, encoded_Y, test_size=0.30, random_state=8)\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b64634cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cpu\n",
      "epoch 0  | loss: 149399290.26347| val_0_unsup_loss: 3893763.75|  0:00:06s\n",
      "epoch 1  | loss: 1427506.32939| val_0_unsup_loss: 97364.42969|  0:00:11s\n",
      "epoch 2  | loss: 178502.06379| val_0_unsup_loss: 493305.59375|  0:00:16s\n",
      "epoch 3  | loss: 87639.77717| val_0_unsup_loss: 970.84985|  0:00:21s\n",
      "epoch 4  | loss: 83132.60763| val_0_unsup_loss: 5895.03027|  0:00:26s\n",
      "epoch 5  | loss: 68334.74405| val_0_unsup_loss: 1597.69641|  0:00:32s\n",
      "epoch 6  | loss: 49499.34829| val_0_unsup_loss: 430.88806|  0:00:37s\n",
      "epoch 7  | loss: 42426.19051| val_0_unsup_loss: 7846.76514|  0:00:42s\n",
      "epoch 8  | loss: 17970.08185| val_0_unsup_loss: 65.60343|  0:00:47s\n",
      "epoch 9  | loss: 29841.2788| val_0_unsup_loss: 2391.82202|  0:00:53s\n",
      "epoch 10 | loss: 41208.95511| val_0_unsup_loss: 8147.67432|  0:00:58s\n",
      "epoch 11 | loss: 6907.6766| val_0_unsup_loss: 278946.75|  0:01:04s\n",
      "epoch 12 | loss: 4198.52499| val_0_unsup_loss: 10026666.0|  0:01:11s\n",
      "epoch 13 | loss: 1830.67996| val_0_unsup_loss: 432816.6875|  0:01:17s\n",
      "epoch 14 | loss: 2084.45634| val_0_unsup_loss: 471964.71875|  0:01:25s\n",
      "epoch 15 | loss: 1781.01275| val_0_unsup_loss: 451075.28125|  0:01:31s\n",
      "epoch 16 | loss: 1669.7144| val_0_unsup_loss: 251456.90625|  0:01:36s\n",
      "epoch 17 | loss: 2197.36681| val_0_unsup_loss: 80430.89062|  0:01:42s\n",
      "epoch 18 | loss: 996.05252| val_0_unsup_loss: 4205.8833|  0:01:48s\n",
      "epoch 19 | loss: 11835.64921| val_0_unsup_loss: 18233.95508|  0:01:54s\n",
      "epoch 20 | loss: 2138.34193| val_0_unsup_loss: 19469.0332|  0:01:59s\n",
      "epoch 21 | loss: 1371.89329| val_0_unsup_loss: 36791.26172|  0:02:04s\n",
      "epoch 22 | loss: 1515.60198| val_0_unsup_loss: 210872.67188|  0:02:11s\n",
      "epoch 23 | loss: 783.07003| val_0_unsup_loss: 259434.60938|  0:02:16s\n",
      "epoch 24 | loss: 911.2273| val_0_unsup_loss: 132655.26562|  0:02:22s\n",
      "epoch 25 | loss: 923.33394| val_0_unsup_loss: 226799.32812|  0:02:27s\n",
      "epoch 26 | loss: 836.98121| val_0_unsup_loss: 23177.59961|  0:02:33s\n",
      "epoch 27 | loss: 633.29557| val_0_unsup_loss: 8651.27832|  0:02:39s\n",
      "epoch 28 | loss: 857.93318| val_0_unsup_loss: 2321.20044|  0:02:45s\n",
      "epoch 29 | loss: 702.4166| val_0_unsup_loss: 140638.875|  0:02:51s\n",
      "epoch 30 | loss: 440.72343| val_0_unsup_loss: 88719.50781|  0:02:57s\n",
      "epoch 31 | loss: 558.99765| val_0_unsup_loss: 26349.20117|  0:03:03s\n",
      "epoch 32 | loss: 745.48459| val_0_unsup_loss: 3695628.25|  0:03:10s\n",
      "epoch 33 | loss: 630.86023| val_0_unsup_loss: 1344838.875|  0:03:16s\n",
      "epoch 34 | loss: 2483.10853| val_0_unsup_loss: 233031.92188|  0:03:22s\n",
      "epoch 35 | loss: 497.13329| val_0_unsup_loss: 199906.46875|  0:03:28s\n",
      "epoch 36 | loss: 255.45449| val_0_unsup_loss: 158993.79688|  0:03:33s\n",
      "epoch 37 | loss: 411.39296| val_0_unsup_loss: 3004300.0|  0:03:39s\n",
      "epoch 38 | loss: 1116.6822| val_0_unsup_loss: 8112450.0|  0:03:45s\n",
      "epoch 39 | loss: 554.99112| val_0_unsup_loss: 15660.1377|  0:03:50s\n",
      "epoch 40 | loss: 415.0002| val_0_unsup_loss: 602.65814|  0:03:56s\n",
      "epoch 41 | loss: 324.74919| val_0_unsup_loss: 364441.6875|  0:04:02s\n",
      "epoch 42 | loss: 181.57222| val_0_unsup_loss: 220.92661|  0:04:08s\n",
      "epoch 43 | loss: 214.99721| val_0_unsup_loss: 334.72763|  0:04:15s\n",
      "epoch 44 | loss: 833.6251| val_0_unsup_loss: 12529.1377|  0:04:20s\n",
      "epoch 45 | loss: 462.14244| val_0_unsup_loss: 36870.42578|  0:04:26s\n",
      "epoch 46 | loss: 133.04554| val_0_unsup_loss: 1459.0614|  0:04:31s\n",
      "epoch 47 | loss: 3073.15131| val_0_unsup_loss: 196.01553|  0:04:37s\n",
      "epoch 48 | loss: 877.54265| val_0_unsup_loss: 118.80604|  0:04:42s\n",
      "epoch 49 | loss: 513.77181| val_0_unsup_loss: 328.61313|  0:04:48s\n",
      "epoch 50 | loss: 2481.61459| val_0_unsup_loss: 2514419.0|  0:04:54s\n",
      "epoch 51 | loss: 2651.57953| val_0_unsup_loss: 63726.94922|  0:04:59s\n",
      "epoch 52 | loss: 547.97991| val_0_unsup_loss: 5719.56494|  0:05:05s\n",
      "epoch 53 | loss: 163.81368| val_0_unsup_loss: 77.36096|  0:05:11s\n",
      "epoch 54 | loss: 619.28063| val_0_unsup_loss: 25040.17773|  0:05:16s\n",
      "epoch 55 | loss: 158.18357| val_0_unsup_loss: 11674.55469|  0:05:22s\n",
      "epoch 56 | loss: 333.97269| val_0_unsup_loss: 14762440.0|  0:05:29s\n",
      "epoch 57 | loss: 254.46349| val_0_unsup_loss: 8553649.0|  0:05:35s\n",
      "epoch 58 | loss: 1008.13915| val_0_unsup_loss: 6743032.0|  0:05:40s\n",
      "\n",
      "Early stopping occurred at epoch 58 with best_epoch = 8 and best_val_0_unsup_loss = 65.60343\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    }
   ],
   "source": [
    "# TabNetPretrainer\n",
    "unsupervised_model = TabNetPretrainer(\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=2e-2),\n",
    "    mask_type='entmax', # \"sparsemax\",\n",
    "    )\n",
    "\n",
    "unsupervised_model.fit(\n",
    "    x_train,\n",
    "    eval_set=[x_val],\n",
    "    max_epochs=500 , patience=50,\n",
    "    batch_size=1024, virtual_batch_size=128,\n",
    "    num_workers=0,\n",
    "    drop_last=False,\n",
    "    pretraining_ratio=0.8,\n",
    ")\n",
    "\n",
    "# reconstructed_X, embedded_X = unsupervised_model_no_preproc.predict(x_val)\n",
    "# assert(reconstructed_X.shape==embedded_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "552571d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cpu\n",
      "Loading weights from unsupervised pretraining\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:97: UserWarning: Pretraining: mask_type changed from sparsemax to entmax\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.70283 | train_auc: 0.57719 | valid_auc: 0.56602 |  0:00:08s\n",
      "epoch 1  | loss: 0.68873 | train_auc: 0.61878 | valid_auc: 0.62465 |  0:00:16s\n",
      "epoch 2  | loss: 0.6715  | train_auc: 0.68693 | valid_auc: 0.68856 |  0:00:28s\n",
      "epoch 3  | loss: 0.62049 | train_auc: 0.82575 | valid_auc: 0.82119 |  0:00:39s\n",
      "epoch 4  | loss: 0.55308 | train_auc: 0.85003 | valid_auc: 0.83134 |  0:00:48s\n",
      "epoch 5  | loss: 0.50318 | train_auc: 0.87071 | valid_auc: 0.8463  |  0:00:57s\n",
      "epoch 6  | loss: 0.46945 | train_auc: 0.89226 | valid_auc: 0.86954 |  0:01:07s\n",
      "epoch 7  | loss: 0.44369 | train_auc: 0.90446 | valid_auc: 0.87891 |  0:01:17s\n",
      "epoch 8  | loss: 0.41996 | train_auc: 0.9029  | valid_auc: 0.87476 |  0:01:26s\n",
      "epoch 9  | loss: 0.40872 | train_auc: 0.92269 | valid_auc: 0.89487 |  0:01:37s\n",
      "epoch 10 | loss: 0.34585 | train_auc: 0.92864 | valid_auc: 0.90396 |  0:01:47s\n",
      "epoch 11 | loss: 0.31113 | train_auc: 0.93556 | valid_auc: 0.90695 |  0:01:56s\n",
      "epoch 12 | loss: 0.31529 | train_auc: 0.94278 | valid_auc: 0.91553 |  0:02:05s\n",
      "epoch 13 | loss: 0.29588 | train_auc: 0.94884 | valid_auc: 0.92152 |  0:02:14s\n",
      "epoch 14 | loss: 0.29242 | train_auc: 0.95413 | valid_auc: 0.92619 |  0:02:24s\n",
      "epoch 15 | loss: 0.2817  | train_auc: 0.95873 | valid_auc: 0.93122 |  0:02:33s\n",
      "epoch 16 | loss: 0.26861 | train_auc: 0.9593  | valid_auc: 0.92908 |  0:02:43s\n",
      "epoch 17 | loss: 0.26495 | train_auc: 0.96286 | valid_auc: 0.93246 |  0:02:52s\n",
      "epoch 18 | loss: 0.26941 | train_auc: 0.96353 | valid_auc: 0.9308  |  0:03:02s\n",
      "epoch 19 | loss: 0.25364 | train_auc: 0.96636 | valid_auc: 0.9337  |  0:03:11s\n",
      "epoch 20 | loss: 0.24969 | train_auc: 0.96708 | valid_auc: 0.93435 |  0:03:20s\n",
      "epoch 21 | loss: 0.24033 | train_auc: 0.96812 | valid_auc: 0.93318 |  0:03:29s\n",
      "epoch 22 | loss: 0.2367  | train_auc: 0.96992 | valid_auc: 0.93473 |  0:03:38s\n",
      "epoch 23 | loss: 0.22877 | train_auc: 0.97074 | valid_auc: 0.93367 |  0:03:47s\n",
      "epoch 24 | loss: 0.22696 | train_auc: 0.9725  | valid_auc: 0.93268 |  0:03:56s\n",
      "epoch 25 | loss: 0.24538 | train_auc: 0.97427 | valid_auc: 0.92627 |  0:04:05s\n",
      "epoch 26 | loss: 0.21785 | train_auc: 0.97443 | valid_auc: 0.92725 |  0:04:14s\n",
      "epoch 27 | loss: 0.21549 | train_auc: 0.97419 | valid_auc: 0.93076 |  0:04:23s\n",
      "epoch 28 | loss: 0.21591 | train_auc: 0.97575 | valid_auc: 0.93005 |  0:04:33s\n",
      "epoch 29 | loss: 0.2088  | train_auc: 0.97488 | valid_auc: 0.93001 |  0:04:44s\n",
      "epoch 30 | loss: 0.21343 | train_auc: 0.97676 | valid_auc: 0.93011 |  0:04:56s\n",
      "epoch 31 | loss: 0.21141 | train_auc: 0.97743 | valid_auc: 0.92756 |  0:05:06s\n",
      "epoch 32 | loss: 0.20521 | train_auc: 0.97864 | valid_auc: 0.93063 |  0:05:16s\n",
      "epoch 33 | loss: 0.20602 | train_auc: 0.97953 | valid_auc: 0.93243 |  0:05:27s\n",
      "epoch 34 | loss: 0.19643 | train_auc: 0.97897 | valid_auc: 0.92676 |  0:05:36s\n",
      "epoch 35 | loss: 0.19305 | train_auc: 0.9804  | valid_auc: 0.9309  |  0:05:47s\n",
      "epoch 36 | loss: 0.19121 | train_auc: 0.98069 | valid_auc: 0.92934 |  0:05:58s\n",
      "epoch 37 | loss: 0.20148 | train_auc: 0.98078 | valid_auc: 0.92137 |  0:06:08s\n",
      "epoch 38 | loss: 0.1921  | train_auc: 0.98077 | valid_auc: 0.91071 |  0:06:17s\n",
      "epoch 39 | loss: 0.19171 | train_auc: 0.9815  | valid_auc: 0.92349 |  0:06:27s\n",
      "epoch 40 | loss: 0.19252 | train_auc: 0.98153 | valid_auc: 0.92227 |  0:06:37s\n",
      "epoch 41 | loss: 0.1812  | train_auc: 0.98238 | valid_auc: 0.9302  |  0:06:47s\n",
      "epoch 42 | loss: 0.18551 | train_auc: 0.98345 | valid_auc: 0.9278  |  0:06:57s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_valid_auc = 0.93473\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    }
   ],
   "source": [
    "clf = TabNetClassifier(\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=2e-2),\n",
    "    scheduler_params={\"step_size\":10, # how to use learning rate scheduler\n",
    "                      \"gamma\":0.9},\n",
    "    scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "    mask_type='sparsemax' # This will be overwritten if using pretrain model\n",
    ")\n",
    "\n",
    "clf.fit(\n",
    "    X_train= x_train, y_train=y_train,\n",
    "    eval_set=[(x_train, y_train), (x_val, y_val)],\n",
    "    eval_name=['train', 'valid'],\n",
    "    eval_metric=['auc'],\n",
    "    from_unsupervised=unsupervised_model,\n",
    "    max_epochs=500 , patience=20,\n",
    "    batch_size=1024, virtual_batch_size=128,\n",
    "    num_workers=0,\n",
    "    weights=1,\n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72a3a216",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5278569c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Value\n",
    "x_val_pred = clf.predict_proba(x_val)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8f36edb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting it into a form that'll be gradeable\n",
    "x_val_pred_label = x_val_pred > 0.25\n",
    "x_val_pred_label = x_val_pred_label.astype(int)\n",
    "x_val_pred_label_df = pd.DataFrame(x_val_pred_label)\n",
    "y_val_df = pd.DataFrame(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5dade256",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: 91.51%\n"
     ]
    }
   ],
   "source": [
    "f1s = f1_score(y_val_df, x_val_pred_label_df)\n",
    "print(\"Baseline: %.2f%%\" % (f1s*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ca23af",
   "metadata": {},
   "source": [
    "## Let's Try Feature Engineering with Tabnet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c66edf3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRAN_AMT</th>\n",
       "      <th>ACCT_PRE_TRAN_AVAIL_BAL</th>\n",
       "      <th>CUST_AGE</th>\n",
       "      <th>OPEN_ACCT_CT</th>\n",
       "      <th>WF_dvc_age</th>\n",
       "      <th>PWD_UPDT_TS</th>\n",
       "      <th>CARR_NAME</th>\n",
       "      <th>RGN_NAME</th>\n",
       "      <th>STATE_PRVNC_TXT</th>\n",
       "      <th>ALERT_TRGR_CD</th>\n",
       "      <th>DVC_TYPE_TXT</th>\n",
       "      <th>AUTHC_PRIM_TYPE_CD</th>\n",
       "      <th>AUTHC_SCNDRY_STAT_TXT</th>\n",
       "      <th>CUST_ZIP</th>\n",
       "      <th>CUST_STATE</th>\n",
       "      <th>PH_NUM_UPDT_TS</th>\n",
       "      <th>CUST_SINCE_DT</th>\n",
       "      <th>TRAN_TS</th>\n",
       "      <th>TRAN_DT</th>\n",
       "      <th>FRAUD_NONFRAUD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.38</td>\n",
       "      <td>23619.91</td>\n",
       "      <td>47</td>\n",
       "      <td>4</td>\n",
       "      <td>2777</td>\n",
       "      <td>2018-01-16 11:03:58</td>\n",
       "      <td>cox communications inc.</td>\n",
       "      <td>southwest</td>\n",
       "      <td>nevada</td>\n",
       "      <td>MOBL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UN_PWD</td>\n",
       "      <td>ALLOW</td>\n",
       "      <td>89002</td>\n",
       "      <td>NV</td>\n",
       "      <td>2021-02-24 15:55:10</td>\n",
       "      <td>1993-01-06</td>\n",
       "      <td>2021-05-03 18:03:58</td>\n",
       "      <td>2021-05-03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>45</td>\n",
       "      <td>5</td>\n",
       "      <td>2721</td>\n",
       "      <td>NaT</td>\n",
       "      <td>charter communications</td>\n",
       "      <td>southwest</td>\n",
       "      <td>california</td>\n",
       "      <td>MOBL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FACE_ID</td>\n",
       "      <td>ALLOW</td>\n",
       "      <td>94541</td>\n",
       "      <td>CA</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1971-01-07</td>\n",
       "      <td>2021-01-13 19:19:37</td>\n",
       "      <td>2021-01-13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54.84</td>\n",
       "      <td>34570.63</td>\n",
       "      <td>36</td>\n",
       "      <td>8</td>\n",
       "      <td>1531</td>\n",
       "      <td>2021-12-22 10:42:51</td>\n",
       "      <td>utah broadband llc</td>\n",
       "      <td>mountain</td>\n",
       "      <td>utah</td>\n",
       "      <td>ONLN</td>\n",
       "      <td>DESKTOP</td>\n",
       "      <td>UN_PWD</td>\n",
       "      <td>ALLOW</td>\n",
       "      <td>21811</td>\n",
       "      <td>MD</td>\n",
       "      <td>2019-05-05 01:08:39</td>\n",
       "      <td>1994-02-01</td>\n",
       "      <td>2021-04-08 09:42:51</td>\n",
       "      <td>2021-04-08</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "      <td>835</td>\n",
       "      <td>2020-02-08 07:28:31</td>\n",
       "      <td>t-mobile usa  inc.</td>\n",
       "      <td>southwest</td>\n",
       "      <td>california</td>\n",
       "      <td>MOBL</td>\n",
       "      <td>MOBILE</td>\n",
       "      <td>UN_PWD</td>\n",
       "      <td>ALLOW</td>\n",
       "      <td>89822</td>\n",
       "      <td>NV</td>\n",
       "      <td>2019-02-16 06:45:37</td>\n",
       "      <td>2001-11-01</td>\n",
       "      <td>2021-08-10 15:28:31</td>\n",
       "      <td>2021-08-10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>497.08</td>\n",
       "      <td>12725.18</td>\n",
       "      <td>81</td>\n",
       "      <td>2</td>\n",
       "      <td>1095</td>\n",
       "      <td>2020-12-28 12:12:44</td>\n",
       "      <td>cogent communications</td>\n",
       "      <td>south central</td>\n",
       "      <td>texas</td>\n",
       "      <td>MOBL</td>\n",
       "      <td>MOBILE</td>\n",
       "      <td>UN_PWD</td>\n",
       "      <td>CHALLENGE_SUCCESS</td>\n",
       "      <td>84108</td>\n",
       "      <td>UT</td>\n",
       "      <td>2020-05-08 10:27:06</td>\n",
       "      <td>1987-02-07</td>\n",
       "      <td>2021-06-27 11:12:44</td>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13995</th>\n",
       "      <td>1937.21</td>\n",
       "      <td>230.75</td>\n",
       "      <td>55</td>\n",
       "      <td>4</td>\n",
       "      <td>142</td>\n",
       "      <td>NaT</td>\n",
       "      <td>cellco partnership dba verizon wireless</td>\n",
       "      <td>southwest</td>\n",
       "      <td>california</td>\n",
       "      <td>MOBL</td>\n",
       "      <td>MOBILE</td>\n",
       "      <td>UN_PWD</td>\n",
       "      <td>ALLOW</td>\n",
       "      <td>92503</td>\n",
       "      <td>CA</td>\n",
       "      <td>2017-07-15 06:58:59</td>\n",
       "      <td>2001-06-05</td>\n",
       "      <td>2021-03-12 12:11:59</td>\n",
       "      <td>2021-03-12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13996</th>\n",
       "      <td>114.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>44</td>\n",
       "      <td>10</td>\n",
       "      <td>272</td>\n",
       "      <td>2017-11-02 04:28:20</td>\n",
       "      <td>t-mobile usa  inc.</td>\n",
       "      <td>southwest</td>\n",
       "      <td>california</td>\n",
       "      <td>MOBL</td>\n",
       "      <td>MOBILE</td>\n",
       "      <td>FACE_ID</td>\n",
       "      <td>ALLOW</td>\n",
       "      <td>80478</td>\n",
       "      <td>CO</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2010-06-03</td>\n",
       "      <td>2021-06-11 09:28:20</td>\n",
       "      <td>2021-06-11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13997</th>\n",
       "      <td>493.00</td>\n",
       "      <td>2848.63</td>\n",
       "      <td>54</td>\n",
       "      <td>3</td>\n",
       "      <td>517</td>\n",
       "      <td>2021-06-03 19:31:15</td>\n",
       "      <td>att services inc</td>\n",
       "      <td>southwest</td>\n",
       "      <td>california</td>\n",
       "      <td>MOBL</td>\n",
       "      <td>DESKTOP</td>\n",
       "      <td>UN_PWD</td>\n",
       "      <td>ALLOW</td>\n",
       "      <td>33579</td>\n",
       "      <td>FL</td>\n",
       "      <td>2021-05-25 08:50:05</td>\n",
       "      <td>1984-10-27</td>\n",
       "      <td>2021-05-16 12:31:15</td>\n",
       "      <td>2021-05-16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13998</th>\n",
       "      <td>491.64</td>\n",
       "      <td>3163.25</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-03-02 11:34:54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ONLN</td>\n",
       "      <td>DESKTOP</td>\n",
       "      <td>UN_PWD</td>\n",
       "      <td>ALLOW</td>\n",
       "      <td>91702</td>\n",
       "      <td>CA</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>2021-05-11 12:34:54</td>\n",
       "      <td>2021-05-11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13999</th>\n",
       "      <td>6.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>60</td>\n",
       "      <td>6</td>\n",
       "      <td>944</td>\n",
       "      <td>NaT</td>\n",
       "      <td>charter communications inc</td>\n",
       "      <td>south central</td>\n",
       "      <td>texas</td>\n",
       "      <td>MOBL</td>\n",
       "      <td>MOBILE</td>\n",
       "      <td>UN_PWD</td>\n",
       "      <td>ALLOW</td>\n",
       "      <td>7407</td>\n",
       "      <td>NJ</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2013-01-09</td>\n",
       "      <td>2021-02-15 16:38:00</td>\n",
       "      <td>2021-02-15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14000 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       TRAN_AMT  ACCT_PRE_TRAN_AVAIL_BAL  CUST_AGE  OPEN_ACCT_CT  WF_dvc_age  \\\n",
       "0          5.38                 23619.91        47             4        2777   \n",
       "1         65.19                     0.00        45             5        2721   \n",
       "2         54.84                 34570.63        36             8        1531   \n",
       "3          0.01                     0.00        62             3         835   \n",
       "4        497.08                 12725.18        81             2        1095   \n",
       "...         ...                      ...       ...           ...         ...   \n",
       "13995   1937.21                   230.75        55             4         142   \n",
       "13996    114.38                     0.00        44            10         272   \n",
       "13997    493.00                  2848.63        54             3         517   \n",
       "13998    491.64                  3163.25        21             3           0   \n",
       "13999      6.02                     0.00        60             6         944   \n",
       "\n",
       "              PWD_UPDT_TS                                CARR_NAME  \\\n",
       "0     2018-01-16 11:03:58                  cox communications inc.   \n",
       "1                     NaT                   charter communications   \n",
       "2     2021-12-22 10:42:51                       utah broadband llc   \n",
       "3     2020-02-08 07:28:31                       t-mobile usa  inc.   \n",
       "4     2020-12-28 12:12:44                    cogent communications   \n",
       "...                   ...                                      ...   \n",
       "13995                 NaT  cellco partnership dba verizon wireless   \n",
       "13996 2017-11-02 04:28:20                       t-mobile usa  inc.   \n",
       "13997 2021-06-03 19:31:15                         att services inc   \n",
       "13998 2020-03-02 11:34:54                                      NaN   \n",
       "13999                 NaT               charter communications inc   \n",
       "\n",
       "            RGN_NAME STATE_PRVNC_TXT ALERT_TRGR_CD DVC_TYPE_TXT  \\\n",
       "0          southwest          nevada          MOBL          NaN   \n",
       "1          southwest      california          MOBL          NaN   \n",
       "2           mountain            utah          ONLN      DESKTOP   \n",
       "3          southwest      california          MOBL       MOBILE   \n",
       "4      south central           texas          MOBL       MOBILE   \n",
       "...              ...             ...           ...          ...   \n",
       "13995      southwest      california          MOBL       MOBILE   \n",
       "13996      southwest      california          MOBL       MOBILE   \n",
       "13997      southwest      california          MOBL      DESKTOP   \n",
       "13998            NaN             NaN          ONLN      DESKTOP   \n",
       "13999  south central           texas          MOBL       MOBILE   \n",
       "\n",
       "      AUTHC_PRIM_TYPE_CD AUTHC_SCNDRY_STAT_TXT  CUST_ZIP CUST_STATE  \\\n",
       "0                 UN_PWD                 ALLOW     89002         NV   \n",
       "1                FACE_ID                 ALLOW     94541         CA   \n",
       "2                 UN_PWD                 ALLOW     21811         MD   \n",
       "3                 UN_PWD                 ALLOW     89822         NV   \n",
       "4                 UN_PWD     CHALLENGE_SUCCESS     84108         UT   \n",
       "...                  ...                   ...       ...        ...   \n",
       "13995             UN_PWD                 ALLOW     92503         CA   \n",
       "13996            FACE_ID                 ALLOW     80478         CO   \n",
       "13997             UN_PWD                 ALLOW     33579         FL   \n",
       "13998             UN_PWD                 ALLOW     91702         CA   \n",
       "13999             UN_PWD                 ALLOW      7407         NJ   \n",
       "\n",
       "           PH_NUM_UPDT_TS CUST_SINCE_DT             TRAN_TS    TRAN_DT  \\\n",
       "0     2021-02-24 15:55:10    1993-01-06 2021-05-03 18:03:58 2021-05-03   \n",
       "1                     NaT    1971-01-07 2021-01-13 19:19:37 2021-01-13   \n",
       "2     2019-05-05 01:08:39    1994-02-01 2021-04-08 09:42:51 2021-04-08   \n",
       "3     2019-02-16 06:45:37    2001-11-01 2021-08-10 15:28:31 2021-08-10   \n",
       "4     2020-05-08 10:27:06    1987-02-07 2021-06-27 11:12:44 2021-06-27   \n",
       "...                   ...           ...                 ...        ...   \n",
       "13995 2017-07-15 06:58:59    2001-06-05 2021-03-12 12:11:59 2021-03-12   \n",
       "13996                 NaT    2010-06-03 2021-06-11 09:28:20 2021-06-11   \n",
       "13997 2021-05-25 08:50:05    1984-10-27 2021-05-16 12:31:15 2021-05-16   \n",
       "13998                 NaT    2021-03-01 2021-05-11 12:34:54 2021-05-11   \n",
       "13999                 NaT    2013-01-09 2021-02-15 16:38:00 2021-02-15   \n",
       "\n",
       "       FRAUD_NONFRAUD  \n",
       "0                   0  \n",
       "1                   0  \n",
       "2                   1  \n",
       "3                   0  \n",
       "4                   1  \n",
       "...               ...  \n",
       "13995               0  \n",
       "13996               0  \n",
       "13997               1  \n",
       "13998               1  \n",
       "13999               0  \n",
       "\n",
       "[14000 rows x 20 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trying this out with Josh's Feature Engineering\n",
    "testDf = pd.read_csv(\"WFTest.csv\")\n",
    "trainDf = pd.read_csv(\"WFTrain.csv\")\n",
    "\n",
    "to_datetime = ['PWD_UPDT_TS', 'PH_NUM_UPDT_TS', 'CUST_SINCE_DT','TRAN_TS',\n",
    "               'TRAN_DT', 'ACTVY_DT']\n",
    "for datetime in to_datetime:\n",
    "  trainDf[datetime] = pd.to_datetime(trainDf[datetime], errors='coerce')\n",
    "\n",
    "to_categorical = ['CARR_NAME', 'RGN_NAME', 'STATE_PRVNC_TXT', 'ALERT_TRGR_CD',\n",
    "                  'DVC_TYPE_TXT', 'AUTHC_PRIM_TYPE_CD', 'AUTHC_SCNDRY_STAT_TXT',\n",
    "                  'CUST_STATE','ACTN_CD','ACTN_INTNL_TXT','TRAN_TYPE_CD',\n",
    "                  'FRAUD_NONFRAUD']\n",
    "\n",
    "for category in to_categorical:\n",
    "  trainDf[category] = trainDf[category].astype(\"category\")\n",
    "\n",
    "redundant = ['ACTN_CD', 'TRAN_TYPE_CD','ACTN_INTNL_TXT','ACTVY_DT']\n",
    "trainDf.drop(columns = redundant, inplace=True)\n",
    "\n",
    "trainDf.FRAUD_NONFRAUD = trainDf.FRAUD_NONFRAUD == 'Fraud'\n",
    "trainDf['FRAUD_NONFRAUD'] = trainDf['FRAUD_NONFRAUD'].astype(int)\n",
    "\n",
    "trainDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "270d320f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRAN_AMT</th>\n",
       "      <th>ACCT_PRE_TRAN_AVAIL_BAL</th>\n",
       "      <th>CUST_AGE</th>\n",
       "      <th>OPEN_ACCT_CT</th>\n",
       "      <th>WF_dvc_age</th>\n",
       "      <th>FRAUD_NONFRAUD</th>\n",
       "      <th>DAY_ACC_AGE</th>\n",
       "      <th>DAY_FRM_NUM_UPDT</th>\n",
       "      <th>DAY_FRM_PWD_UPDT</th>\n",
       "      <th>CARR_NAME_att</th>\n",
       "      <th>...</th>\n",
       "      <th>AUTHC_PRIM_TYPE_CD_AFA_PL</th>\n",
       "      <th>AUTHC_PRIM_TYPE_CD_FACE_ID</th>\n",
       "      <th>AUTHC_PRIM_TYPE_CD_TOUCH_ID</th>\n",
       "      <th>AUTHC_PRIM_TYPE_CD_UN_PWD</th>\n",
       "      <th>AUTHC_SCNDRY_STAT_TXT_ALLOW</th>\n",
       "      <th>AUTHC_SCNDRY_STAT_TXT_CHALLENGE_ISSUED</th>\n",
       "      <th>AUTHC_SCNDRY_STAT_TXT_CHALLENGE_SUCCESS</th>\n",
       "      <th>TXT_CASE_INT</th>\n",
       "      <th>TXT_CASE_MATCH</th>\n",
       "      <th>TXT_CASE_MISMATCH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.38</td>\n",
       "      <td>23619.91</td>\n",
       "      <td>47</td>\n",
       "      <td>4</td>\n",
       "      <td>2777</td>\n",
       "      <td>0</td>\n",
       "      <td>10344</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>45</td>\n",
       "      <td>5</td>\n",
       "      <td>2721</td>\n",
       "      <td>0</td>\n",
       "      <td>18269</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54.84</td>\n",
       "      <td>34570.63</td>\n",
       "      <td>36</td>\n",
       "      <td>8</td>\n",
       "      <td>1531</td>\n",
       "      <td>1</td>\n",
       "      <td>9928</td>\n",
       "      <td>704.0</td>\n",
       "      <td>-259.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "      <td>835</td>\n",
       "      <td>0</td>\n",
       "      <td>7222</td>\n",
       "      <td>906.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>497.08</td>\n",
       "      <td>12725.18</td>\n",
       "      <td>81</td>\n",
       "      <td>2</td>\n",
       "      <td>1095</td>\n",
       "      <td>1</td>\n",
       "      <td>12559</td>\n",
       "      <td>415.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13995</th>\n",
       "      <td>1937.21</td>\n",
       "      <td>230.75</td>\n",
       "      <td>55</td>\n",
       "      <td>4</td>\n",
       "      <td>142</td>\n",
       "      <td>0</td>\n",
       "      <td>7220</td>\n",
       "      <td>1336.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13996</th>\n",
       "      <td>114.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>44</td>\n",
       "      <td>10</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>4026</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1317.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13997</th>\n",
       "      <td>493.00</td>\n",
       "      <td>2848.63</td>\n",
       "      <td>54</td>\n",
       "      <td>3</td>\n",
       "      <td>517</td>\n",
       "      <td>1</td>\n",
       "      <td>13350</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13998</th>\n",
       "      <td>491.64</td>\n",
       "      <td>3163.25</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>435.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13999</th>\n",
       "      <td>6.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>60</td>\n",
       "      <td>6</td>\n",
       "      <td>944</td>\n",
       "      <td>0</td>\n",
       "      <td>2959</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14000 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       TRAN_AMT  ACCT_PRE_TRAN_AVAIL_BAL  CUST_AGE  OPEN_ACCT_CT  WF_dvc_age  \\\n",
       "0          5.38                 23619.91        47             4        2777   \n",
       "1         65.19                     0.00        45             5        2721   \n",
       "2         54.84                 34570.63        36             8        1531   \n",
       "3          0.01                     0.00        62             3         835   \n",
       "4        497.08                 12725.18        81             2        1095   \n",
       "...         ...                      ...       ...           ...         ...   \n",
       "13995   1937.21                   230.75        55             4         142   \n",
       "13996    114.38                     0.00        44            10         272   \n",
       "13997    493.00                  2848.63        54             3         517   \n",
       "13998    491.64                  3163.25        21             3           0   \n",
       "13999      6.02                     0.00        60             6         944   \n",
       "\n",
       "       FRAUD_NONFRAUD  DAY_ACC_AGE  DAY_FRM_NUM_UPDT  DAY_FRM_PWD_UPDT  \\\n",
       "0                   0        10344              68.0            1203.0   \n",
       "1                   0        18269               NaN               NaN   \n",
       "2                   1         9928             704.0            -259.0   \n",
       "3                   0         7222             906.0             549.0   \n",
       "4                   1        12559             415.0             180.0   \n",
       "...               ...          ...               ...               ...   \n",
       "13995               0         7220            1336.0               NaN   \n",
       "13996               0         4026               NaN            1317.0   \n",
       "13997               1        13350              -9.0             -19.0   \n",
       "13998               1           71               NaN             435.0   \n",
       "13999               0         2959               NaN               NaN   \n",
       "\n",
       "       CARR_NAME_att  ...  AUTHC_PRIM_TYPE_CD_AFA_PL  \\\n",
       "0                  0  ...                          0   \n",
       "1                  0  ...                          0   \n",
       "2                  0  ...                          0   \n",
       "3                  0  ...                          0   \n",
       "4                  0  ...                          0   \n",
       "...              ...  ...                        ...   \n",
       "13995              0  ...                          0   \n",
       "13996              0  ...                          0   \n",
       "13997              1  ...                          0   \n",
       "13998              0  ...                          0   \n",
       "13999              0  ...                          0   \n",
       "\n",
       "       AUTHC_PRIM_TYPE_CD_FACE_ID  AUTHC_PRIM_TYPE_CD_TOUCH_ID  \\\n",
       "0                               0                            0   \n",
       "1                               1                            0   \n",
       "2                               0                            0   \n",
       "3                               0                            0   \n",
       "4                               0                            0   \n",
       "...                           ...                          ...   \n",
       "13995                           0                            0   \n",
       "13996                           1                            0   \n",
       "13997                           0                            0   \n",
       "13998                           0                            0   \n",
       "13999                           0                            0   \n",
       "\n",
       "       AUTHC_PRIM_TYPE_CD_UN_PWD  AUTHC_SCNDRY_STAT_TXT_ALLOW  \\\n",
       "0                              1                            1   \n",
       "1                              0                            1   \n",
       "2                              1                            1   \n",
       "3                              1                            1   \n",
       "4                              1                            0   \n",
       "...                          ...                          ...   \n",
       "13995                          1                            1   \n",
       "13996                          0                            1   \n",
       "13997                          1                            1   \n",
       "13998                          1                            1   \n",
       "13999                          1                            1   \n",
       "\n",
       "       AUTHC_SCNDRY_STAT_TXT_CHALLENGE_ISSUED  \\\n",
       "0                                           0   \n",
       "1                                           0   \n",
       "2                                           0   \n",
       "3                                           0   \n",
       "4                                           0   \n",
       "...                                       ...   \n",
       "13995                                       0   \n",
       "13996                                       0   \n",
       "13997                                       0   \n",
       "13998                                       0   \n",
       "13999                                       0   \n",
       "\n",
       "       AUTHC_SCNDRY_STAT_TXT_CHALLENGE_SUCCESS  TXT_CASE_INT  TXT_CASE_MATCH  \\\n",
       "0                                            0             0               1   \n",
       "1                                            0             0               1   \n",
       "2                                            0             0               0   \n",
       "3                                            0             0               0   \n",
       "4                                            1             0               0   \n",
       "...                                        ...           ...             ...   \n",
       "13995                                        0             0               1   \n",
       "13996                                        0             0               0   \n",
       "13997                                        0             0               0   \n",
       "13998                                        0             0               0   \n",
       "13999                                        0             0               0   \n",
       "\n",
       "       TXT_CASE_MISMATCH  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      1  \n",
       "3                      1  \n",
       "4                      1  \n",
       "...                  ...  \n",
       "13995                  0  \n",
       "13996                  1  \n",
       "13997                  1  \n",
       "13998                  1  \n",
       "13999                  1  \n",
       "\n",
       "[14000 rows x 45 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Similar data cleaning process as above\n",
    "DfProc = trainDf\n",
    "\n",
    "carrMap = {\n",
    "    'cox communications inc.' : 'cox',\n",
    "    't-mobile usa  inc.' : 'tmobile',\n",
    "    'charter communications inc' : 'charter',\n",
    "    'comcast' : 'comcast',\n",
    "    'comcast cable communications  llc' : 'comcast',\n",
    "    'centurylink communications  llc' : 'century',\n",
    "    'frontier communications of america  inc.' : 'frontier',\n",
    "    'att services inc' : 'att',\n",
    "    'charter communications' : 'charter',\n",
    "    'at&t mobility llc ' : 'att',\n",
    "    'cellco partnership dba verizon wireless' : 'verizon',\n",
    "}\n",
    "\n",
    "regionSet = { 'southwest', 'south central', 'southeast', 'mountain',\n",
    "             'northeast', 'great lakes', 'mid atlantic', 'pacific northwest',\n",
    "             'midwest'}\n",
    "regionMap = {x:x for x in regionSet}\n",
    "    \n",
    "\n",
    "DfProc['CARR_NAME'] = DfProc['CARR_NAME'].map(carrMap).fillna(\"other\")\n",
    "DfProc['RGN_NAME'] = DfProc['RGN_NAME'].map(regionMap).fillna(\"other\")\n",
    "\n",
    "#ADDITIONAL FEATURE ENGINEERING - - - - - - - - - - - - \n",
    "\n",
    "#Normalize date features against transaction date\n",
    "# How old was the account when it made the transaction\n",
    "DfProc['DAY_ACC_AGE'] = (\n",
    "    DfProc['TRAN_TS'] - DfProc['CUST_SINCE_DT']).dt.days\n",
    "# How long was it been since the phone number was updated since the transaction\n",
    "DfProc['DAY_FRM_NUM_UPDT'] = (\n",
    "    DfProc['TRAN_TS'] - DfProc['PH_NUM_UPDT_TS']).dt.days\n",
    "# How long was it been since the password was updated since the transaction\n",
    "DfProc['DAY_FRM_PWD_UPDT'] = (\n",
    "    DfProc['TRAN_TS'] - DfProc['PWD_UPDT_TS']).dt.days\n",
    "\n",
    "# Cleaning \"region\" column to match entries in state column.\n",
    "# States were mapped to their abbreviations, if state outside US its mapped to\n",
    "# \"INT\" for international\n",
    "stateDict = {'nevada' : 'NV', 'california': 'CA', 'utah': 'UT', 'texas': 'TX','arizona': 'AZ', 'wisconsin': 'WI', 'minnesota': 'MN', 'phnum penh' : 'INT','alabama': 'AL', 'florida': 'FL', 'nebraska': 'NE', 'south dakota': 'SD',\n",
    " 'punjab': 'INT', 'north carolina': 'NC', 'new york': 'NY', 'michigan': 'MI','colorado': 'CO', 'massachusetts': 'MA', 'antioquia': 'INT', 'washington': 'WA','arkansas': 'AR', 'new jersey': 'NJ', 'kentucky': 'KY', 'ostergotlands lan': 'INT',\n",
    " 'tennessee': 'TN', 'district of columbia': 'DC', 'georgia': 'GA', 'maryland': 'MD','oregon': 'OR', 'wyoming': 'WY', 'oklahoma': 'OK', 'illinois': 'IL','north dakota': 'ND', 'indiana': 'IN', 'pennsylvania': 'PA', 'distrito nacional': 'INT',\n",
    " 'distrito capital': 'INT', 'iowa': 'IA', 'zuerich': 'INT', 'hamerkaz': 'INT','sonora': 'INT', 'madrid': 'INT', 'new mexico': 'NM', 'new south wales' : 'INT','loire-atlantique' : 'INT', 'carabobo' : 'INT', 'montana' : 'MT', 'idaho' : 'ID',\n",
    " 'hong kong' : 'INT', 'ohio' : 'OH', 'south carolina': 'SC', 'missouri': 'MS', 'colima': 'INT', 'baja california': 'INT', 'noord-brabant': 'INT', 'nairobi area': 'INT', 'baden-wuerttemberg': 'INT', 'virginia' : 'VA','alaska': 'AK', 'hawaii': 'HI', 'kansas': 'KS', 'greater accra': 'INT', 'kingston': 'INT', 'connecticut' : 'CT', 'louisiana': 'LA', 'bolivar': 'INT',\n",
    " 'lagos': 'INT', 'gujarat': 'INT', 'zulia': 'INT', 'morelos': 'INT', 'jalisco': 'INT', 'san salvador': 'INT', 'west bengal': 'INT', 'guerrero': 'INT', 'distrito federal': 'INT',\n",
    " 'mississippi': 'MS', \"saint george's\": 'INT', 'hampshire': 'NH', 'paris': 'INT','mazowieckie': 'INT', 'region metropolitana': 'INT', 'ha noi': 'INT', 'lara': 'INT','maine': 'ME', 'seoul teukbyeolsi': 'INT', 'telangana': 'INT', 'victoria': 'INT',\n",
    " 'kinshasa': 'INT', 'aguascalientes': 'INT', 'western australia': 'INT','andhra pradesh': 'INT', 'sao paulo': 'INT', 'nueva esparta': 'INT','dubayy': 'INT', 'chihuahua': 'INT', 'rhode island': 'ri', 'istanbul': 'INT','guatemala': 'INT', 'gauteng': 'INT', 'michoacan de ocampo': 'INT', \"ra's al khaymah\": 'INT',\n",
    " 'sodermanlands lan': 'INT', 'da nang': 'INT', 'taipei': 'INT','sindh': 'INT','tamaulipas': 'INT','sinaloa': 'INT','liverpool': 'INT','western cape': 'INT', 'aragua': 'INT', 'british columbia': 'INT', 'guanacaste': 'INT','`amman': 'INT',\n",
    " 'hessen': 'INT','ontario': 'INT','delaware': 'DE', 'dublin': 'INT', 'south west': 'INT', 'west virginia': 'WV', 'south australia': 'INT', 'delhi': 'INT', 'pichincha': 'INT', 'new providence': 'INT', 'tokyo': 'INT', 'nordrhein-westfalen' : 'INT'}\n",
    "\n",
    "# Use statedict to create column to describe where transaction originated from\n",
    "DfProc['TXT_STATE'] = DfProc['STATE_PRVNC_TXT'].map(stateDict).fillna(\"None\")\n",
    "\n",
    "#Function to apply to column of transaction location and customer location \n",
    "#To compare if the two match\n",
    "def locationCompare(txtLoc, custLoc):\n",
    "  if txtLoc != custLoc:\n",
    "    if txtLoc == 'INT':\n",
    "      return 'INT'\n",
    "    else:\n",
    "      return 'MISMATCH'\n",
    "  return 'MATCH'\n",
    "\n",
    "#Apply functino above to TXT state and CUST state column\n",
    "DfProc['TXT_CASE'] = DfProc.apply(\n",
    "    lambda x: locationCompare(x['TXT_STATE'], x['CUST_STATE']), axis=1)\n",
    "\n",
    "\n",
    "## This didn't really help Josh so let's skip it\n",
    "# #Read in external dataframe with data for each zip code\n",
    "# zipInfoDf = pd.read_csv('zip_code_rural.csv')\n",
    "# #Get population number (zpop) and population density (lzden )for each zip code\n",
    "# zipInfoDf = zipInfoDf[['zip', 'zpop', 'lzden']]\n",
    "# #Add this information to df\n",
    "# DfProc = DfProc.merge(zipInfoDf, how='left', left_on='CUST_ZIP', right_on='zip')\n",
    "\n",
    "\n",
    "#Similar process to above, we end up keeping the generated features\n",
    "#And removing a lot of the really detailed categorical variables\n",
    "categorical = ['CARR_NAME', 'RGN_NAME', 'STATE_PRVNC_TXT', 'ALERT_TRGR_CD',\n",
    "                'DVC_TYPE_TXT', 'AUTHC_PRIM_TYPE_CD', 'AUTHC_SCNDRY_STAT_TXT',\n",
    "                'CUST_STATE', 'TXT_CASE']\n",
    "\n",
    "remove = ['PWD_UPDT_TS', 'PH_NUM_UPDT_TS', 'CUST_SINCE_DT','TRAN_TS','TRAN_DT',\n",
    "          'CUST_STATE', 'STATE_PRVNC_TXT', 'TXT_STATE', 'CUST_ZIP', 'zip']\n",
    "\n",
    "\n",
    "categoricalDummies = [x for x in categorical if x not in remove]\n",
    "\n",
    "for var in categoricalDummies:\n",
    "    cat_list = pd.get_dummies(DfProc[var], prefix=var)\n",
    "    DfProc=DfProc.join(cat_list)\n",
    "data_vars=DfProc.columns.values.tolist()\n",
    "to_keep=[i for i in data_vars if i not in categorical and i not in remove]\n",
    "DfProc=DfProc[to_keep]\n",
    "\n",
    "DfProc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c542aa45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.84936742,  0.44672723, -0.36842923, ..., -0.13290498,\n",
       "         2.23798653, -2.10739634],\n",
       "       [-0.66121524, -0.34148634, -0.47464743, ..., -0.13290498,\n",
       "         2.23798653, -2.10739634],\n",
       "       [-0.69377459,  0.81216071, -0.95262935, ..., -0.13290498,\n",
       "        -0.44683021,  0.47451919],\n",
       "       ...,\n",
       "       [ 0.68460294, -0.24642549,  0.00333449, ..., -0.13290498,\n",
       "        -0.44683021,  0.47451919],\n",
       "       [ 0.68032461, -0.23592639, -1.74926589, ..., -0.13290498,\n",
       "        -0.44683021,  0.47451919],\n",
       "       [-0.84735409, -0.34148634,  0.32198911, ..., -0.13290498,\n",
       "        -0.44683021,  0.47451919]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = DfProc.loc[:, DfProc.columns != 'FRAUD_NONFRAUD'].astype(float)\n",
    "scaler = StandardScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X))\n",
    "X_mean_imputed = X.fillna(X.mean())\n",
    "X_mean_imputed_numpy = X_mean_imputed.to_numpy()\n",
    "\n",
    "\n",
    "Y = DfProc['FRAUD_NONFRAUD']\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "\n",
    "X_mean_imputed_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52071339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.86626054, -0.34148634, -1.74926589, ..., -0.13290498,\n",
       "         2.23798653, -2.10739634],\n",
       "       [-0.86626054, -0.30758502, -1.32439307, ..., -0.13290498,\n",
       "         2.23798653, -2.10739634],\n",
       "       [-0.86626054, -0.34148634, -0.63397474, ..., -0.13290498,\n",
       "        -0.44683021,  0.47451919],\n",
       "       ...,\n",
       "       [-0.72073437, -0.34148634, -0.26221102, ..., -0.13290498,\n",
       "        -0.44683021,  0.47451919],\n",
       "       [-0.60625756, -0.27989632, -0.89952025, ..., -0.13290498,\n",
       "        -0.44683021,  0.47451919],\n",
       "       [-0.86355512, -0.05314057,  1.06551654, ..., -0.13290498,\n",
       "         2.23798653, -2.10739634]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Need a validation set for this, Keras can wrap tabnet and do cv but not sure needed\n",
    "x_train, x_val, y_train, y_val = train_test_split(X_mean_imputed_numpy, encoded_Y, test_size=0.30, random_state=8)\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9fb9eb62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cpu\n",
      "epoch 0  | loss: 1.63437 | val_0_unsup_loss: 1.06263 |  0:00:01s\n",
      "epoch 1  | loss: 1.06488 | val_0_unsup_loss: 1.01474 |  0:00:02s\n",
      "epoch 2  | loss: 1.01182 | val_0_unsup_loss: 1.00483 |  0:00:03s\n",
      "epoch 3  | loss: 1.00029 | val_0_unsup_loss: 1.00674 |  0:00:04s\n",
      "epoch 4  | loss: 0.99748 | val_0_unsup_loss: 1.00457 |  0:00:05s\n",
      "epoch 5  | loss: 1.00274 | val_0_unsup_loss: 1.00482 |  0:00:06s\n",
      "epoch 6  | loss: 0.99903 | val_0_unsup_loss: 1.00418 |  0:00:07s\n",
      "epoch 7  | loss: 0.99726 | val_0_unsup_loss: 1.00018 |  0:00:08s\n",
      "epoch 8  | loss: 1.00386 | val_0_unsup_loss: 0.99921 |  0:00:09s\n",
      "epoch 9  | loss: 0.99461 | val_0_unsup_loss: 0.99196 |  0:00:10s\n",
      "epoch 10 | loss: 1.00099 | val_0_unsup_loss: 0.98488 |  0:00:11s\n",
      "epoch 11 | loss: 0.98934 | val_0_unsup_loss: 0.97643 |  0:00:12s\n",
      "epoch 12 | loss: 0.99411 | val_0_unsup_loss: 0.9732  |  0:00:13s\n",
      "epoch 13 | loss: 0.99425 | val_0_unsup_loss: 0.96968 |  0:00:14s\n",
      "epoch 14 | loss: 0.98987 | val_0_unsup_loss: 0.96625 |  0:00:15s\n",
      "epoch 15 | loss: 0.98797 | val_0_unsup_loss: 0.95824 |  0:00:16s\n",
      "epoch 16 | loss: 0.99187 | val_0_unsup_loss: 0.96054 |  0:00:17s\n",
      "epoch 17 | loss: 16062.69198| val_0_unsup_loss: 0.96228 |  0:00:18s\n",
      "epoch 18 | loss: 0.98634 | val_0_unsup_loss: 0.96545 |  0:00:18s\n",
      "epoch 19 | loss: 0.99685 | val_0_unsup_loss: 0.95992 |  0:00:19s\n",
      "epoch 20 | loss: 0.98301 | val_0_unsup_loss: 0.95404 |  0:00:20s\n",
      "epoch 21 | loss: 0.98559 | val_0_unsup_loss: 0.94485 |  0:00:21s\n",
      "epoch 22 | loss: 0.97671 | val_0_unsup_loss: 0.93899 |  0:00:22s\n",
      "epoch 23 | loss: 0.98245 | val_0_unsup_loss: 0.93416 |  0:00:23s\n",
      "epoch 24 | loss: 0.97735 | val_0_unsup_loss: 0.92828 |  0:00:24s\n",
      "epoch 25 | loss: 0.98012 | val_0_unsup_loss: 0.92532 |  0:00:25s\n",
      "epoch 26 | loss: 0.96639 | val_0_unsup_loss: 0.92292 |  0:00:26s\n",
      "epoch 27 | loss: 0.96209 | val_0_unsup_loss: 0.92123 |  0:00:27s\n",
      "epoch 28 | loss: 0.97414 | val_0_unsup_loss: 0.92092 |  0:00:28s\n",
      "epoch 29 | loss: 0.96922 | val_0_unsup_loss: 0.91925 |  0:00:29s\n",
      "epoch 30 | loss: 0.96703 | val_0_unsup_loss: 0.91911 |  0:00:30s\n",
      "epoch 31 | loss: 0.96344 | val_0_unsup_loss: 0.91534 |  0:00:31s\n",
      "epoch 32 | loss: 0.96486 | val_0_unsup_loss: 0.91613 |  0:00:32s\n",
      "epoch 33 | loss: 0.96886 | val_0_unsup_loss: 0.91758 |  0:00:33s\n",
      "epoch 34 | loss: 4697.85827| val_0_unsup_loss: 0.92206 |  0:00:34s\n",
      "epoch 35 | loss: 0.9744  | val_0_unsup_loss: 0.92373 |  0:00:35s\n",
      "epoch 36 | loss: 0.97691 | val_0_unsup_loss: 0.91859 |  0:00:36s\n",
      "epoch 37 | loss: 0.97036 | val_0_unsup_loss: 0.91522 |  0:00:37s\n",
      "epoch 38 | loss: 0.97438 | val_0_unsup_loss: 0.91567 |  0:00:38s\n",
      "epoch 39 | loss: 0.96906 | val_0_unsup_loss: 0.9154  |  0:00:40s\n",
      "epoch 40 | loss: 0.96692 | val_0_unsup_loss: 0.91299 |  0:00:41s\n",
      "epoch 41 | loss: 0.96665 | val_0_unsup_loss: 0.91123 |  0:00:42s\n",
      "epoch 42 | loss: 0.958   | val_0_unsup_loss: 0.91106 |  0:00:43s\n",
      "epoch 43 | loss: 0.96921 | val_0_unsup_loss: 0.91171 |  0:00:44s\n",
      "epoch 44 | loss: 0.97293 | val_0_unsup_loss: 0.90846 |  0:00:45s\n",
      "epoch 45 | loss: 0.95953 | val_0_unsup_loss: 0.90733 |  0:00:46s\n",
      "epoch 46 | loss: 0.95692 | val_0_unsup_loss: 0.9058  |  0:00:47s\n",
      "epoch 47 | loss: 0.96727 | val_0_unsup_loss: 0.90413 |  0:00:48s\n",
      "epoch 48 | loss: 0.95973 | val_0_unsup_loss: 0.90469 |  0:00:49s\n",
      "epoch 49 | loss: 0.95787 | val_0_unsup_loss: 0.90411 |  0:00:50s\n",
      "epoch 50 | loss: 3081.62146| val_0_unsup_loss: 0.90658 |  0:00:51s\n",
      "epoch 51 | loss: 0.96702 | val_0_unsup_loss: 0.91823 |  0:00:52s\n",
      "epoch 52 | loss: 0.97218 | val_0_unsup_loss: 0.91267 |  0:00:53s\n",
      "epoch 53 | loss: 13119.98562| val_0_unsup_loss: 0.91715 |  0:00:54s\n",
      "epoch 54 | loss: 0.97003 | val_0_unsup_loss: 0.92466 |  0:00:55s\n",
      "epoch 55 | loss: 0.96529 | val_0_unsup_loss: 0.90915 |  0:00:56s\n",
      "epoch 56 | loss: 0.96923 | val_0_unsup_loss: 0.90348 |  0:00:57s\n",
      "epoch 57 | loss: 9763.62097| val_0_unsup_loss: 0.8955  |  0:00:58s\n",
      "epoch 58 | loss: 4370.55416| val_0_unsup_loss: 0.89788 |  0:00:59s\n",
      "epoch 59 | loss: 0.96296 | val_0_unsup_loss: 0.91054 |  0:01:00s\n",
      "epoch 60 | loss: 0.97187 | val_0_unsup_loss: 0.89921 |  0:01:01s\n",
      "epoch 61 | loss: 0.96624 | val_0_unsup_loss: 0.89483 |  0:01:02s\n",
      "epoch 62 | loss: 0.96014 | val_0_unsup_loss: 0.89218 |  0:01:03s\n",
      "epoch 63 | loss: 0.95581 | val_0_unsup_loss: 0.89257 |  0:01:04s\n",
      "epoch 64 | loss: 0.96189 | val_0_unsup_loss: 0.89009 |  0:01:05s\n",
      "epoch 65 | loss: 0.96246 | val_0_unsup_loss: 0.88874 |  0:01:06s\n",
      "epoch 66 | loss: 0.96189 | val_0_unsup_loss: 0.88684 |  0:01:07s\n",
      "epoch 67 | loss: 0.9631  | val_0_unsup_loss: 0.88356 |  0:01:08s\n",
      "epoch 68 | loss: 0.95637 | val_0_unsup_loss: 0.88353 |  0:01:09s\n",
      "epoch 69 | loss: 0.95646 | val_0_unsup_loss: 0.88069 |  0:01:10s\n",
      "epoch 70 | loss: 0.961   | val_0_unsup_loss: 0.8806  |  0:01:11s\n",
      "epoch 71 | loss: 0.95468 | val_0_unsup_loss: 0.88036 |  0:01:12s\n",
      "epoch 72 | loss: 13957.50831| val_0_unsup_loss: 0.88252 |  0:01:13s\n",
      "epoch 73 | loss: 0.96071 | val_0_unsup_loss: 0.90233 |  0:01:14s\n",
      "epoch 74 | loss: 0.96751 | val_0_unsup_loss: 0.88718 |  0:01:15s\n",
      "epoch 75 | loss: 0.95905 | val_0_unsup_loss: 0.88052 |  0:01:16s\n",
      "epoch 76 | loss: 0.95941 | val_0_unsup_loss: 0.87769 |  0:01:17s\n",
      "epoch 77 | loss: 0.96301 | val_0_unsup_loss: 0.87678 |  0:01:18s\n",
      "epoch 78 | loss: 13104.04919| val_0_unsup_loss: 0.87977 |  0:01:19s\n",
      "epoch 79 | loss: 0.96625 | val_0_unsup_loss: 0.89685 |  0:01:20s\n",
      "epoch 80 | loss: 0.94803 | val_0_unsup_loss: 0.88648 |  0:01:21s\n",
      "epoch 81 | loss: 0.956   | val_0_unsup_loss: 0.87821 |  0:01:22s\n",
      "epoch 82 | loss: 0.94568 | val_0_unsup_loss: 0.87579 |  0:01:23s\n",
      "epoch 83 | loss: 0.95395 | val_0_unsup_loss: 0.87723 |  0:01:24s\n",
      "epoch 84 | loss: 0.95205 | val_0_unsup_loss: 0.87688 |  0:01:25s\n",
      "epoch 85 | loss: 0.96159 | val_0_unsup_loss: 0.87914 |  0:01:26s\n",
      "epoch 86 | loss: 0.95797 | val_0_unsup_loss: 0.87859 |  0:01:27s\n",
      "epoch 87 | loss: 0.95566 | val_0_unsup_loss: 0.89236 |  0:01:27s\n",
      "epoch 88 | loss: 0.95478 | val_0_unsup_loss: 0.89908 |  0:01:28s\n",
      "epoch 89 | loss: 0.95882 | val_0_unsup_loss: 0.89618 |  0:01:29s\n",
      "epoch 90 | loss: 0.94206 | val_0_unsup_loss: 0.8912  |  0:01:30s\n",
      "epoch 91 | loss: 0.95679 | val_0_unsup_loss: 0.88448 |  0:01:31s\n",
      "epoch 92 | loss: 0.95488 | val_0_unsup_loss: 0.88066 |  0:01:32s\n",
      "epoch 93 | loss: 0.94943 | val_0_unsup_loss: 0.88179 |  0:01:33s\n",
      "epoch 94 | loss: 0.9536  | val_0_unsup_loss: 0.87751 |  0:01:34s\n",
      "epoch 95 | loss: 0.94793 | val_0_unsup_loss: 0.87421 |  0:01:35s\n",
      "epoch 96 | loss: 0.96016 | val_0_unsup_loss: 0.87187 |  0:01:36s\n",
      "epoch 97 | loss: 0.95401 | val_0_unsup_loss: 0.87458 |  0:01:37s\n",
      "epoch 98 | loss: 2092.84887| val_0_unsup_loss: 0.8837  |  0:01:38s\n",
      "epoch 99 | loss: 0.95938 | val_0_unsup_loss: 0.9208  |  0:01:39s\n",
      "epoch 100| loss: 0.96304 | val_0_unsup_loss: 0.8909  |  0:01:40s\n",
      "epoch 101| loss: 0.95495 | val_0_unsup_loss: 0.87857 |  0:01:41s\n",
      "epoch 102| loss: 0.95421 | val_0_unsup_loss: 0.87577 |  0:01:42s\n",
      "epoch 103| loss: 0.95812 | val_0_unsup_loss: 0.88329 |  0:01:43s\n",
      "epoch 104| loss: 0.96125 | val_0_unsup_loss: 0.87901 |  0:01:44s\n",
      "epoch 105| loss: 1475.75376| val_0_unsup_loss: 0.87491 |  0:01:45s\n",
      "epoch 106| loss: 20572.30775| val_0_unsup_loss: 0.87775 |  0:01:46s\n",
      "epoch 107| loss: 0.95272 | val_0_unsup_loss: 0.88315 |  0:01:47s\n",
      "epoch 108| loss: 0.95532 | val_0_unsup_loss: 0.87875 |  0:01:48s\n",
      "epoch 109| loss: 0.95198 | val_0_unsup_loss: 0.87458 |  0:01:49s\n",
      "epoch 110| loss: 0.94909 | val_0_unsup_loss: 0.87328 |  0:01:50s\n",
      "epoch 111| loss: 0.94972 | val_0_unsup_loss: 0.8741  |  0:01:51s\n",
      "epoch 112| loss: 0.94891 | val_0_unsup_loss: 0.87223 |  0:01:52s\n",
      "epoch 113| loss: 11323.98746| val_0_unsup_loss: 0.87205 |  0:01:53s\n",
      "epoch 114| loss: 0.95527 | val_0_unsup_loss: 0.87351 |  0:01:54s\n",
      "epoch 115| loss: 0.95064 | val_0_unsup_loss: 0.87347 |  0:01:55s\n",
      "epoch 116| loss: 0.95146 | val_0_unsup_loss: 0.87403 |  0:01:56s\n",
      "epoch 117| loss: 0.94949 | val_0_unsup_loss: 0.87286 |  0:01:57s\n",
      "epoch 118| loss: 0.95213 | val_0_unsup_loss: 0.87385 |  0:01:58s\n",
      "epoch 119| loss: 2770.74137| val_0_unsup_loss: 0.87674 |  0:01:59s\n",
      "epoch 120| loss: 0.95746 | val_0_unsup_loss: 0.87551 |  0:02:00s\n",
      "epoch 121| loss: 0.95856 | val_0_unsup_loss: 0.87892 |  0:02:01s\n",
      "epoch 122| loss: 0.95228 | val_0_unsup_loss: 0.87707 |  0:02:02s\n",
      "epoch 123| loss: 0.95563 | val_0_unsup_loss: 0.87537 |  0:02:03s\n",
      "epoch 124| loss: 0.95332 | val_0_unsup_loss: 0.87474 |  0:02:04s\n",
      "epoch 125| loss: 0.96143 | val_0_unsup_loss: 0.87673 |  0:02:05s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 126| loss: 0.95096 | val_0_unsup_loss: 0.87397 |  0:02:06s\n",
      "epoch 127| loss: 0.94914 | val_0_unsup_loss: 0.87337 |  0:02:07s\n",
      "epoch 128| loss: 0.95206 | val_0_unsup_loss: 0.87053 |  0:02:08s\n",
      "epoch 129| loss: 0.95128 | val_0_unsup_loss: 0.87246 |  0:02:09s\n",
      "epoch 130| loss: 0.95886 | val_0_unsup_loss: 0.87574 |  0:02:10s\n",
      "epoch 131| loss: 0.9508  | val_0_unsup_loss: 0.87795 |  0:02:11s\n",
      "epoch 132| loss: 0.95847 | val_0_unsup_loss: 0.87887 |  0:02:12s\n",
      "epoch 133| loss: 0.95023 | val_0_unsup_loss: 0.87973 |  0:02:13s\n",
      "epoch 134| loss: 888.01164| val_0_unsup_loss: 0.89124 |  0:02:14s\n",
      "epoch 135| loss: 8071.57349| val_0_unsup_loss: 0.89848 |  0:02:15s\n",
      "epoch 136| loss: 0.96304 | val_0_unsup_loss: 0.88942 |  0:02:16s\n",
      "epoch 137| loss: 0.95876 | val_0_unsup_loss: 0.88175 |  0:02:17s\n",
      "epoch 138| loss: 0.95981 | val_0_unsup_loss: 0.87952 |  0:02:18s\n",
      "epoch 139| loss: 0.96669 | val_0_unsup_loss: 0.87957 |  0:02:19s\n",
      "epoch 140| loss: 0.9612  | val_0_unsup_loss: 0.87647 |  0:02:20s\n",
      "epoch 141| loss: 0.95798 | val_0_unsup_loss: 0.87392 |  0:02:21s\n",
      "epoch 142| loss: 7060.03118| val_0_unsup_loss: 0.87774 |  0:02:22s\n",
      "epoch 143| loss: 0.96708 | val_0_unsup_loss: 0.87808 |  0:02:23s\n",
      "epoch 144| loss: 0.95464 | val_0_unsup_loss: 0.86687 |  0:02:24s\n",
      "epoch 145| loss: 0.95896 | val_0_unsup_loss: 0.86069 |  0:02:25s\n",
      "epoch 146| loss: 0.9563  | val_0_unsup_loss: 0.85865 |  0:02:26s\n",
      "epoch 147| loss: 6577.06061| val_0_unsup_loss: 0.86205 |  0:02:27s\n",
      "epoch 148| loss: 0.95506 | val_0_unsup_loss: 0.87258 |  0:02:28s\n",
      "epoch 149| loss: 0.95718 | val_0_unsup_loss: 0.87275 |  0:02:29s\n",
      "epoch 150| loss: 0.94948 | val_0_unsup_loss: 0.87387 |  0:02:30s\n",
      "epoch 151| loss: 0.96188 | val_0_unsup_loss: 0.86984 |  0:02:31s\n",
      "epoch 152| loss: 0.96028 | val_0_unsup_loss: 0.87058 |  0:02:32s\n",
      "epoch 153| loss: 0.9564  | val_0_unsup_loss: 0.87034 |  0:02:33s\n",
      "epoch 154| loss: 0.95311 | val_0_unsup_loss: 0.8669  |  0:02:34s\n",
      "epoch 155| loss: 0.96013 | val_0_unsup_loss: 0.8657  |  0:02:35s\n",
      "epoch 156| loss: 0.95425 | val_0_unsup_loss: 0.86421 |  0:02:36s\n",
      "epoch 157| loss: 884.55712| val_0_unsup_loss: 0.86896 |  0:02:37s\n",
      "epoch 158| loss: 0.95921 | val_0_unsup_loss: 0.88856 |  0:02:38s\n",
      "epoch 159| loss: 0.95993 | val_0_unsup_loss: 0.87074 |  0:02:39s\n",
      "epoch 160| loss: 0.95493 | val_0_unsup_loss: 0.86827 |  0:02:40s\n",
      "epoch 161| loss: 0.94964 | val_0_unsup_loss: 0.86423 |  0:02:40s\n",
      "epoch 162| loss: 0.95599 | val_0_unsup_loss: 0.86471 |  0:02:41s\n",
      "epoch 163| loss: 0.95119 | val_0_unsup_loss: 0.86326 |  0:02:43s\n",
      "epoch 164| loss: 0.94904 | val_0_unsup_loss: 0.86491 |  0:02:43s\n",
      "epoch 165| loss: 0.95166 | val_0_unsup_loss: 0.86283 |  0:02:44s\n",
      "epoch 166| loss: 0.95239 | val_0_unsup_loss: 0.86354 |  0:02:45s\n",
      "epoch 167| loss: 0.95165 | val_0_unsup_loss: 0.86448 |  0:02:46s\n",
      "epoch 168| loss: 0.94921 | val_0_unsup_loss: 0.8646  |  0:02:47s\n",
      "epoch 169| loss: 0.95685 | val_0_unsup_loss: 0.86579 |  0:02:48s\n",
      "epoch 170| loss: 0.95197 | val_0_unsup_loss: 0.86532 |  0:02:49s\n",
      "epoch 171| loss: 11805.11517| val_0_unsup_loss: 0.86917 |  0:02:50s\n",
      "epoch 172| loss: 0.9542  | val_0_unsup_loss: 0.86289 |  0:02:51s\n",
      "epoch 173| loss: 0.95281 | val_0_unsup_loss: 0.86541 |  0:02:52s\n",
      "epoch 174| loss: 0.96029 | val_0_unsup_loss: 0.86265 |  0:02:53s\n",
      "epoch 175| loss: 0.94809 | val_0_unsup_loss: 0.86225 |  0:02:54s\n",
      "epoch 176| loss: 904.3624| val_0_unsup_loss: 0.86343 |  0:02:55s\n",
      "epoch 177| loss: 0.95157 | val_0_unsup_loss: 0.87849 |  0:02:56s\n",
      "epoch 178| loss: 0.95077 | val_0_unsup_loss: 0.87193 |  0:02:57s\n",
      "epoch 179| loss: 0.95173 | val_0_unsup_loss: 0.86778 |  0:02:58s\n",
      "epoch 180| loss: 0.95373 | val_0_unsup_loss: 0.86395 |  0:02:59s\n",
      "epoch 181| loss: 0.95485 | val_0_unsup_loss: 0.8631  |  0:03:00s\n",
      "epoch 182| loss: 5840.11878| val_0_unsup_loss: 0.8632  |  0:03:01s\n",
      "epoch 183| loss: 0.95302 | val_0_unsup_loss: 0.86189 |  0:03:02s\n",
      "epoch 184| loss: 0.94808 | val_0_unsup_loss: 0.86455 |  0:03:03s\n",
      "epoch 185| loss: 0.952   | val_0_unsup_loss: 0.86514 |  0:03:04s\n",
      "epoch 186| loss: 0.94794 | val_0_unsup_loss: 0.86717 |  0:03:05s\n",
      "epoch 187| loss: 0.95066 | val_0_unsup_loss: 0.86597 |  0:03:06s\n",
      "epoch 188| loss: 0.95022 | val_0_unsup_loss: 0.8653  |  0:03:07s\n",
      "epoch 189| loss: 0.94977 | val_0_unsup_loss: 0.86503 |  0:03:08s\n",
      "epoch 190| loss: 0.95028 | val_0_unsup_loss: 0.86636 |  0:03:09s\n",
      "epoch 191| loss: 0.94697 | val_0_unsup_loss: 0.86399 |  0:03:10s\n",
      "epoch 192| loss: 0.95006 | val_0_unsup_loss: 0.86428 |  0:03:10s\n",
      "epoch 193| loss: 0.94864 | val_0_unsup_loss: 0.86288 |  0:03:11s\n",
      "epoch 194| loss: 1973.24999| val_0_unsup_loss: 0.86316 |  0:03:12s\n",
      "epoch 195| loss: 0.95729 | val_0_unsup_loss: 0.87381 |  0:03:13s\n",
      "epoch 196| loss: 0.95483 | val_0_unsup_loss: 0.8663  |  0:03:14s\n",
      "\n",
      "Early stopping occurred at epoch 196 with best_epoch = 146 and best_val_0_unsup_loss = 0.85865\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    }
   ],
   "source": [
    "# TabNetPretrainer\n",
    "unsupervised_model = TabNetPretrainer(\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=2e-2),\n",
    "    mask_type='entmax', # \"sparsemax\",\n",
    "    )\n",
    "\n",
    "unsupervised_model.fit(\n",
    "    x_train,\n",
    "    eval_set=[x_val],\n",
    "    max_epochs=500 , patience=50,\n",
    "    batch_size=1024, virtual_batch_size=128,\n",
    "    num_workers=0,\n",
    "    drop_last=False,\n",
    "    pretraining_ratio=0.8,\n",
    ")\n",
    "\n",
    "# reconstructed_X, embedded_X = unsupervised_model_no_preproc.predict(x_val)\n",
    "# assert(reconstructed_X.shape==embedded_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19bcbe8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cpu\n",
      "Loading weights from unsupervised pretraining\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:97: UserWarning: Pretraining: mask_type changed from sparsemax to entmax\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.65099 | train_auc: 0.82551 | valid_auc: 0.81725 |  0:00:01s\n",
      "epoch 1  | loss: 0.50575 | train_auc: 0.86396 | valid_auc: 0.85007 |  0:00:02s\n",
      "epoch 2  | loss: 0.40237 | train_auc: 0.91692 | valid_auc: 0.90864 |  0:00:04s\n",
      "epoch 3  | loss: 0.3359  | train_auc: 0.93406 | valid_auc: 0.92654 |  0:00:05s\n",
      "epoch 4  | loss: 0.32699 | train_auc: 0.94013 | valid_auc: 0.93167 |  0:00:07s\n",
      "epoch 5  | loss: 0.3181  | train_auc: 0.94554 | valid_auc: 0.93809 |  0:00:08s\n",
      "epoch 6  | loss: 0.28882 | train_auc: 0.9481  | valid_auc: 0.94088 |  0:00:09s\n",
      "epoch 7  | loss: 0.28351 | train_auc: 0.95196 | valid_auc: 0.94485 |  0:00:11s\n",
      "epoch 8  | loss: 0.27955 | train_auc: 0.95333 | valid_auc: 0.94312 |  0:00:12s\n",
      "epoch 9  | loss: 0.27884 | train_auc: 0.95398 | valid_auc: 0.94602 |  0:00:13s\n",
      "epoch 10 | loss: 0.28156 | train_auc: 0.95532 | valid_auc: 0.94706 |  0:00:15s\n",
      "epoch 11 | loss: 0.27916 | train_auc: 0.95546 | valid_auc: 0.949   |  0:00:16s\n",
      "epoch 12 | loss: 0.27528 | train_auc: 0.95913 | valid_auc: 0.95371 |  0:00:17s\n",
      "epoch 13 | loss: 0.26624 | train_auc: 0.956   | valid_auc: 0.94956 |  0:00:18s\n",
      "epoch 14 | loss: 0.25619 | train_auc: 0.95383 | valid_auc: 0.94699 |  0:00:20s\n",
      "epoch 15 | loss: 0.24814 | train_auc: 0.96315 | valid_auc: 0.956   |  0:00:21s\n",
      "epoch 16 | loss: 0.24722 | train_auc: 0.96187 | valid_auc: 0.95607 |  0:00:22s\n",
      "epoch 17 | loss: 0.22189 | train_auc: 0.96436 | valid_auc: 0.95813 |  0:00:24s\n",
      "epoch 18 | loss: 0.21556 | train_auc: 0.97173 | valid_auc: 0.96409 |  0:00:25s\n",
      "epoch 19 | loss: 0.22466 | train_auc: 0.9425  | valid_auc: 0.9335  |  0:00:27s\n",
      "epoch 20 | loss: 0.21278 | train_auc: 0.97652 | valid_auc: 0.96935 |  0:00:28s\n",
      "epoch 21 | loss: 0.18794 | train_auc: 0.96211 | valid_auc: 0.95218 |  0:00:30s\n",
      "epoch 22 | loss: 0.21489 | train_auc: 0.86061 | valid_auc: 0.84555 |  0:00:31s\n",
      "epoch 23 | loss: 0.19793 | train_auc: 0.9534  | valid_auc: 0.94201 |  0:00:33s\n",
      "epoch 24 | loss: 0.18885 | train_auc: 0.9741  | valid_auc: 0.96534 |  0:00:34s\n",
      "epoch 25 | loss: 0.20107 | train_auc: 0.96759 | valid_auc: 0.95954 |  0:00:35s\n",
      "epoch 26 | loss: 0.19947 | train_auc: 0.81612 | valid_auc: 0.80001 |  0:00:37s\n",
      "epoch 27 | loss: 0.18801 | train_auc: 0.96416 | valid_auc: 0.95573 |  0:00:38s\n",
      "epoch 28 | loss: 0.19362 | train_auc: 0.95351 | valid_auc: 0.94315 |  0:00:39s\n",
      "epoch 29 | loss: 0.18962 | train_auc: 0.97202 | valid_auc: 0.96131 |  0:00:41s\n",
      "epoch 30 | loss: 0.18272 | train_auc: 0.90889 | valid_auc: 0.89248 |  0:00:42s\n",
      "epoch 31 | loss: 0.19462 | train_auc: 0.96809 | valid_auc: 0.95718 |  0:00:43s\n",
      "epoch 32 | loss: 0.17594 | train_auc: 0.77584 | valid_auc: 0.75492 |  0:00:45s\n",
      "epoch 33 | loss: 0.18763 | train_auc: 0.98381 | valid_auc: 0.97422 |  0:00:46s\n",
      "epoch 34 | loss: 0.171   | train_auc: 0.9671  | valid_auc: 0.9584  |  0:00:48s\n",
      "epoch 35 | loss: 0.1822  | train_auc: 0.68325 | valid_auc: 0.66747 |  0:00:49s\n",
      "epoch 36 | loss: 0.17031 | train_auc: 0.978   | valid_auc: 0.96754 |  0:00:50s\n",
      "epoch 37 | loss: 0.16198 | train_auc: 0.98342 | valid_auc: 0.97465 |  0:00:52s\n",
      "epoch 38 | loss: 0.16302 | train_auc: 0.98288 | valid_auc: 0.97434 |  0:00:53s\n",
      "epoch 39 | loss: 0.16607 | train_auc: 0.98543 | valid_auc: 0.97574 |  0:00:54s\n",
      "epoch 40 | loss: 0.17456 | train_auc: 0.97694 | valid_auc: 0.96361 |  0:00:56s\n",
      "epoch 41 | loss: 0.15851 | train_auc: 0.97973 | valid_auc: 0.96692 |  0:00:57s\n",
      "epoch 42 | loss: 0.15559 | train_auc: 0.9477  | valid_auc: 0.9308  |  0:00:58s\n",
      "epoch 43 | loss: 0.15673 | train_auc: 0.73662 | valid_auc: 0.71841 |  0:00:59s\n",
      "epoch 44 | loss: 0.1564  | train_auc: 0.95702 | valid_auc: 0.93847 |  0:01:01s\n",
      "epoch 45 | loss: 0.15952 | train_auc: 0.89251 | valid_auc: 0.87141 |  0:01:02s\n",
      "epoch 46 | loss: 0.15674 | train_auc: 0.85677 | valid_auc: 0.83283 |  0:01:03s\n",
      "epoch 47 | loss: 0.1584  | train_auc: 0.6932  | valid_auc: 0.67173 |  0:01:04s\n",
      "epoch 48 | loss: 0.15883 | train_auc: 0.98515 | valid_auc: 0.9701  |  0:01:06s\n",
      "epoch 49 | loss: 0.1463  | train_auc: 0.97113 | valid_auc: 0.9538  |  0:01:07s\n",
      "epoch 50 | loss: 0.157   | train_auc: 0.96935 | valid_auc: 0.95259 |  0:01:08s\n",
      "epoch 51 | loss: 0.1429  | train_auc: 0.71737 | valid_auc: 0.69538 |  0:01:10s\n",
      "epoch 52 | loss: 0.14374 | train_auc: 0.98927 | valid_auc: 0.97409 |  0:01:11s\n",
      "epoch 53 | loss: 0.13725 | train_auc: 0.9872  | valid_auc: 0.97028 |  0:01:13s\n",
      "epoch 54 | loss: 0.13904 | train_auc: 0.90985 | valid_auc: 0.87812 |  0:01:14s\n",
      "epoch 55 | loss: 0.14385 | train_auc: 0.9389  | valid_auc: 0.91346 |  0:01:16s\n",
      "epoch 56 | loss: 0.14469 | train_auc: 0.83476 | valid_auc: 0.79779 |  0:01:17s\n",
      "epoch 57 | loss: 0.13986 | train_auc: 0.9509  | valid_auc: 0.92286 |  0:01:18s\n",
      "epoch 58 | loss: 0.14725 | train_auc: 0.89787 | valid_auc: 0.86738 |  0:01:19s\n",
      "epoch 59 | loss: 0.15001 | train_auc: 0.7891  | valid_auc: 0.75809 |  0:01:21s\n",
      "\n",
      "Early stopping occurred at epoch 59 with best_epoch = 39 and best_valid_auc = 0.97574\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    }
   ],
   "source": [
    "clf = TabNetClassifier(\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=2e-2),\n",
    "    scheduler_params={\"step_size\":10, # how to use learning rate scheduler\n",
    "                      \"gamma\":0.9},\n",
    "    scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "    mask_type='sparsemax' # This will be overwritten if using pretrain model\n",
    ")\n",
    "\n",
    "clf.fit(\n",
    "    X_train= x_train, y_train=y_train,\n",
    "    eval_set=[(x_train, y_train), (x_val, y_val)],\n",
    "    eval_name=['train', 'valid'],\n",
    "    eval_metric=['auc'],\n",
    "    from_unsupervised=unsupervised_model,\n",
    "    max_epochs=500 , patience=20,\n",
    "    batch_size=1024, virtual_batch_size=128,\n",
    "    num_workers=0,\n",
    "    weights=1,\n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f377ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: 84.02%\n"
     ]
    }
   ],
   "source": [
    "# Predicting the Value\n",
    "x_val_pred = clf.predict_proba(x_val)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a9f6e2f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: 87.60%\n"
     ]
    }
   ],
   "source": [
    "# Getting it into a form that'll be gradeable\n",
    "x_val_pred_label = x_val_pred > 0.5\n",
    "x_val_pred_label = x_val_pred_label.astype(int)\n",
    "x_val_pred_label_df = pd.DataFrame(x_val_pred_label)\n",
    "y_val_df = pd.DataFrame(y_val)\n",
    "\n",
    "f1s = f1_score(y_val_df, x_val_pred_label_df)\n",
    "print(\"Baseline: %.2f%%\" % (f1s*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
