{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fe324d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regular Importing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85a557a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture output\n",
    "# Keras Importing\n",
    "!pip install tensorflow\n",
    "!pip install keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdc3d649",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture output\n",
    "# Importing for seeing the missing Data\n",
    "!pip install missingno\n",
    "import missingno as msno"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1398e66",
   "metadata": {},
   "source": [
    "## Does TabNet Do Better Than Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f3a8a72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture output\n",
    "# Tabnet Importing\n",
    "!pip install pytorch_tabnet\n",
    "from pytorch_tabnet.pretraining import TabNetPretrainer\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "import pytorch_tabnet\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e82c8aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRAN_AMT</th>\n",
       "      <th>ACCT_PRE_TRAN_AVAIL_BAL</th>\n",
       "      <th>CUST_AGE</th>\n",
       "      <th>OPEN_ACCT_CT</th>\n",
       "      <th>WF_dvc_age</th>\n",
       "      <th>PWD_UPDT_TS</th>\n",
       "      <th>CARR_NAME</th>\n",
       "      <th>RGN_NAME</th>\n",
       "      <th>STATE_PRVNC_TXT</th>\n",
       "      <th>ALERT_TRGR_CD</th>\n",
       "      <th>...</th>\n",
       "      <th>CUST_STATE</th>\n",
       "      <th>PH_NUM_UPDT_TS</th>\n",
       "      <th>CUST_SINCE_DT</th>\n",
       "      <th>TRAN_TS</th>\n",
       "      <th>TRAN_DT</th>\n",
       "      <th>ACTN_CD</th>\n",
       "      <th>ACTN_INTNL_TXT</th>\n",
       "      <th>TRAN_TYPE_CD</th>\n",
       "      <th>ACTVY_DT</th>\n",
       "      <th>FRAUD_NONFRAUD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.38</td>\n",
       "      <td>23619.91</td>\n",
       "      <td>47</td>\n",
       "      <td>4</td>\n",
       "      <td>2777</td>\n",
       "      <td>1/16/2018 11:3:58</td>\n",
       "      <td>cox communications inc.</td>\n",
       "      <td>southwest</td>\n",
       "      <td>nevada</td>\n",
       "      <td>MOBL</td>\n",
       "      <td>...</td>\n",
       "      <td>NV</td>\n",
       "      <td>2/24/2021 15:55:10</td>\n",
       "      <td>1993-01-06 00:00:00</td>\n",
       "      <td>5/3/2021 18:3:58</td>\n",
       "      <td>5/3/2021</td>\n",
       "      <td>SCHPMT</td>\n",
       "      <td>P2P_COMMIT</td>\n",
       "      <td>P2P</td>\n",
       "      <td>5/3/2021</td>\n",
       "      <td>Non-Fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>45</td>\n",
       "      <td>5</td>\n",
       "      <td>2721</td>\n",
       "      <td>NaN</td>\n",
       "      <td>charter communications</td>\n",
       "      <td>southwest</td>\n",
       "      <td>california</td>\n",
       "      <td>MOBL</td>\n",
       "      <td>...</td>\n",
       "      <td>CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1971-01-07 00:00:00</td>\n",
       "      <td>1/13/2021 19:19:37</td>\n",
       "      <td>1/13/2021</td>\n",
       "      <td>SCHPMT</td>\n",
       "      <td>P2P_COMMIT</td>\n",
       "      <td>P2P</td>\n",
       "      <td>1/13/2021</td>\n",
       "      <td>Non-Fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54.84</td>\n",
       "      <td>34570.63</td>\n",
       "      <td>36</td>\n",
       "      <td>8</td>\n",
       "      <td>1531</td>\n",
       "      <td>12/22/2021 10:42:51</td>\n",
       "      <td>utah broadband llc</td>\n",
       "      <td>mountain</td>\n",
       "      <td>utah</td>\n",
       "      <td>ONLN</td>\n",
       "      <td>...</td>\n",
       "      <td>MD</td>\n",
       "      <td>5/5/2019 1:8:39</td>\n",
       "      <td>1994-02-01 00:00:00</td>\n",
       "      <td>4/8/2021 9:42:51</td>\n",
       "      <td>4/8/2021</td>\n",
       "      <td>SCHPMT</td>\n",
       "      <td>P2P_COMMIT</td>\n",
       "      <td>P2P</td>\n",
       "      <td>4/8/2021</td>\n",
       "      <td>Fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "      <td>835</td>\n",
       "      <td>2/8/2020 7:28:31</td>\n",
       "      <td>t-mobile usa  inc.</td>\n",
       "      <td>southwest</td>\n",
       "      <td>california</td>\n",
       "      <td>MOBL</td>\n",
       "      <td>...</td>\n",
       "      <td>NV</td>\n",
       "      <td>2/16/2019 6:45:37</td>\n",
       "      <td>2001-11-01 00:00:00</td>\n",
       "      <td>8/10/2021 15:28:31</td>\n",
       "      <td>8/10/2021</td>\n",
       "      <td>SCHPMT</td>\n",
       "      <td>P2P_COMMIT</td>\n",
       "      <td>P2P</td>\n",
       "      <td>8/10/2021</td>\n",
       "      <td>Non-Fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>497.08</td>\n",
       "      <td>12725.18</td>\n",
       "      <td>81</td>\n",
       "      <td>2</td>\n",
       "      <td>1095</td>\n",
       "      <td>12/28/2020 12:12:44</td>\n",
       "      <td>cogent communications</td>\n",
       "      <td>south central</td>\n",
       "      <td>texas</td>\n",
       "      <td>MOBL</td>\n",
       "      <td>...</td>\n",
       "      <td>UT</td>\n",
       "      <td>5/8/2020 10:27:6</td>\n",
       "      <td>1987-02-07 00:00:00</td>\n",
       "      <td>6/27/2021 11:12:44</td>\n",
       "      <td>6/27/2021</td>\n",
       "      <td>SCHPMT</td>\n",
       "      <td>P2P_COMMIT</td>\n",
       "      <td>P2P</td>\n",
       "      <td>6/27/2021</td>\n",
       "      <td>Fraud</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TRAN_AMT  ACCT_PRE_TRAN_AVAIL_BAL  CUST_AGE  OPEN_ACCT_CT  WF_dvc_age  \\\n",
       "0      5.38                 23619.91        47             4        2777   \n",
       "1     65.19                     0.00        45             5        2721   \n",
       "2     54.84                 34570.63        36             8        1531   \n",
       "3      0.01                     0.00        62             3         835   \n",
       "4    497.08                 12725.18        81             2        1095   \n",
       "\n",
       "           PWD_UPDT_TS                CARR_NAME       RGN_NAME  \\\n",
       "0    1/16/2018 11:3:58  cox communications inc.      southwest   \n",
       "1                  NaN   charter communications      southwest   \n",
       "2  12/22/2021 10:42:51       utah broadband llc       mountain   \n",
       "3     2/8/2020 7:28:31       t-mobile usa  inc.      southwest   \n",
       "4  12/28/2020 12:12:44    cogent communications  south central   \n",
       "\n",
       "  STATE_PRVNC_TXT ALERT_TRGR_CD  ... CUST_STATE      PH_NUM_UPDT_TS  \\\n",
       "0          nevada          MOBL  ...         NV  2/24/2021 15:55:10   \n",
       "1      california          MOBL  ...         CA                 NaN   \n",
       "2            utah          ONLN  ...         MD     5/5/2019 1:8:39   \n",
       "3      california          MOBL  ...         NV   2/16/2019 6:45:37   \n",
       "4           texas          MOBL  ...         UT    5/8/2020 10:27:6   \n",
       "\n",
       "         CUST_SINCE_DT             TRAN_TS    TRAN_DT ACTN_CD ACTN_INTNL_TXT  \\\n",
       "0  1993-01-06 00:00:00    5/3/2021 18:3:58   5/3/2021  SCHPMT     P2P_COMMIT   \n",
       "1  1971-01-07 00:00:00  1/13/2021 19:19:37  1/13/2021  SCHPMT     P2P_COMMIT   \n",
       "2  1994-02-01 00:00:00    4/8/2021 9:42:51   4/8/2021  SCHPMT     P2P_COMMIT   \n",
       "3  2001-11-01 00:00:00  8/10/2021 15:28:31  8/10/2021  SCHPMT     P2P_COMMIT   \n",
       "4  1987-02-07 00:00:00  6/27/2021 11:12:44  6/27/2021  SCHPMT     P2P_COMMIT   \n",
       "\n",
       "  TRAN_TYPE_CD   ACTVY_DT FRAUD_NONFRAUD  \n",
       "0          P2P   5/3/2021      Non-Fraud  \n",
       "1          P2P  1/13/2021      Non-Fraud  \n",
       "2          P2P   4/8/2021          Fraud  \n",
       "3          P2P  8/10/2021      Non-Fraud  \n",
       "4          P2P  6/27/2021          Fraud  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Loading\n",
    "testDf = pd.read_csv(\"WFTest.csv\")\n",
    "trainDf = pd.read_csv(\"WFTrain.csv\")\n",
    "trainDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc751abf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.380000e+00, 2.361991e+04, 4.700000e+01, ..., 1.000000e+00,\n",
       "        1.000000e+00, 1.000000e+00],\n",
       "       [6.519000e+01, 0.000000e+00, 4.500000e+01, ..., 1.000000e+00,\n",
       "        1.000000e+00, 1.000000e+00],\n",
       "       [5.484000e+01, 3.457063e+04, 3.600000e+01, ..., 1.000000e+00,\n",
       "        1.000000e+00, 1.000000e+00],\n",
       "       ...,\n",
       "       [4.930000e+02, 2.848630e+03, 5.400000e+01, ..., 1.000000e+00,\n",
       "        1.000000e+00, 1.000000e+00],\n",
       "       [4.916400e+02, 3.163250e+03, 2.100000e+01, ..., 1.000000e+00,\n",
       "        1.000000e+00, 1.000000e+00],\n",
       "       [6.020000e+00, 0.000000e+00, 6.000000e+01, ..., 1.000000e+00,\n",
       "        1.000000e+00, 1.000000e+00]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting up the Features\n",
    "numerical = ['TRAN_AMT', 'ACCT_PRE_TRAN_AVAIL_BAL','CUST_AGE',\n",
    "             'OPEN_ACCT_CT', 'WF_dvc_age', 'CUST_ZIP']\n",
    "categorical = ['CARR_NAME', 'RGN_NAME', 'STATE_PRVNC_TXT', 'ALERT_TRGR_CD',\n",
    "                  'DVC_TYPE_TXT', 'AUTHC_PRIM_TYPE_CD', 'AUTHC_SCNDRY_STAT_TXT',\n",
    "                  'CUST_STATE','ACTN_CD','ACTN_INTNL_TXT','TRAN_TYPE_CD']\n",
    "X_cat = pd.get_dummies(trainDf[categorical])\n",
    "X_num = trainDf[numerical]\n",
    "X = pd.concat([X_num, X_cat], axis = 1)\n",
    "X_mean_imputed = X.fillna(X.mean())\n",
    "X_mean_imputed_numpy = X_mean_imputed.to_numpy()\n",
    "X_mean_imputed_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd4a3dab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the Y values\n",
    "Y = trainDf[\"FRAUD_NONFRAUD\"]\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "encoded_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8baac8ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000e-02, 0.00000e+00, 2.10000e+01, ..., 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00],\n",
       "       [1.00000e-02, 1.01590e+03, 2.90000e+01, ..., 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00],\n",
       "       [1.00000e-02, 0.00000e+00, 4.20000e+01, ..., 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00],\n",
       "       ...,\n",
       "       [4.62700e+01, 0.00000e+00, 4.90000e+01, ..., 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00],\n",
       "       [8.26600e+01, 1.84563e+03, 3.70000e+01, ..., 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00],\n",
       "       [8.70000e-01, 8.64068e+03, 7.40000e+01, ..., 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Need a validation set for this, Keras can wrap tabnet and do cv but not sure needed\n",
    "x_train, x_val, y_train, y_val = train_test_split(X_mean_imputed_numpy, encoded_Y, test_size=0.30, random_state=8)\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b64634cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cpu\n",
      "epoch 0  | loss: 149399290.26347| val_0_unsup_loss: 3893763.75|  0:00:06s\n",
      "epoch 1  | loss: 1427506.32939| val_0_unsup_loss: 97364.42969|  0:00:11s\n",
      "epoch 2  | loss: 178502.06379| val_0_unsup_loss: 493305.59375|  0:00:16s\n",
      "epoch 3  | loss: 87639.77717| val_0_unsup_loss: 970.84985|  0:00:21s\n",
      "epoch 4  | loss: 83132.60763| val_0_unsup_loss: 5895.03027|  0:00:26s\n",
      "epoch 5  | loss: 68334.74405| val_0_unsup_loss: 1597.69641|  0:00:32s\n",
      "epoch 6  | loss: 49499.34829| val_0_unsup_loss: 430.88806|  0:00:37s\n",
      "epoch 7  | loss: 42426.19051| val_0_unsup_loss: 7846.76514|  0:00:42s\n",
      "epoch 8  | loss: 17970.08185| val_0_unsup_loss: 65.60343|  0:00:47s\n",
      "epoch 9  | loss: 29841.2788| val_0_unsup_loss: 2391.82202|  0:00:53s\n",
      "epoch 10 | loss: 41208.95511| val_0_unsup_loss: 8147.67432|  0:00:58s\n",
      "epoch 11 | loss: 6907.6766| val_0_unsup_loss: 278946.75|  0:01:04s\n",
      "epoch 12 | loss: 4198.52499| val_0_unsup_loss: 10026666.0|  0:01:11s\n",
      "epoch 13 | loss: 1830.67996| val_0_unsup_loss: 432816.6875|  0:01:17s\n",
      "epoch 14 | loss: 2084.45634| val_0_unsup_loss: 471964.71875|  0:01:25s\n",
      "epoch 15 | loss: 1781.01275| val_0_unsup_loss: 451075.28125|  0:01:31s\n",
      "epoch 16 | loss: 1669.7144| val_0_unsup_loss: 251456.90625|  0:01:36s\n",
      "epoch 17 | loss: 2197.36681| val_0_unsup_loss: 80430.89062|  0:01:42s\n",
      "epoch 18 | loss: 996.05252| val_0_unsup_loss: 4205.8833|  0:01:48s\n",
      "epoch 19 | loss: 11835.64921| val_0_unsup_loss: 18233.95508|  0:01:54s\n",
      "epoch 20 | loss: 2138.34193| val_0_unsup_loss: 19469.0332|  0:01:59s\n",
      "epoch 21 | loss: 1371.89329| val_0_unsup_loss: 36791.26172|  0:02:04s\n",
      "epoch 22 | loss: 1515.60198| val_0_unsup_loss: 210872.67188|  0:02:11s\n",
      "epoch 23 | loss: 783.07003| val_0_unsup_loss: 259434.60938|  0:02:16s\n",
      "epoch 24 | loss: 911.2273| val_0_unsup_loss: 132655.26562|  0:02:22s\n",
      "epoch 25 | loss: 923.33394| val_0_unsup_loss: 226799.32812|  0:02:27s\n",
      "epoch 26 | loss: 836.98121| val_0_unsup_loss: 23177.59961|  0:02:33s\n",
      "epoch 27 | loss: 633.29557| val_0_unsup_loss: 8651.27832|  0:02:39s\n",
      "epoch 28 | loss: 857.93318| val_0_unsup_loss: 2321.20044|  0:02:45s\n",
      "epoch 29 | loss: 702.4166| val_0_unsup_loss: 140638.875|  0:02:51s\n",
      "epoch 30 | loss: 440.72343| val_0_unsup_loss: 88719.50781|  0:02:57s\n",
      "epoch 31 | loss: 558.99765| val_0_unsup_loss: 26349.20117|  0:03:03s\n",
      "epoch 32 | loss: 745.48459| val_0_unsup_loss: 3695628.25|  0:03:10s\n",
      "epoch 33 | loss: 630.86023| val_0_unsup_loss: 1344838.875|  0:03:16s\n",
      "epoch 34 | loss: 2483.10853| val_0_unsup_loss: 233031.92188|  0:03:22s\n",
      "epoch 35 | loss: 497.13329| val_0_unsup_loss: 199906.46875|  0:03:28s\n",
      "epoch 36 | loss: 255.45449| val_0_unsup_loss: 158993.79688|  0:03:33s\n",
      "epoch 37 | loss: 411.39296| val_0_unsup_loss: 3004300.0|  0:03:39s\n",
      "epoch 38 | loss: 1116.6822| val_0_unsup_loss: 8112450.0|  0:03:45s\n",
      "epoch 39 | loss: 554.99112| val_0_unsup_loss: 15660.1377|  0:03:50s\n",
      "epoch 40 | loss: 415.0002| val_0_unsup_loss: 602.65814|  0:03:56s\n",
      "epoch 41 | loss: 324.74919| val_0_unsup_loss: 364441.6875|  0:04:02s\n",
      "epoch 42 | loss: 181.57222| val_0_unsup_loss: 220.92661|  0:04:08s\n",
      "epoch 43 | loss: 214.99721| val_0_unsup_loss: 334.72763|  0:04:15s\n",
      "epoch 44 | loss: 833.6251| val_0_unsup_loss: 12529.1377|  0:04:20s\n",
      "epoch 45 | loss: 462.14244| val_0_unsup_loss: 36870.42578|  0:04:26s\n",
      "epoch 46 | loss: 133.04554| val_0_unsup_loss: 1459.0614|  0:04:31s\n",
      "epoch 47 | loss: 3073.15131| val_0_unsup_loss: 196.01553|  0:04:37s\n",
      "epoch 48 | loss: 877.54265| val_0_unsup_loss: 118.80604|  0:04:42s\n",
      "epoch 49 | loss: 513.77181| val_0_unsup_loss: 328.61313|  0:04:48s\n",
      "epoch 50 | loss: 2481.61459| val_0_unsup_loss: 2514419.0|  0:04:54s\n",
      "epoch 51 | loss: 2651.57953| val_0_unsup_loss: 63726.94922|  0:04:59s\n",
      "epoch 52 | loss: 547.97991| val_0_unsup_loss: 5719.56494|  0:05:05s\n",
      "epoch 53 | loss: 163.81368| val_0_unsup_loss: 77.36096|  0:05:11s\n",
      "epoch 54 | loss: 619.28063| val_0_unsup_loss: 25040.17773|  0:05:16s\n",
      "epoch 55 | loss: 158.18357| val_0_unsup_loss: 11674.55469|  0:05:22s\n",
      "epoch 56 | loss: 333.97269| val_0_unsup_loss: 14762440.0|  0:05:29s\n",
      "epoch 57 | loss: 254.46349| val_0_unsup_loss: 8553649.0|  0:05:35s\n",
      "epoch 58 | loss: 1008.13915| val_0_unsup_loss: 6743032.0|  0:05:40s\n",
      "\n",
      "Early stopping occurred at epoch 58 with best_epoch = 8 and best_val_0_unsup_loss = 65.60343\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    }
   ],
   "source": [
    "# TabNetPretrainer\n",
    "unsupervised_model = TabNetPretrainer(\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=2e-2),\n",
    "    mask_type='entmax', # \"sparsemax\",\n",
    "    )\n",
    "\n",
    "unsupervised_model.fit(\n",
    "    x_train,\n",
    "    eval_set=[x_val],\n",
    "    max_epochs=500 , patience=50,\n",
    "    batch_size=1024, virtual_batch_size=128,\n",
    "    num_workers=0,\n",
    "    drop_last=False,\n",
    "    pretraining_ratio=0.8,\n",
    ")\n",
    "\n",
    "# reconstructed_X, embedded_X = unsupervised_model_no_preproc.predict(x_val)\n",
    "# assert(reconstructed_X.shape==embedded_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "552571d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cpu\n",
      "Loading weights from unsupervised pretraining\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:97: UserWarning: Pretraining: mask_type changed from sparsemax to entmax\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.70283 | train_auc: 0.57719 | valid_auc: 0.56602 |  0:00:08s\n",
      "epoch 1  | loss: 0.68873 | train_auc: 0.61878 | valid_auc: 0.62465 |  0:00:16s\n",
      "epoch 2  | loss: 0.6715  | train_auc: 0.68693 | valid_auc: 0.68856 |  0:00:28s\n",
      "epoch 3  | loss: 0.62049 | train_auc: 0.82575 | valid_auc: 0.82119 |  0:00:39s\n",
      "epoch 4  | loss: 0.55308 | train_auc: 0.85003 | valid_auc: 0.83134 |  0:00:48s\n",
      "epoch 5  | loss: 0.50318 | train_auc: 0.87071 | valid_auc: 0.8463  |  0:00:57s\n",
      "epoch 6  | loss: 0.46945 | train_auc: 0.89226 | valid_auc: 0.86954 |  0:01:07s\n",
      "epoch 7  | loss: 0.44369 | train_auc: 0.90446 | valid_auc: 0.87891 |  0:01:17s\n",
      "epoch 8  | loss: 0.41996 | train_auc: 0.9029  | valid_auc: 0.87476 |  0:01:26s\n",
      "epoch 9  | loss: 0.40872 | train_auc: 0.92269 | valid_auc: 0.89487 |  0:01:37s\n",
      "epoch 10 | loss: 0.34585 | train_auc: 0.92864 | valid_auc: 0.90396 |  0:01:47s\n",
      "epoch 11 | loss: 0.31113 | train_auc: 0.93556 | valid_auc: 0.90695 |  0:01:56s\n",
      "epoch 12 | loss: 0.31529 | train_auc: 0.94278 | valid_auc: 0.91553 |  0:02:05s\n",
      "epoch 13 | loss: 0.29588 | train_auc: 0.94884 | valid_auc: 0.92152 |  0:02:14s\n",
      "epoch 14 | loss: 0.29242 | train_auc: 0.95413 | valid_auc: 0.92619 |  0:02:24s\n",
      "epoch 15 | loss: 0.2817  | train_auc: 0.95873 | valid_auc: 0.93122 |  0:02:33s\n",
      "epoch 16 | loss: 0.26861 | train_auc: 0.9593  | valid_auc: 0.92908 |  0:02:43s\n",
      "epoch 17 | loss: 0.26495 | train_auc: 0.96286 | valid_auc: 0.93246 |  0:02:52s\n",
      "epoch 18 | loss: 0.26941 | train_auc: 0.96353 | valid_auc: 0.9308  |  0:03:02s\n",
      "epoch 19 | loss: 0.25364 | train_auc: 0.96636 | valid_auc: 0.9337  |  0:03:11s\n",
      "epoch 20 | loss: 0.24969 | train_auc: 0.96708 | valid_auc: 0.93435 |  0:03:20s\n",
      "epoch 21 | loss: 0.24033 | train_auc: 0.96812 | valid_auc: 0.93318 |  0:03:29s\n",
      "epoch 22 | loss: 0.2367  | train_auc: 0.96992 | valid_auc: 0.93473 |  0:03:38s\n",
      "epoch 23 | loss: 0.22877 | train_auc: 0.97074 | valid_auc: 0.93367 |  0:03:47s\n",
      "epoch 24 | loss: 0.22696 | train_auc: 0.9725  | valid_auc: 0.93268 |  0:03:56s\n",
      "epoch 25 | loss: 0.24538 | train_auc: 0.97427 | valid_auc: 0.92627 |  0:04:05s\n",
      "epoch 26 | loss: 0.21785 | train_auc: 0.97443 | valid_auc: 0.92725 |  0:04:14s\n",
      "epoch 27 | loss: 0.21549 | train_auc: 0.97419 | valid_auc: 0.93076 |  0:04:23s\n",
      "epoch 28 | loss: 0.21591 | train_auc: 0.97575 | valid_auc: 0.93005 |  0:04:33s\n",
      "epoch 29 | loss: 0.2088  | train_auc: 0.97488 | valid_auc: 0.93001 |  0:04:44s\n",
      "epoch 30 | loss: 0.21343 | train_auc: 0.97676 | valid_auc: 0.93011 |  0:04:56s\n",
      "epoch 31 | loss: 0.21141 | train_auc: 0.97743 | valid_auc: 0.92756 |  0:05:06s\n",
      "epoch 32 | loss: 0.20521 | train_auc: 0.97864 | valid_auc: 0.93063 |  0:05:16s\n",
      "epoch 33 | loss: 0.20602 | train_auc: 0.97953 | valid_auc: 0.93243 |  0:05:27s\n",
      "epoch 34 | loss: 0.19643 | train_auc: 0.97897 | valid_auc: 0.92676 |  0:05:36s\n",
      "epoch 35 | loss: 0.19305 | train_auc: 0.9804  | valid_auc: 0.9309  |  0:05:47s\n",
      "epoch 36 | loss: 0.19121 | train_auc: 0.98069 | valid_auc: 0.92934 |  0:05:58s\n",
      "epoch 37 | loss: 0.20148 | train_auc: 0.98078 | valid_auc: 0.92137 |  0:06:08s\n",
      "epoch 38 | loss: 0.1921  | train_auc: 0.98077 | valid_auc: 0.91071 |  0:06:17s\n",
      "epoch 39 | loss: 0.19171 | train_auc: 0.9815  | valid_auc: 0.92349 |  0:06:27s\n",
      "epoch 40 | loss: 0.19252 | train_auc: 0.98153 | valid_auc: 0.92227 |  0:06:37s\n",
      "epoch 41 | loss: 0.1812  | train_auc: 0.98238 | valid_auc: 0.9302  |  0:06:47s\n",
      "epoch 42 | loss: 0.18551 | train_auc: 0.98345 | valid_auc: 0.9278  |  0:06:57s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_valid_auc = 0.93473\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    }
   ],
   "source": [
    "clf = TabNetClassifier(\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=2e-2),\n",
    "    scheduler_params={\"step_size\":10, # how to use learning rate scheduler\n",
    "                      \"gamma\":0.9},\n",
    "    scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "    mask_type='sparsemax' # This will be overwritten if using pretrain model\n",
    ")\n",
    "\n",
    "clf.fit(\n",
    "    X_train= x_train, y_train=y_train,\n",
    "    eval_set=[(x_train, y_train), (x_val, y_val)],\n",
    "    eval_name=['train', 'valid'],\n",
    "    eval_metric=['auc'],\n",
    "    from_unsupervised=unsupervised_model,\n",
    "    max_epochs=500 , patience=20,\n",
    "    batch_size=1024, virtual_batch_size=128,\n",
    "    num_workers=0,\n",
    "    weights=1,\n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72a3a216",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5278569c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Value\n",
    "x_val_pred = clf.predict_proba(x_val)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8f36edb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting it into a form that'll be gradeable\n",
    "x_val_pred_label = x_val_pred > 0.25\n",
    "x_val_pred_label = x_val_pred_label.astype(int)\n",
    "x_val_pred_label_df = pd.DataFrame(x_val_pred_label)\n",
    "y_val_df = pd.DataFrame(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5dade256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: 91.51%\n"
     ]
    }
   ],
   "source": [
    "f1s = f1_score(y_val_df, x_val_pred_label_df)\n",
    "print(\"Baseline: %.2f%%\" % (f1s*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
