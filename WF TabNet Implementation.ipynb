{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6fe324d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regular Importing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85a557a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture output\n",
    "# Keras Importing\n",
    "!pip install tensorflow\n",
    "!pip install keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdc3d649",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture output\n",
    "# Importing for seeing the missing Data\n",
    "!pip install missingno\n",
    "import missingno as msno"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1398e66",
   "metadata": {},
   "source": [
    "## Does TabNet Do Better Than Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f3a8a72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture output\n",
    "# Tabnet Importing\n",
    "!pip install pytorch_tabnet\n",
    "from pytorch_tabnet.pretraining import TabNetPretrainer\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "import pytorch_tabnet\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e82c8aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRAN_AMT</th>\n",
       "      <th>ACCT_PRE_TRAN_AVAIL_BAL</th>\n",
       "      <th>CUST_AGE</th>\n",
       "      <th>OPEN_ACCT_CT</th>\n",
       "      <th>WF_dvc_age</th>\n",
       "      <th>PWD_UPDT_TS</th>\n",
       "      <th>CARR_NAME</th>\n",
       "      <th>RGN_NAME</th>\n",
       "      <th>STATE_PRVNC_TXT</th>\n",
       "      <th>ALERT_TRGR_CD</th>\n",
       "      <th>...</th>\n",
       "      <th>CUST_STATE</th>\n",
       "      <th>PH_NUM_UPDT_TS</th>\n",
       "      <th>CUST_SINCE_DT</th>\n",
       "      <th>TRAN_TS</th>\n",
       "      <th>TRAN_DT</th>\n",
       "      <th>ACTN_CD</th>\n",
       "      <th>ACTN_INTNL_TXT</th>\n",
       "      <th>TRAN_TYPE_CD</th>\n",
       "      <th>ACTVY_DT</th>\n",
       "      <th>FRAUD_NONFRAUD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.38</td>\n",
       "      <td>23619.91</td>\n",
       "      <td>47</td>\n",
       "      <td>4</td>\n",
       "      <td>2777</td>\n",
       "      <td>1/16/2018 11:3:58</td>\n",
       "      <td>cox communications inc.</td>\n",
       "      <td>southwest</td>\n",
       "      <td>nevada</td>\n",
       "      <td>MOBL</td>\n",
       "      <td>...</td>\n",
       "      <td>NV</td>\n",
       "      <td>2/24/2021 15:55:10</td>\n",
       "      <td>1993-01-06 00:00:00</td>\n",
       "      <td>5/3/2021 18:3:58</td>\n",
       "      <td>5/3/2021</td>\n",
       "      <td>SCHPMT</td>\n",
       "      <td>P2P_COMMIT</td>\n",
       "      <td>P2P</td>\n",
       "      <td>5/3/2021</td>\n",
       "      <td>Non-Fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>45</td>\n",
       "      <td>5</td>\n",
       "      <td>2721</td>\n",
       "      <td>NaN</td>\n",
       "      <td>charter communications</td>\n",
       "      <td>southwest</td>\n",
       "      <td>california</td>\n",
       "      <td>MOBL</td>\n",
       "      <td>...</td>\n",
       "      <td>CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1971-01-07 00:00:00</td>\n",
       "      <td>1/13/2021 19:19:37</td>\n",
       "      <td>1/13/2021</td>\n",
       "      <td>SCHPMT</td>\n",
       "      <td>P2P_COMMIT</td>\n",
       "      <td>P2P</td>\n",
       "      <td>1/13/2021</td>\n",
       "      <td>Non-Fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54.84</td>\n",
       "      <td>34570.63</td>\n",
       "      <td>36</td>\n",
       "      <td>8</td>\n",
       "      <td>1531</td>\n",
       "      <td>12/22/2021 10:42:51</td>\n",
       "      <td>utah broadband llc</td>\n",
       "      <td>mountain</td>\n",
       "      <td>utah</td>\n",
       "      <td>ONLN</td>\n",
       "      <td>...</td>\n",
       "      <td>MD</td>\n",
       "      <td>5/5/2019 1:8:39</td>\n",
       "      <td>1994-02-01 00:00:00</td>\n",
       "      <td>4/8/2021 9:42:51</td>\n",
       "      <td>4/8/2021</td>\n",
       "      <td>SCHPMT</td>\n",
       "      <td>P2P_COMMIT</td>\n",
       "      <td>P2P</td>\n",
       "      <td>4/8/2021</td>\n",
       "      <td>Fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "      <td>835</td>\n",
       "      <td>2/8/2020 7:28:31</td>\n",
       "      <td>t-mobile usa  inc.</td>\n",
       "      <td>southwest</td>\n",
       "      <td>california</td>\n",
       "      <td>MOBL</td>\n",
       "      <td>...</td>\n",
       "      <td>NV</td>\n",
       "      <td>2/16/2019 6:45:37</td>\n",
       "      <td>2001-11-01 00:00:00</td>\n",
       "      <td>8/10/2021 15:28:31</td>\n",
       "      <td>8/10/2021</td>\n",
       "      <td>SCHPMT</td>\n",
       "      <td>P2P_COMMIT</td>\n",
       "      <td>P2P</td>\n",
       "      <td>8/10/2021</td>\n",
       "      <td>Non-Fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>497.08</td>\n",
       "      <td>12725.18</td>\n",
       "      <td>81</td>\n",
       "      <td>2</td>\n",
       "      <td>1095</td>\n",
       "      <td>12/28/2020 12:12:44</td>\n",
       "      <td>cogent communications</td>\n",
       "      <td>south central</td>\n",
       "      <td>texas</td>\n",
       "      <td>MOBL</td>\n",
       "      <td>...</td>\n",
       "      <td>UT</td>\n",
       "      <td>5/8/2020 10:27:6</td>\n",
       "      <td>1987-02-07 00:00:00</td>\n",
       "      <td>6/27/2021 11:12:44</td>\n",
       "      <td>6/27/2021</td>\n",
       "      <td>SCHPMT</td>\n",
       "      <td>P2P_COMMIT</td>\n",
       "      <td>P2P</td>\n",
       "      <td>6/27/2021</td>\n",
       "      <td>Fraud</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TRAN_AMT  ACCT_PRE_TRAN_AVAIL_BAL  CUST_AGE  OPEN_ACCT_CT  WF_dvc_age  \\\n",
       "0      5.38                 23619.91        47             4        2777   \n",
       "1     65.19                     0.00        45             5        2721   \n",
       "2     54.84                 34570.63        36             8        1531   \n",
       "3      0.01                     0.00        62             3         835   \n",
       "4    497.08                 12725.18        81             2        1095   \n",
       "\n",
       "           PWD_UPDT_TS                CARR_NAME       RGN_NAME  \\\n",
       "0    1/16/2018 11:3:58  cox communications inc.      southwest   \n",
       "1                  NaN   charter communications      southwest   \n",
       "2  12/22/2021 10:42:51       utah broadband llc       mountain   \n",
       "3     2/8/2020 7:28:31       t-mobile usa  inc.      southwest   \n",
       "4  12/28/2020 12:12:44    cogent communications  south central   \n",
       "\n",
       "  STATE_PRVNC_TXT ALERT_TRGR_CD  ... CUST_STATE      PH_NUM_UPDT_TS  \\\n",
       "0          nevada          MOBL  ...         NV  2/24/2021 15:55:10   \n",
       "1      california          MOBL  ...         CA                 NaN   \n",
       "2            utah          ONLN  ...         MD     5/5/2019 1:8:39   \n",
       "3      california          MOBL  ...         NV   2/16/2019 6:45:37   \n",
       "4           texas          MOBL  ...         UT    5/8/2020 10:27:6   \n",
       "\n",
       "         CUST_SINCE_DT             TRAN_TS    TRAN_DT ACTN_CD ACTN_INTNL_TXT  \\\n",
       "0  1993-01-06 00:00:00    5/3/2021 18:3:58   5/3/2021  SCHPMT     P2P_COMMIT   \n",
       "1  1971-01-07 00:00:00  1/13/2021 19:19:37  1/13/2021  SCHPMT     P2P_COMMIT   \n",
       "2  1994-02-01 00:00:00    4/8/2021 9:42:51   4/8/2021  SCHPMT     P2P_COMMIT   \n",
       "3  2001-11-01 00:00:00  8/10/2021 15:28:31  8/10/2021  SCHPMT     P2P_COMMIT   \n",
       "4  1987-02-07 00:00:00  6/27/2021 11:12:44  6/27/2021  SCHPMT     P2P_COMMIT   \n",
       "\n",
       "  TRAN_TYPE_CD   ACTVY_DT FRAUD_NONFRAUD  \n",
       "0          P2P   5/3/2021      Non-Fraud  \n",
       "1          P2P  1/13/2021      Non-Fraud  \n",
       "2          P2P   4/8/2021          Fraud  \n",
       "3          P2P  8/10/2021      Non-Fraud  \n",
       "4          P2P  6/27/2021          Fraud  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Loading\n",
    "testDf = pd.read_csv(\"WFTest.csv\")\n",
    "trainDf = pd.read_csv(\"WFTrain.csv\")\n",
    "trainDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bc751abf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.380000e+00, 2.361991e+04, 4.700000e+01, ..., 1.000000e+00,\n",
       "        1.000000e+00, 1.000000e+00],\n",
       "       [6.519000e+01, 0.000000e+00, 4.500000e+01, ..., 1.000000e+00,\n",
       "        1.000000e+00, 1.000000e+00],\n",
       "       [5.484000e+01, 3.457063e+04, 3.600000e+01, ..., 1.000000e+00,\n",
       "        1.000000e+00, 1.000000e+00],\n",
       "       ...,\n",
       "       [4.930000e+02, 2.848630e+03, 5.400000e+01, ..., 1.000000e+00,\n",
       "        1.000000e+00, 1.000000e+00],\n",
       "       [4.916400e+02, 3.163250e+03, 2.100000e+01, ..., 1.000000e+00,\n",
       "        1.000000e+00, 1.000000e+00],\n",
       "       [6.020000e+00, 0.000000e+00, 6.000000e+01, ..., 1.000000e+00,\n",
       "        1.000000e+00, 1.000000e+00]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting up the Features\n",
    "numerical = ['TRAN_AMT', 'ACCT_PRE_TRAN_AVAIL_BAL','CUST_AGE',\n",
    "             'OPEN_ACCT_CT', 'WF_dvc_age', 'CUST_ZIP']\n",
    "categorical = ['CARR_NAME', 'RGN_NAME', 'STATE_PRVNC_TXT', 'ALERT_TRGR_CD',\n",
    "                  'DVC_TYPE_TXT', 'AUTHC_PRIM_TYPE_CD', 'AUTHC_SCNDRY_STAT_TXT',\n",
    "                  'CUST_STATE','ACTN_CD','ACTN_INTNL_TXT','TRAN_TYPE_CD']\n",
    "X_cat = pd.get_dummies(trainDf[categorical])\n",
    "X_num = trainDf[numerical]\n",
    "X = pd.concat([X_num, X_cat], axis = 1)\n",
    "X_mean_imputed = X.fillna(X.mean())\n",
    "X_mean_imputed_numpy = X_mean_imputed.to_numpy()\n",
    "X_mean_imputed_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fd4a3dab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the Y values\n",
    "Y = trainDf[\"FRAUD_NONFRAUD\"]\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "encoded_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8baac8ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000e-02, 0.00000e+00, 2.10000e+01, ..., 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00],\n",
       "       [1.00000e-02, 1.01590e+03, 2.90000e+01, ..., 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00],\n",
       "       [1.00000e-02, 0.00000e+00, 4.20000e+01, ..., 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00],\n",
       "       ...,\n",
       "       [4.62700e+01, 0.00000e+00, 4.90000e+01, ..., 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00],\n",
       "       [8.26600e+01, 1.84563e+03, 3.70000e+01, ..., 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00],\n",
       "       [8.70000e-01, 8.64068e+03, 7.40000e+01, ..., 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Need a validation set for this, Keras can wrap tabnet and do cv but not sure needed\n",
    "x_train, x_val, y_train, y_val = train_test_split(X_mean_imputed_numpy, encoded_Y, test_size=0.30, random_state=8)\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b64634cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cpu\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "5758",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3360\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3361\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 5758",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14056/460038987.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     )\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m unsupervised_model.fit(\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0meval_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pytorch_tabnet\\pretraining.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X_train, eval_set, eval_name, loss_fn, pretraining_ratio, weights, max_epochs, patience, batch_size, virtual_batch_size, num_workers, drop_last, callbacks, pin_memory)\u001b[0m\n\u001b[0;32m    147\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callback_container\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m             \u001b[1;31m# Apply predict epoch to all eval sets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pytorch_tabnet\\pretraining.py\u001b[0m in \u001b[0;36m_train_epoch\u001b[1;34m(self, train_loader)\u001b[0m\n\u001b[0;32m    270\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 272\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    273\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callback_container\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pytorch_tabnet\\utils.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3453\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3454\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3455\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3456\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3457\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3361\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3363\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3365\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 5758"
     ]
    }
   ],
   "source": [
    "# TabNetPretrainer\n",
    "unsupervised_model = TabNetPretrainer(\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=2e-2),\n",
    "    mask_type='entmax', # \"sparsemax\",\n",
    "    )\n",
    "\n",
    "unsupervised_model.fit(\n",
    "    x_train,\n",
    "    eval_set=[x_val],\n",
    "    max_epochs=500 , patience=50,\n",
    "    batch_size=128, virtual_batch_size=128,\n",
    "    num_workers=0,\n",
    "    drop_last=False,\n",
    "    pretraining_ratio=0.8,\n",
    ")\n",
    "\n",
    "# reconstructed_X, embedded_X = unsupervised_model_no_preproc.predict(x_val)\n",
    "# assert(reconstructed_X.shape==embedded_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "552571d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cpu\n",
      "epoch 0  | loss: 0.68956 | train_auc: 0.82448 | valid_auc: 0.82016 |  0:00:07s\n",
      "epoch 1  | loss: 0.48592 | train_auc: 0.90904 | valid_auc: 0.90531 |  0:00:14s\n",
      "epoch 2  | loss: 0.37208 | train_auc: 0.93199 | valid_auc: 0.92206 |  0:00:21s\n",
      "epoch 3  | loss: 0.34745 | train_auc: 0.94016 | valid_auc: 0.92585 |  0:00:30s\n",
      "epoch 4  | loss: 0.30701 | train_auc: 0.95145 | valid_auc: 0.93084 |  0:00:38s\n",
      "epoch 5  | loss: 0.29716 | train_auc: 0.95504 | valid_auc: 0.9298  |  0:00:46s\n",
      "epoch 6  | loss: 0.29067 | train_auc: 0.95937 | valid_auc: 0.9312  |  0:00:54s\n",
      "epoch 7  | loss: 0.26654 | train_auc: 0.96023 | valid_auc: 0.93037 |  0:01:03s\n",
      "epoch 8  | loss: 0.25947 | train_auc: 0.96019 | valid_auc: 0.92944 |  0:01:11s\n",
      "epoch 9  | loss: 0.27088 | train_auc: 0.9602  | valid_auc: 0.92631 |  0:01:20s\n",
      "epoch 10 | loss: 0.23549 | train_auc: 0.96398 | valid_auc: 0.92513 |  0:01:29s\n",
      "epoch 11 | loss: 0.22989 | train_auc: 0.9643  | valid_auc: 0.91942 |  0:01:38s\n",
      "epoch 12 | loss: 0.22516 | train_auc: 0.96683 | valid_auc: 0.92452 |  0:01:48s\n",
      "epoch 13 | loss: 0.21899 | train_auc: 0.96857 | valid_auc: 0.92836 |  0:01:57s\n",
      "epoch 14 | loss: 0.21909 | train_auc: 0.96916 | valid_auc: 0.92665 |  0:02:05s\n",
      "epoch 15 | loss: 0.21276 | train_auc: 0.96982 | valid_auc: 0.92462 |  0:02:14s\n",
      "epoch 16 | loss: 0.20582 | train_auc: 0.96913 | valid_auc: 0.92136 |  0:02:22s\n",
      "epoch 17 | loss: 0.20224 | train_auc: 0.97311 | valid_auc: 0.92697 |  0:02:32s\n",
      "epoch 18 | loss: 0.20112 | train_auc: 0.97301 | valid_auc: 0.92062 |  0:02:41s\n",
      "epoch 19 | loss: 0.18379 | train_auc: 0.97386 | valid_auc: 0.92392 |  0:02:49s\n",
      "epoch 20 | loss: 0.20005 | train_auc: 0.97237 | valid_auc: 0.91991 |  0:02:58s\n",
      "epoch 21 | loss: 0.18563 | train_auc: 0.96995 | valid_auc: 0.92037 |  0:03:06s\n",
      "epoch 22 | loss: 0.18779 | train_auc: 0.96583 | valid_auc: 0.90797 |  0:03:14s\n",
      "epoch 23 | loss: 0.18209 | train_auc: 0.96935 | valid_auc: 0.91818 |  0:03:22s\n",
      "epoch 24 | loss: 0.1683  | train_auc: 0.97326 | valid_auc: 0.91576 |  0:03:32s\n",
      "epoch 25 | loss: 0.1883  | train_auc: 0.97656 | valid_auc: 0.91476 |  0:03:41s\n",
      "epoch 26 | loss: 0.15827 | train_auc: 0.97812 | valid_auc: 0.91787 |  0:03:49s\n",
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 6 and best_valid_auc = 0.9312\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    }
   ],
   "source": [
    "clf = TabNetClassifier(\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=2e-2),\n",
    "    scheduler_params={\"step_size\":10, # how to use learning rate scheduler\n",
    "                      \"gamma\":0.9},\n",
    "    scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "    mask_type='sparsemax' # This will be overwritten if using pretrain model\n",
    ")\n",
    "\n",
    "clf.fit(\n",
    "    X_train= x_train, y_train=y_train,\n",
    "    eval_set=[(x_train, y_train), (x_val, y_val)],\n",
    "    eval_name=['train', 'valid'],\n",
    "    eval_metric=['auc'],\n",
    "    max_epochs=500 , patience=20,\n",
    "    batch_size=124, virtual_batch_size=128,\n",
    "    num_workers=0,\n",
    "    weights=1,\n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "72a3a216",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5278569c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val_pred = clf.predict_proba(x_val)[:, 1]\n",
    "x_val_pred_label = x_val_pred > 0.5\n",
    "x_val_pred_label = x_val_pred_label.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8f36edb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val_pred_label_df = pd.DataFrame(x_val_pred_label)\n",
    "y_val_df = pd.DataFrame(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5dade256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: 87.41%\n"
     ]
    }
   ],
   "source": [
    "f1s = f1_score(y_val_df, x_val_pred_label_df)\n",
    "print(\"Baseline: %.2f%%\" % (f1s*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
