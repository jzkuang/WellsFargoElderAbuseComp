{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d122c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regular Importing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34c12563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: absl-py~=0.10 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (0.14.1)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (0.37.0)\n",
      "Requirement already satisfied: numpy~=1.19.2 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (1.19.5)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (3.18.1)\n",
      "Requirement already satisfied: keras~=2.6 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: h5py~=3.1.0 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.37.0 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (1.41.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: gast==0.4.0 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: clang~=5.0 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (5.0)\n",
      "Requirement already satisfied: tensorboard~=2.6 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: tensorflow-estimator~=2.6 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (1.35.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (49.2.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.26.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2021.5.30)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.26.6)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: keras in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.6.0)\n"
     ]
    }
   ],
   "source": [
    "# Keras Importing\n",
    "!pip install tensorflow\n",
    "!pip install keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7229a9a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: missingno in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.5.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from missingno) (1.19.5)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from missingno) (3.4.3)\n",
      "Requirement already satisfied: seaborn in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from missingno) (0.11.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from missingno) (1.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->missingno) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->missingno) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->missingno) (0.10.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->missingno) (8.3.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->missingno) (1.3.2)\n",
      "Requirement already satisfied: six in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from cycler>=0.10->matplotlib->missingno) (1.15.0)\n",
      "Requirement already satisfied: pandas>=0.23 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from seaborn->missingno) (1.3.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas>=0.23->seaborn->missingno) (2021.1)\n"
     ]
    }
   ],
   "source": [
    "# Importing for seeing the missing Data\n",
    "!pip install missingno\n",
    "import missingno as msno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ff033d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRAN_AMT</th>\n",
       "      <th>ACCT_PRE_TRAN_AVAIL_BAL</th>\n",
       "      <th>CUST_AGE</th>\n",
       "      <th>OPEN_ACCT_CT</th>\n",
       "      <th>WF_dvc_age</th>\n",
       "      <th>PWD_UPDT_TS</th>\n",
       "      <th>CARR_NAME</th>\n",
       "      <th>RGN_NAME</th>\n",
       "      <th>STATE_PRVNC_TXT</th>\n",
       "      <th>ALERT_TRGR_CD</th>\n",
       "      <th>...</th>\n",
       "      <th>CUST_STATE</th>\n",
       "      <th>PH_NUM_UPDT_TS</th>\n",
       "      <th>CUST_SINCE_DT</th>\n",
       "      <th>TRAN_TS</th>\n",
       "      <th>TRAN_DT</th>\n",
       "      <th>ACTN_CD</th>\n",
       "      <th>ACTN_INTNL_TXT</th>\n",
       "      <th>TRAN_TYPE_CD</th>\n",
       "      <th>ACTVY_DT</th>\n",
       "      <th>FRAUD_NONFRAUD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.38</td>\n",
       "      <td>23619.91</td>\n",
       "      <td>47</td>\n",
       "      <td>4</td>\n",
       "      <td>2777</td>\n",
       "      <td>1/16/2018 11:3:58</td>\n",
       "      <td>cox communications inc.</td>\n",
       "      <td>southwest</td>\n",
       "      <td>nevada</td>\n",
       "      <td>MOBL</td>\n",
       "      <td>...</td>\n",
       "      <td>NV</td>\n",
       "      <td>2/24/2021 15:55:10</td>\n",
       "      <td>1993-01-06 00:00:00</td>\n",
       "      <td>5/3/2021 18:3:58</td>\n",
       "      <td>5/3/2021</td>\n",
       "      <td>SCHPMT</td>\n",
       "      <td>P2P_COMMIT</td>\n",
       "      <td>P2P</td>\n",
       "      <td>5/3/2021</td>\n",
       "      <td>Non-Fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>45</td>\n",
       "      <td>5</td>\n",
       "      <td>2721</td>\n",
       "      <td>NaN</td>\n",
       "      <td>charter communications</td>\n",
       "      <td>southwest</td>\n",
       "      <td>california</td>\n",
       "      <td>MOBL</td>\n",
       "      <td>...</td>\n",
       "      <td>CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1971-01-07 00:00:00</td>\n",
       "      <td>1/13/2021 19:19:37</td>\n",
       "      <td>1/13/2021</td>\n",
       "      <td>SCHPMT</td>\n",
       "      <td>P2P_COMMIT</td>\n",
       "      <td>P2P</td>\n",
       "      <td>1/13/2021</td>\n",
       "      <td>Non-Fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54.84</td>\n",
       "      <td>34570.63</td>\n",
       "      <td>36</td>\n",
       "      <td>8</td>\n",
       "      <td>1531</td>\n",
       "      <td>12/22/2021 10:42:51</td>\n",
       "      <td>utah broadband llc</td>\n",
       "      <td>mountain</td>\n",
       "      <td>utah</td>\n",
       "      <td>ONLN</td>\n",
       "      <td>...</td>\n",
       "      <td>MD</td>\n",
       "      <td>5/5/2019 1:8:39</td>\n",
       "      <td>1994-02-01 00:00:00</td>\n",
       "      <td>4/8/2021 9:42:51</td>\n",
       "      <td>4/8/2021</td>\n",
       "      <td>SCHPMT</td>\n",
       "      <td>P2P_COMMIT</td>\n",
       "      <td>P2P</td>\n",
       "      <td>4/8/2021</td>\n",
       "      <td>Fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "      <td>835</td>\n",
       "      <td>2/8/2020 7:28:31</td>\n",
       "      <td>t-mobile usa  inc.</td>\n",
       "      <td>southwest</td>\n",
       "      <td>california</td>\n",
       "      <td>MOBL</td>\n",
       "      <td>...</td>\n",
       "      <td>NV</td>\n",
       "      <td>2/16/2019 6:45:37</td>\n",
       "      <td>2001-11-01 00:00:00</td>\n",
       "      <td>8/10/2021 15:28:31</td>\n",
       "      <td>8/10/2021</td>\n",
       "      <td>SCHPMT</td>\n",
       "      <td>P2P_COMMIT</td>\n",
       "      <td>P2P</td>\n",
       "      <td>8/10/2021</td>\n",
       "      <td>Non-Fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>497.08</td>\n",
       "      <td>12725.18</td>\n",
       "      <td>81</td>\n",
       "      <td>2</td>\n",
       "      <td>1095</td>\n",
       "      <td>12/28/2020 12:12:44</td>\n",
       "      <td>cogent communications</td>\n",
       "      <td>south central</td>\n",
       "      <td>texas</td>\n",
       "      <td>MOBL</td>\n",
       "      <td>...</td>\n",
       "      <td>UT</td>\n",
       "      <td>5/8/2020 10:27:6</td>\n",
       "      <td>1987-02-07 00:00:00</td>\n",
       "      <td>6/27/2021 11:12:44</td>\n",
       "      <td>6/27/2021</td>\n",
       "      <td>SCHPMT</td>\n",
       "      <td>P2P_COMMIT</td>\n",
       "      <td>P2P</td>\n",
       "      <td>6/27/2021</td>\n",
       "      <td>Fraud</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TRAN_AMT  ACCT_PRE_TRAN_AVAIL_BAL  CUST_AGE  OPEN_ACCT_CT  WF_dvc_age  \\\n",
       "0      5.38                 23619.91        47             4        2777   \n",
       "1     65.19                     0.00        45             5        2721   \n",
       "2     54.84                 34570.63        36             8        1531   \n",
       "3      0.01                     0.00        62             3         835   \n",
       "4    497.08                 12725.18        81             2        1095   \n",
       "\n",
       "           PWD_UPDT_TS                CARR_NAME       RGN_NAME  \\\n",
       "0    1/16/2018 11:3:58  cox communications inc.      southwest   \n",
       "1                  NaN   charter communications      southwest   \n",
       "2  12/22/2021 10:42:51       utah broadband llc       mountain   \n",
       "3     2/8/2020 7:28:31       t-mobile usa  inc.      southwest   \n",
       "4  12/28/2020 12:12:44    cogent communications  south central   \n",
       "\n",
       "  STATE_PRVNC_TXT ALERT_TRGR_CD  ... CUST_STATE      PH_NUM_UPDT_TS  \\\n",
       "0          nevada          MOBL  ...         NV  2/24/2021 15:55:10   \n",
       "1      california          MOBL  ...         CA                 NaN   \n",
       "2            utah          ONLN  ...         MD     5/5/2019 1:8:39   \n",
       "3      california          MOBL  ...         NV   2/16/2019 6:45:37   \n",
       "4           texas          MOBL  ...         UT    5/8/2020 10:27:6   \n",
       "\n",
       "         CUST_SINCE_DT             TRAN_TS    TRAN_DT ACTN_CD ACTN_INTNL_TXT  \\\n",
       "0  1993-01-06 00:00:00    5/3/2021 18:3:58   5/3/2021  SCHPMT     P2P_COMMIT   \n",
       "1  1971-01-07 00:00:00  1/13/2021 19:19:37  1/13/2021  SCHPMT     P2P_COMMIT   \n",
       "2  1994-02-01 00:00:00    4/8/2021 9:42:51   4/8/2021  SCHPMT     P2P_COMMIT   \n",
       "3  2001-11-01 00:00:00  8/10/2021 15:28:31  8/10/2021  SCHPMT     P2P_COMMIT   \n",
       "4  1987-02-07 00:00:00  6/27/2021 11:12:44  6/27/2021  SCHPMT     P2P_COMMIT   \n",
       "\n",
       "  TRAN_TYPE_CD   ACTVY_DT FRAUD_NONFRAUD  \n",
       "0          P2P   5/3/2021      Non-Fraud  \n",
       "1          P2P  1/13/2021      Non-Fraud  \n",
       "2          P2P   4/8/2021          Fraud  \n",
       "3          P2P  8/10/2021      Non-Fraud  \n",
       "4          P2P  6/27/2021          Fraud  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Loading\n",
    "testDf = pd.read_csv(\"WFTest.csv\")\n",
    "trainDf = pd.read_csv(\"WFTrain.csv\")\n",
    "trainDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "429cf18e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRAN_AMT</th>\n",
       "      <th>ACCT_PRE_TRAN_AVAIL_BAL</th>\n",
       "      <th>CUST_AGE</th>\n",
       "      <th>OPEN_ACCT_CT</th>\n",
       "      <th>WF_dvc_age</th>\n",
       "      <th>CUST_ZIP</th>\n",
       "      <th>CARR_NAME_24 shells</th>\n",
       "      <th>CARR_NAME_3ds communications llc</th>\n",
       "      <th>CARR_NAME_432 internet  llc</th>\n",
       "      <th>CARR_NAME_702 communications</th>\n",
       "      <th>...</th>\n",
       "      <th>CUST_STATE_TX</th>\n",
       "      <th>CUST_STATE_UT</th>\n",
       "      <th>CUST_STATE_VA</th>\n",
       "      <th>CUST_STATE_WA</th>\n",
       "      <th>CUST_STATE_WI</th>\n",
       "      <th>CUST_STATE_WV</th>\n",
       "      <th>CUST_STATE_WY</th>\n",
       "      <th>ACTN_CD_SCHPMT</th>\n",
       "      <th>ACTN_INTNL_TXT_P2P_COMMIT</th>\n",
       "      <th>TRAN_TYPE_CD_P2P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.38</td>\n",
       "      <td>23619.91</td>\n",
       "      <td>47.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2777.0</td>\n",
       "      <td>89002.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>45.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2721.0</td>\n",
       "      <td>94541.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54.84</td>\n",
       "      <td>34570.63</td>\n",
       "      <td>36.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1531.0</td>\n",
       "      <td>21811.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>62.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>835.0</td>\n",
       "      <td>89822.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>497.08</td>\n",
       "      <td>12725.18</td>\n",
       "      <td>81.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1095.0</td>\n",
       "      <td>84108.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13995</th>\n",
       "      <td>1937.21</td>\n",
       "      <td>230.75</td>\n",
       "      <td>55.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>92503.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13996</th>\n",
       "      <td>114.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>44.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>272.0</td>\n",
       "      <td>80478.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13997</th>\n",
       "      <td>493.00</td>\n",
       "      <td>2848.63</td>\n",
       "      <td>54.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>517.0</td>\n",
       "      <td>33579.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13998</th>\n",
       "      <td>491.64</td>\n",
       "      <td>3163.25</td>\n",
       "      <td>21.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91702.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13999</th>\n",
       "      <td>6.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>60.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>944.0</td>\n",
       "      <td>7407.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14000 rows × 771 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       TRAN_AMT  ACCT_PRE_TRAN_AVAIL_BAL  CUST_AGE  OPEN_ACCT_CT  WF_dvc_age  \\\n",
       "0          5.38                 23619.91      47.0           4.0      2777.0   \n",
       "1         65.19                     0.00      45.0           5.0      2721.0   \n",
       "2         54.84                 34570.63      36.0           8.0      1531.0   \n",
       "3          0.01                     0.00      62.0           3.0       835.0   \n",
       "4        497.08                 12725.18      81.0           2.0      1095.0   \n",
       "...         ...                      ...       ...           ...         ...   \n",
       "13995   1937.21                   230.75      55.0           4.0       142.0   \n",
       "13996    114.38                     0.00      44.0          10.0       272.0   \n",
       "13997    493.00                  2848.63      54.0           3.0       517.0   \n",
       "13998    491.64                  3163.25      21.0           3.0         0.0   \n",
       "13999      6.02                     0.00      60.0           6.0       944.0   \n",
       "\n",
       "       CUST_ZIP  CARR_NAME_24 shells  CARR_NAME_3ds communications llc  \\\n",
       "0       89002.0                    0                                 0   \n",
       "1       94541.0                    0                                 0   \n",
       "2       21811.0                    0                                 0   \n",
       "3       89822.0                    0                                 0   \n",
       "4       84108.0                    0                                 0   \n",
       "...         ...                  ...                               ...   \n",
       "13995   92503.0                    0                                 0   \n",
       "13996   80478.0                    0                                 0   \n",
       "13997   33579.0                    0                                 0   \n",
       "13998   91702.0                    0                                 0   \n",
       "13999    7407.0                    0                                 0   \n",
       "\n",
       "       CARR_NAME_432 internet  llc  CARR_NAME_702 communications  ...  \\\n",
       "0                                0                             0  ...   \n",
       "1                                0                             0  ...   \n",
       "2                                0                             0  ...   \n",
       "3                                0                             0  ...   \n",
       "4                                0                             0  ...   \n",
       "...                            ...                           ...  ...   \n",
       "13995                            0                             0  ...   \n",
       "13996                            0                             0  ...   \n",
       "13997                            0                             0  ...   \n",
       "13998                            0                             0  ...   \n",
       "13999                            0                             0  ...   \n",
       "\n",
       "       CUST_STATE_TX  CUST_STATE_UT  CUST_STATE_VA  CUST_STATE_WA  \\\n",
       "0                  0              0              0              0   \n",
       "1                  0              0              0              0   \n",
       "2                  0              0              0              0   \n",
       "3                  0              0              0              0   \n",
       "4                  0              1              0              0   \n",
       "...              ...            ...            ...            ...   \n",
       "13995              0              0              0              0   \n",
       "13996              0              0              0              0   \n",
       "13997              0              0              0              0   \n",
       "13998              0              0              0              0   \n",
       "13999              0              0              0              0   \n",
       "\n",
       "       CUST_STATE_WI  CUST_STATE_WV  CUST_STATE_WY  ACTN_CD_SCHPMT  \\\n",
       "0                  0              0              0               1   \n",
       "1                  0              0              0               1   \n",
       "2                  0              0              0               1   \n",
       "3                  0              0              0               1   \n",
       "4                  0              0              0               1   \n",
       "...              ...            ...            ...             ...   \n",
       "13995              0              0              0               1   \n",
       "13996              0              0              0               1   \n",
       "13997              0              0              0               1   \n",
       "13998              0              0              0               1   \n",
       "13999              0              0              0               1   \n",
       "\n",
       "       ACTN_INTNL_TXT_P2P_COMMIT  TRAN_TYPE_CD_P2P  \n",
       "0                              1                 1  \n",
       "1                              1                 1  \n",
       "2                              1                 1  \n",
       "3                              1                 1  \n",
       "4                              1                 1  \n",
       "...                          ...               ...  \n",
       "13995                          1                 1  \n",
       "13996                          1                 1  \n",
       "13997                          1                 1  \n",
       "13998                          1                 1  \n",
       "13999                          1                 1  \n",
       "\n",
       "[14000 rows x 771 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting up the Features\n",
    "numerical = ['TRAN_AMT', 'ACCT_PRE_TRAN_AVAIL_BAL','CUST_AGE',\n",
    "             'OPEN_ACCT_CT', 'WF_dvc_age', 'CUST_ZIP']\n",
    "categorical = ['CARR_NAME', 'RGN_NAME', 'STATE_PRVNC_TXT', 'ALERT_TRGR_CD',\n",
    "                  'DVC_TYPE_TXT', 'AUTHC_PRIM_TYPE_CD', 'AUTHC_SCNDRY_STAT_TXT',\n",
    "                  'CUST_STATE','ACTN_CD','ACTN_INTNL_TXT','TRAN_TYPE_CD']\n",
    "X_cat = pd.get_dummies(trainDf[categorical])\n",
    "X_num = trainDf[numerical].astype(float)\n",
    "X = pd.concat([X_num, X_cat], axis = 1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a608d18a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the Y values\n",
    "Y = trainDf[\"FRAUD_NONFRAUD\"]\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "encoded_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9fef138a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Metric\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "50dbbc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the baseline\n",
    "def create_base_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(350, input_dim= 771, activation='relu')) # 2 Layers Right Now\n",
    "    model.add(Dense(175, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c2c8302e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "88/88 [==============================] - 1s 4ms/step - loss: 201.1359 - accuracy: 0.6481\n",
      "Epoch 2/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 48.9683 - accuracy: 0.7004\n",
      "Epoch 3/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 29.3696 - accuracy: 0.7507\n",
      "Epoch 4/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 20.1089 - accuracy: 0.7611\n",
      "Epoch 5/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 30.1518 - accuracy: 0.7422\n",
      "Epoch 6/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 49.1889 - accuracy: 0.7292\n",
      "Epoch 7/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 25.2470 - accuracy: 0.7576\n",
      "Epoch 8/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 14.2615 - accuracy: 0.7830\n",
      "Epoch 9/50\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 29.0306 - accuracy: 0.7435\n",
      "Epoch 10/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 14.9381 - accuracy: 0.7668\n",
      "Epoch 11/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 12.8503 - accuracy: 0.7829\n",
      "Epoch 12/50\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 12.5475 - accuracy: 0.7812\n",
      "Epoch 13/50\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 13.5232 - accuracy: 0.7789\n",
      "Epoch 14/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 12.7398 - accuracy: 0.7680\n",
      "Epoch 15/50\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 11.0283 - accuracy: 0.7876\n",
      "Epoch 16/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 10.8052 - accuracy: 0.7943\n",
      "Epoch 17/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 11.6569 - accuracy: 0.7772\n",
      "Epoch 18/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 20.1838 - accuracy: 0.7691\n",
      "Epoch 19/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 7.3583 - accuracy: 0.8112\n",
      "Epoch 20/50\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 7.8717 - accuracy: 0.7993\n",
      "Epoch 21/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 8.4555 - accuracy: 0.7925\n",
      "Epoch 22/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 11.0810 - accuracy: 0.7815\n",
      "Epoch 23/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 10.0406 - accuracy: 0.7878\n",
      "Epoch 24/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 7.0876 - accuracy: 0.8059\n",
      "Epoch 25/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 12.0811 - accuracy: 0.7798\n",
      "Epoch 26/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 7.1625 - accuracy: 0.8121\n",
      "Epoch 27/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 6.5088 - accuracy: 0.8031\n",
      "Epoch 28/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 5.7902 - accuracy: 0.8153\n",
      "Epoch 29/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 8.8141 - accuracy: 0.7804\n",
      "Epoch 30/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 4.8097 - accuracy: 0.8173\n",
      "Epoch 31/50\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 5.0866 - accuracy: 0.8115\n",
      "Epoch 32/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 7.5217 - accuracy: 0.8011\n",
      "Epoch 33/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 4.4077 - accuracy: 0.8143\n",
      "Epoch 34/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 6.6535 - accuracy: 0.7941\n",
      "Epoch 35/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 6.1220 - accuracy: 0.8082\n",
      "Epoch 36/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 4.6853 - accuracy: 0.8171\n",
      "Epoch 37/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 5.0867 - accuracy: 0.8034\n",
      "Epoch 38/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 3.7874 - accuracy: 0.8242\n",
      "Epoch 39/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 4.7785 - accuracy: 0.8054\n",
      "Epoch 40/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 3.3461 - accuracy: 0.8197\n",
      "Epoch 41/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 4.5796 - accuracy: 0.8126\n",
      "Epoch 42/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 2.8598 - accuracy: 0.8267\n",
      "Epoch 43/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 4.6323 - accuracy: 0.8060\n",
      "Epoch 44/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 4.1828 - accuracy: 0.8085\n",
      "Epoch 45/50\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 3.9895 - accuracy: 0.8222\n",
      "Epoch 46/50\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 4.6456 - accuracy: 0.7952\n",
      "Epoch 47/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 3.7984 - accuracy: 0.8107\n",
      "Epoch 48/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 3.6863 - accuracy: 0.8221\n",
      "Epoch 49/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 3.9664 - accuracy: 0.8011\n",
      "Epoch 50/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 4.7022 - accuracy: 0.7915\n",
      "Epoch 1/50\n",
      "88/88 [==============================] - 1s 4ms/step - loss: 225.9821 - accuracy: 0.6440\n",
      "Epoch 2/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 37.9915 - accuracy: 0.7100\n",
      "Epoch 3/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 37.2400 - accuracy: 0.7296\n",
      "Epoch 4/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 19.8973 - accuracy: 0.7608\n",
      "Epoch 5/50\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 47.7247 - accuracy: 0.7208\n",
      "Epoch 6/50\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 25.1648 - accuracy: 0.7571\n",
      "Epoch 7/50\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 29.5214 - accuracy: 0.7401\n",
      "Epoch 8/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 14.0684 - accuracy: 0.7865\n",
      "Epoch 9/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 26.0275 - accuracy: 0.7518\n",
      "Epoch 10/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 15.4442 - accuracy: 0.7872\n",
      "Epoch 11/50\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 25.1357 - accuracy: 0.7605\n",
      "Epoch 12/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 14.4637 - accuracy: 0.7929\n",
      "Epoch 13/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 17.0114 - accuracy: 0.7763\n",
      "Epoch 14/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 11.6582 - accuracy: 0.7942\n",
      "Epoch 15/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 16.8210 - accuracy: 0.7761\n",
      "Epoch 16/50\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 28.6410 - accuracy: 0.7563\n",
      "Epoch 17/50\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 12.9477 - accuracy: 0.7968\n",
      "Epoch 18/50\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 12.2023 - accuracy: 0.7900\n",
      "Epoch 19/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 14.4462 - accuracy: 0.7834\n",
      "Epoch 20/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 10.2147 - accuracy: 0.7989\n",
      "Epoch 21/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 17.2913 - accuracy: 0.7707\n",
      "Epoch 22/50\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 10.2277 - accuracy: 0.8018\n",
      "Epoch 23/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 9.6407 - accuracy: 0.8036\n",
      "Epoch 24/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 9.7526 - accuracy: 0.7916\n",
      "Epoch 25/50\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 8.4754 - accuracy: 0.8065\n",
      "Epoch 26/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 9.7095 - accuracy: 0.7994\n",
      "Epoch 27/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 9.2003 - accuracy: 0.7999\n",
      "Epoch 28/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 8.3998 - accuracy: 0.8045\n",
      "Epoch 29/50\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 14.9112 - accuracy: 0.7831\n",
      "Epoch 30/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 9.3176 - accuracy: 0.7885\n",
      "Epoch 31/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 7.5698 - accuracy: 0.8040\n",
      "Epoch 32/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 7.8978 - accuracy: 0.8047\n",
      "Epoch 33/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 7.4226 - accuracy: 0.8045\n",
      "Epoch 34/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 5.9244 - accuracy: 0.8165\n",
      "Epoch 35/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 7.3575 - accuracy: 0.7933\n",
      "Epoch 36/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 5.9020 - accuracy: 0.8138\n",
      "Epoch 37/50\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 7.0811 - accuracy: 0.8056\n",
      "Epoch 38/50\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 4.6712 - accuracy: 0.8171\n",
      "Epoch 39/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 5.6389 - accuracy: 0.8078\n",
      "Epoch 40/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 5.8688 - accuracy: 0.8077\n",
      "Epoch 41/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 4.9163 - accuracy: 0.8096\n",
      "Epoch 42/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 4.5045 - accuracy: 0.8170\n",
      "Epoch 43/50\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 4.2042 - accuracy: 0.8150\n",
      "Epoch 44/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 4.2545 - accuracy: 0.8161\n",
      "Epoch 45/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 3.8819 - accuracy: 0.8243\n",
      "Epoch 46/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 3.4856 - accuracy: 0.8239\n",
      "Epoch 47/50\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 5.3325 - accuracy: 0.7938\n",
      "Epoch 48/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 3.9166 - accuracy: 0.8252\n",
      "Epoch 49/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 3.9776 - accuracy: 0.8249\n",
      "Epoch 50/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 4.6972 - accuracy: 0.8023\n",
      "Epoch 1/50\n",
      "88/88 [==============================] - 1s 4ms/step - loss: 232.5295 - accuracy: 0.6464\n",
      "Epoch 2/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 44.4634 - accuracy: 0.7021\n",
      "Epoch 3/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 52.6340 - accuracy: 0.7109\n",
      "Epoch 4/50\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 26.1217 - accuracy: 0.7619\n",
      "Epoch 5/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 36.4916 - accuracy: 0.7394\n",
      "Epoch 6/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 32.1439 - accuracy: 0.7467\n",
      "Epoch 7/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 35.8125 - accuracy: 0.7375\n",
      "Epoch 8/50\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 17.8426 - accuracy: 0.7695\n",
      "Epoch 9/50\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 15.9995 - accuracy: 0.7779\n",
      "Epoch 10/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 21.4168 - accuracy: 0.7622\n",
      "Epoch 11/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 20.2788 - accuracy: 0.7704\n",
      "Epoch 12/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 13.7206 - accuracy: 0.7897\n",
      "Epoch 13/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 14.8697 - accuracy: 0.7876\n",
      "Epoch 14/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 17.8214 - accuracy: 0.7809\n",
      "Epoch 15/50\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 20.6492 - accuracy: 0.7668\n",
      "Epoch 16/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 13.7782 - accuracy: 0.7777\n",
      "Epoch 17/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 10.0604 - accuracy: 0.7940\n",
      "Epoch 18/50\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 10.7624 - accuracy: 0.7876\n",
      "Epoch 19/50\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 8.6717 - accuracy: 0.8029\n",
      "Epoch 20/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 18.2071 - accuracy: 0.7735\n",
      "Epoch 21/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 8.8673 - accuracy: 0.7976\n",
      "Epoch 22/50\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 7.3037 - accuracy: 0.8113\n",
      "Epoch 23/50\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 7.2177 - accuracy: 0.8010\n",
      "Epoch 24/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 9.8622 - accuracy: 0.7874\n",
      "Epoch 25/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 7.9151 - accuracy: 0.8012\n",
      "Epoch 26/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 9.0389 - accuracy: 0.7921\n",
      "Epoch 27/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 9.7767 - accuracy: 0.7949\n",
      "Epoch 28/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 7.8755 - accuracy: 0.7985\n",
      "Epoch 29/50\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 9.7085 - accuracy: 0.7894\n",
      "Epoch 30/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 6.8099 - accuracy: 0.8037\n",
      "Epoch 31/50\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 10.0067 - accuracy: 0.7833\n",
      "Epoch 32/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 6.6523 - accuracy: 0.8066\n",
      "Epoch 33/50\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 5.4191 - accuracy: 0.8103\n",
      "Epoch 34/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 6.4502 - accuracy: 0.8004\n",
      "Epoch 35/50\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 8.7280 - accuracy: 0.7934\n",
      "Epoch 36/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 4.7289 - accuracy: 0.8184\n",
      "Epoch 37/50\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 5.2936 - accuracy: 0.8088\n",
      "Epoch 38/50\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 4.1233 - accuracy: 0.8214\n",
      "Epoch 39/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 3.6522 - accuracy: 0.8202\n",
      "Epoch 40/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 4.4181 - accuracy: 0.8102\n",
      "Epoch 41/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 5.0796 - accuracy: 0.7982\n",
      "Epoch 42/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 4.0929 - accuracy: 0.8133\n",
      "Epoch 43/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 5.1030 - accuracy: 0.8055\n",
      "Epoch 44/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 5.6047 - accuracy: 0.7933\n",
      "Epoch 45/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 5.4794 - accuracy: 0.8060\n",
      "Epoch 46/50\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 4.2671 - accuracy: 0.8100\n",
      "Epoch 47/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 3.3379 - accuracy: 0.8196\n",
      "Epoch 48/50\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 4.0087 - accuracy: 0.8112\n",
      "Epoch 49/50\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 3.8279 - accuracy: 0.8102\n",
      "Epoch 50/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 3.7112 - accuracy: 0.8145\n",
      "Epoch 1/50\n",
      "88/88 [==============================] - 1s 4ms/step - loss: 328.5654 - accuracy: 0.6131\n",
      "Epoch 2/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 39.5450 - accuracy: 0.7135\n",
      "Epoch 3/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 36.6354 - accuracy: 0.7215\n",
      "Epoch 4/50\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 40.6130 - accuracy: 0.7105\n",
      "Epoch 5/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 43.8598 - accuracy: 0.7305\n",
      "Epoch 6/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 42.9652 - accuracy: 0.7356\n",
      "Epoch 7/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 31.4893 - accuracy: 0.7456\n",
      "Epoch 8/50\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 32.4498 - accuracy: 0.7308\n",
      "Epoch 9/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 27.4177 - accuracy: 0.7461\n",
      "Epoch 10/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 39.5034 - accuracy: 0.7378\n",
      "Epoch 11/50\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 13.5801 - accuracy: 0.7879\n",
      "Epoch 12/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 15.2623 - accuracy: 0.7662\n",
      "Epoch 13/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 25.0153 - accuracy: 0.7503\n",
      "Epoch 14/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 21.4884 - accuracy: 0.7612\n",
      "Epoch 15/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 0s 4ms/step - loss: 13.4975 - accuracy: 0.7829\n",
      "Epoch 16/50\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 18.3658 - accuracy: 0.7557\n",
      "Epoch 17/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 13.8898 - accuracy: 0.7788\n",
      "Epoch 18/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 21.2357 - accuracy: 0.7693\n",
      "Epoch 19/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 13.8275 - accuracy: 0.7843\n",
      "Epoch 20/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 10.8673 - accuracy: 0.7817\n",
      "Epoch 21/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 11.0662 - accuracy: 0.7854\n",
      "Epoch 22/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 13.0013 - accuracy: 0.7710\n",
      "Epoch 23/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 6.6502 - accuracy: 0.8103\n",
      "Epoch 24/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 15.3886 - accuracy: 0.7796\n",
      "Epoch 25/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 8.4394 - accuracy: 0.7899\n",
      "Epoch 26/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 8.2755 - accuracy: 0.7963\n",
      "Epoch 27/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 11.0341 - accuracy: 0.7804\n",
      "Epoch 28/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 11.6047 - accuracy: 0.7799\n",
      "Epoch 29/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 10.5290 - accuracy: 0.7849\n",
      "Epoch 30/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 6.2307 - accuracy: 0.8146\n",
      "Epoch 31/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 7.5806 - accuracy: 0.7925\n",
      "Epoch 32/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 7.0702 - accuracy: 0.8098\n",
      "Epoch 33/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 8.7999 - accuracy: 0.7932\n",
      "Epoch 34/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 6.5253 - accuracy: 0.7949\n",
      "Epoch 35/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 7.1216 - accuracy: 0.7964\n",
      "Epoch 36/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 11.9048 - accuracy: 0.7869\n",
      "Epoch 37/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 9.6230 - accuracy: 0.7854\n",
      "Epoch 38/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 5.8635 - accuracy: 0.8077\n",
      "Epoch 39/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 9.4088 - accuracy: 0.7836\n",
      "Epoch 40/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 4.6134 - accuracy: 0.8091\n",
      "Epoch 41/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 4.3646 - accuracy: 0.8095\n",
      "Epoch 42/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 5.5709 - accuracy: 0.7991\n",
      "Epoch 43/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 6.7449 - accuracy: 0.7973\n",
      "Epoch 44/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 7.4454 - accuracy: 0.7945\n",
      "Epoch 45/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 6.5158 - accuracy: 0.7932\n",
      "Epoch 46/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 4.7686 - accuracy: 0.8132\n",
      "Epoch 47/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 4.0549 - accuracy: 0.8128\n",
      "Epoch 48/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 4.1021 - accuracy: 0.8138\n",
      "Epoch 49/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 4.8043 - accuracy: 0.8025\n",
      "Epoch 50/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 3.3871 - accuracy: 0.8147\n",
      "Epoch 1/50\n",
      "88/88 [==============================] - 1s 4ms/step - loss: 363.4981 - accuracy: 0.6374\n",
      "Epoch 2/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 33.6137 - accuracy: 0.7048\n",
      "Epoch 3/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 36.9791 - accuracy: 0.7279\n",
      "Epoch 4/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 32.9975 - accuracy: 0.7284\n",
      "Epoch 5/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 42.4278 - accuracy: 0.7288\n",
      "Epoch 6/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 30.1300 - accuracy: 0.7479\n",
      "Epoch 7/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 25.1330 - accuracy: 0.7613\n",
      "Epoch 8/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 20.5399 - accuracy: 0.7653\n",
      "Epoch 9/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 17.3421 - accuracy: 0.7682\n",
      "Epoch 10/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 26.0296 - accuracy: 0.7567\n",
      "Epoch 11/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 14.0992 - accuracy: 0.7872\n",
      "Epoch 12/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 15.9410 - accuracy: 0.7823\n",
      "Epoch 13/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 17.6519 - accuracy: 0.7817\n",
      "Epoch 14/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 15.9971 - accuracy: 0.7789\n",
      "Epoch 15/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 15.7752 - accuracy: 0.7754\n",
      "Epoch 16/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 13.6447 - accuracy: 0.7917\n",
      "Epoch 17/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 18.3904 - accuracy: 0.7771\n",
      "Epoch 18/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 12.2743 - accuracy: 0.7907\n",
      "Epoch 19/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 11.5700 - accuracy: 0.7901\n",
      "Epoch 20/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 9.4999 - accuracy: 0.7968\n",
      "Epoch 21/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 11.0596 - accuracy: 0.7856\n",
      "Epoch 22/50\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 18.1993 - accuracy: 0.7753\n",
      "Epoch 23/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 14.7479 - accuracy: 0.7776\n",
      "Epoch 24/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 10.9574 - accuracy: 0.7931\n",
      "Epoch 25/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 7.4876 - accuracy: 0.8077\n",
      "Epoch 26/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 8.5238 - accuracy: 0.8037\n",
      "Epoch 27/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 11.8029 - accuracy: 0.7821\n",
      "Epoch 28/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 8.7949 - accuracy: 0.7971\n",
      "Epoch 29/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 9.6660 - accuracy: 0.7906\n",
      "Epoch 30/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 5.3932 - accuracy: 0.8179\n",
      "Epoch 31/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 9.2873 - accuracy: 0.7956\n",
      "Epoch 32/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 5.1206 - accuracy: 0.8139\n",
      "Epoch 33/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 6.7420 - accuracy: 0.8108\n",
      "Epoch 34/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 5.6368 - accuracy: 0.8160\n",
      "Epoch 35/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 9.3999 - accuracy: 0.7940\n",
      "Epoch 36/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 6.8474 - accuracy: 0.8115\n",
      "Epoch 37/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 5.2180 - accuracy: 0.8194\n",
      "Epoch 38/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 6.3282 - accuracy: 0.8023\n",
      "Epoch 39/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 7.0714 - accuracy: 0.8024\n",
      "Epoch 40/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 4.6874 - accuracy: 0.8179\n",
      "Epoch 41/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 5.5239 - accuracy: 0.8190\n",
      "Epoch 42/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 4.3833 - accuracy: 0.8202\n",
      "Epoch 43/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 4.2088 - accuracy: 0.8240\n",
      "Epoch 44/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 5.1173 - accuracy: 0.8192\n",
      "Epoch 45/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 3.7806 - accuracy: 0.8177\n",
      "Epoch 46/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 3.7597 - accuracy: 0.8262\n",
      "Epoch 47/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 6.9503 - accuracy: 0.7811\n",
      "Epoch 48/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 4.4673 - accuracy: 0.8201\n",
      "Epoch 49/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 3.0547 - accuracy: 0.8291\n",
      "Epoch 50/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 3.2183 - accuracy: 0.8287\n",
      "Baseline: 88.36% (3.02%)\n"
     ]
    }
   ],
   "source": [
    "estimator = KerasClassifier(build_fn=create_base_model, epochs= 50, batch_size= 128, verbose=0)\n",
    "kfold = StratifiedKFold(n_splits= 5, shuffle=True)\n",
    "results = cross_val_score(estimator, X, encoded_Y, cv=kfold, \n",
    "                             scoring= make_scorer(f1_score, pos_label = 1, labels=[1, 0]))\n",
    "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47f6e3e",
   "metadata": {},
   "source": [
    "So, we get a baseline of ~90% just by training Keras on the default features. There's quite a lot of them, so this doesn't seem really optimal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bef1dd",
   "metadata": {},
   "source": [
    "## Let's Try Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53fc9983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRAN_AMT</th>\n",
       "      <th>ACCT_PRE_TRAN_AVAIL_BAL</th>\n",
       "      <th>CUST_AGE</th>\n",
       "      <th>OPEN_ACCT_CT</th>\n",
       "      <th>WF_dvc_age</th>\n",
       "      <th>PWD_UPDT_TS</th>\n",
       "      <th>CARR_NAME</th>\n",
       "      <th>RGN_NAME</th>\n",
       "      <th>STATE_PRVNC_TXT</th>\n",
       "      <th>ALERT_TRGR_CD</th>\n",
       "      <th>DVC_TYPE_TXT</th>\n",
       "      <th>AUTHC_PRIM_TYPE_CD</th>\n",
       "      <th>AUTHC_SCNDRY_STAT_TXT</th>\n",
       "      <th>CUST_ZIP</th>\n",
       "      <th>CUST_STATE</th>\n",
       "      <th>PH_NUM_UPDT_TS</th>\n",
       "      <th>CUST_SINCE_DT</th>\n",
       "      <th>TRAN_TS</th>\n",
       "      <th>TRAN_DT</th>\n",
       "      <th>FRAUD_NONFRAUD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.38</td>\n",
       "      <td>23619.91</td>\n",
       "      <td>47</td>\n",
       "      <td>4</td>\n",
       "      <td>2777</td>\n",
       "      <td>2018-01-16 11:03:58</td>\n",
       "      <td>cox communications inc.</td>\n",
       "      <td>southwest</td>\n",
       "      <td>nevada</td>\n",
       "      <td>MOBL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UN_PWD</td>\n",
       "      <td>ALLOW</td>\n",
       "      <td>89002</td>\n",
       "      <td>NV</td>\n",
       "      <td>2021-02-24 15:55:10</td>\n",
       "      <td>1993-01-06</td>\n",
       "      <td>2021-05-03 18:03:58</td>\n",
       "      <td>2021-05-03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>45</td>\n",
       "      <td>5</td>\n",
       "      <td>2721</td>\n",
       "      <td>NaT</td>\n",
       "      <td>charter communications</td>\n",
       "      <td>southwest</td>\n",
       "      <td>california</td>\n",
       "      <td>MOBL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FACE_ID</td>\n",
       "      <td>ALLOW</td>\n",
       "      <td>94541</td>\n",
       "      <td>CA</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1971-01-07</td>\n",
       "      <td>2021-01-13 19:19:37</td>\n",
       "      <td>2021-01-13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54.84</td>\n",
       "      <td>34570.63</td>\n",
       "      <td>36</td>\n",
       "      <td>8</td>\n",
       "      <td>1531</td>\n",
       "      <td>2021-12-22 10:42:51</td>\n",
       "      <td>utah broadband llc</td>\n",
       "      <td>mountain</td>\n",
       "      <td>utah</td>\n",
       "      <td>ONLN</td>\n",
       "      <td>DESKTOP</td>\n",
       "      <td>UN_PWD</td>\n",
       "      <td>ALLOW</td>\n",
       "      <td>21811</td>\n",
       "      <td>MD</td>\n",
       "      <td>2019-05-05 01:08:39</td>\n",
       "      <td>1994-02-01</td>\n",
       "      <td>2021-04-08 09:42:51</td>\n",
       "      <td>2021-04-08</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "      <td>835</td>\n",
       "      <td>2020-02-08 07:28:31</td>\n",
       "      <td>t-mobile usa  inc.</td>\n",
       "      <td>southwest</td>\n",
       "      <td>california</td>\n",
       "      <td>MOBL</td>\n",
       "      <td>MOBILE</td>\n",
       "      <td>UN_PWD</td>\n",
       "      <td>ALLOW</td>\n",
       "      <td>89822</td>\n",
       "      <td>NV</td>\n",
       "      <td>2019-02-16 06:45:37</td>\n",
       "      <td>2001-11-01</td>\n",
       "      <td>2021-08-10 15:28:31</td>\n",
       "      <td>2021-08-10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>497.08</td>\n",
       "      <td>12725.18</td>\n",
       "      <td>81</td>\n",
       "      <td>2</td>\n",
       "      <td>1095</td>\n",
       "      <td>2020-12-28 12:12:44</td>\n",
       "      <td>cogent communications</td>\n",
       "      <td>south central</td>\n",
       "      <td>texas</td>\n",
       "      <td>MOBL</td>\n",
       "      <td>MOBILE</td>\n",
       "      <td>UN_PWD</td>\n",
       "      <td>CHALLENGE_SUCCESS</td>\n",
       "      <td>84108</td>\n",
       "      <td>UT</td>\n",
       "      <td>2020-05-08 10:27:06</td>\n",
       "      <td>1987-02-07</td>\n",
       "      <td>2021-06-27 11:12:44</td>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13995</th>\n",
       "      <td>1937.21</td>\n",
       "      <td>230.75</td>\n",
       "      <td>55</td>\n",
       "      <td>4</td>\n",
       "      <td>142</td>\n",
       "      <td>NaT</td>\n",
       "      <td>cellco partnership dba verizon wireless</td>\n",
       "      <td>southwest</td>\n",
       "      <td>california</td>\n",
       "      <td>MOBL</td>\n",
       "      <td>MOBILE</td>\n",
       "      <td>UN_PWD</td>\n",
       "      <td>ALLOW</td>\n",
       "      <td>92503</td>\n",
       "      <td>CA</td>\n",
       "      <td>2017-07-15 06:58:59</td>\n",
       "      <td>2001-06-05</td>\n",
       "      <td>2021-03-12 12:11:59</td>\n",
       "      <td>2021-03-12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13996</th>\n",
       "      <td>114.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>44</td>\n",
       "      <td>10</td>\n",
       "      <td>272</td>\n",
       "      <td>2017-11-02 04:28:20</td>\n",
       "      <td>t-mobile usa  inc.</td>\n",
       "      <td>southwest</td>\n",
       "      <td>california</td>\n",
       "      <td>MOBL</td>\n",
       "      <td>MOBILE</td>\n",
       "      <td>FACE_ID</td>\n",
       "      <td>ALLOW</td>\n",
       "      <td>80478</td>\n",
       "      <td>CO</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2010-06-03</td>\n",
       "      <td>2021-06-11 09:28:20</td>\n",
       "      <td>2021-06-11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13997</th>\n",
       "      <td>493.00</td>\n",
       "      <td>2848.63</td>\n",
       "      <td>54</td>\n",
       "      <td>3</td>\n",
       "      <td>517</td>\n",
       "      <td>2021-06-03 19:31:15</td>\n",
       "      <td>att services inc</td>\n",
       "      <td>southwest</td>\n",
       "      <td>california</td>\n",
       "      <td>MOBL</td>\n",
       "      <td>DESKTOP</td>\n",
       "      <td>UN_PWD</td>\n",
       "      <td>ALLOW</td>\n",
       "      <td>33579</td>\n",
       "      <td>FL</td>\n",
       "      <td>2021-05-25 08:50:05</td>\n",
       "      <td>1984-10-27</td>\n",
       "      <td>2021-05-16 12:31:15</td>\n",
       "      <td>2021-05-16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13998</th>\n",
       "      <td>491.64</td>\n",
       "      <td>3163.25</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-03-02 11:34:54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ONLN</td>\n",
       "      <td>DESKTOP</td>\n",
       "      <td>UN_PWD</td>\n",
       "      <td>ALLOW</td>\n",
       "      <td>91702</td>\n",
       "      <td>CA</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>2021-05-11 12:34:54</td>\n",
       "      <td>2021-05-11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13999</th>\n",
       "      <td>6.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>60</td>\n",
       "      <td>6</td>\n",
       "      <td>944</td>\n",
       "      <td>NaT</td>\n",
       "      <td>charter communications inc</td>\n",
       "      <td>south central</td>\n",
       "      <td>texas</td>\n",
       "      <td>MOBL</td>\n",
       "      <td>MOBILE</td>\n",
       "      <td>UN_PWD</td>\n",
       "      <td>ALLOW</td>\n",
       "      <td>7407</td>\n",
       "      <td>NJ</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2013-01-09</td>\n",
       "      <td>2021-02-15 16:38:00</td>\n",
       "      <td>2021-02-15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14000 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       TRAN_AMT  ACCT_PRE_TRAN_AVAIL_BAL  CUST_AGE  OPEN_ACCT_CT  WF_dvc_age  \\\n",
       "0          5.38                 23619.91        47             4        2777   \n",
       "1         65.19                     0.00        45             5        2721   \n",
       "2         54.84                 34570.63        36             8        1531   \n",
       "3          0.01                     0.00        62             3         835   \n",
       "4        497.08                 12725.18        81             2        1095   \n",
       "...         ...                      ...       ...           ...         ...   \n",
       "13995   1937.21                   230.75        55             4         142   \n",
       "13996    114.38                     0.00        44            10         272   \n",
       "13997    493.00                  2848.63        54             3         517   \n",
       "13998    491.64                  3163.25        21             3           0   \n",
       "13999      6.02                     0.00        60             6         944   \n",
       "\n",
       "              PWD_UPDT_TS                                CARR_NAME  \\\n",
       "0     2018-01-16 11:03:58                  cox communications inc.   \n",
       "1                     NaT                   charter communications   \n",
       "2     2021-12-22 10:42:51                       utah broadband llc   \n",
       "3     2020-02-08 07:28:31                       t-mobile usa  inc.   \n",
       "4     2020-12-28 12:12:44                    cogent communications   \n",
       "...                   ...                                      ...   \n",
       "13995                 NaT  cellco partnership dba verizon wireless   \n",
       "13996 2017-11-02 04:28:20                       t-mobile usa  inc.   \n",
       "13997 2021-06-03 19:31:15                         att services inc   \n",
       "13998 2020-03-02 11:34:54                                      NaN   \n",
       "13999                 NaT               charter communications inc   \n",
       "\n",
       "            RGN_NAME STATE_PRVNC_TXT ALERT_TRGR_CD DVC_TYPE_TXT  \\\n",
       "0          southwest          nevada          MOBL          NaN   \n",
       "1          southwest      california          MOBL          NaN   \n",
       "2           mountain            utah          ONLN      DESKTOP   \n",
       "3          southwest      california          MOBL       MOBILE   \n",
       "4      south central           texas          MOBL       MOBILE   \n",
       "...              ...             ...           ...          ...   \n",
       "13995      southwest      california          MOBL       MOBILE   \n",
       "13996      southwest      california          MOBL       MOBILE   \n",
       "13997      southwest      california          MOBL      DESKTOP   \n",
       "13998            NaN             NaN          ONLN      DESKTOP   \n",
       "13999  south central           texas          MOBL       MOBILE   \n",
       "\n",
       "      AUTHC_PRIM_TYPE_CD AUTHC_SCNDRY_STAT_TXT  CUST_ZIP CUST_STATE  \\\n",
       "0                 UN_PWD                 ALLOW     89002         NV   \n",
       "1                FACE_ID                 ALLOW     94541         CA   \n",
       "2                 UN_PWD                 ALLOW     21811         MD   \n",
       "3                 UN_PWD                 ALLOW     89822         NV   \n",
       "4                 UN_PWD     CHALLENGE_SUCCESS     84108         UT   \n",
       "...                  ...                   ...       ...        ...   \n",
       "13995             UN_PWD                 ALLOW     92503         CA   \n",
       "13996            FACE_ID                 ALLOW     80478         CO   \n",
       "13997             UN_PWD                 ALLOW     33579         FL   \n",
       "13998             UN_PWD                 ALLOW     91702         CA   \n",
       "13999             UN_PWD                 ALLOW      7407         NJ   \n",
       "\n",
       "           PH_NUM_UPDT_TS CUST_SINCE_DT             TRAN_TS    TRAN_DT  \\\n",
       "0     2021-02-24 15:55:10    1993-01-06 2021-05-03 18:03:58 2021-05-03   \n",
       "1                     NaT    1971-01-07 2021-01-13 19:19:37 2021-01-13   \n",
       "2     2019-05-05 01:08:39    1994-02-01 2021-04-08 09:42:51 2021-04-08   \n",
       "3     2019-02-16 06:45:37    2001-11-01 2021-08-10 15:28:31 2021-08-10   \n",
       "4     2020-05-08 10:27:06    1987-02-07 2021-06-27 11:12:44 2021-06-27   \n",
       "...                   ...           ...                 ...        ...   \n",
       "13995 2017-07-15 06:58:59    2001-06-05 2021-03-12 12:11:59 2021-03-12   \n",
       "13996                 NaT    2010-06-03 2021-06-11 09:28:20 2021-06-11   \n",
       "13997 2021-05-25 08:50:05    1984-10-27 2021-05-16 12:31:15 2021-05-16   \n",
       "13998                 NaT    2021-03-01 2021-05-11 12:34:54 2021-05-11   \n",
       "13999                 NaT    2013-01-09 2021-02-15 16:38:00 2021-02-15   \n",
       "\n",
       "       FRAUD_NONFRAUD  \n",
       "0                   0  \n",
       "1                   0  \n",
       "2                   1  \n",
       "3                   0  \n",
       "4                   1  \n",
       "...               ...  \n",
       "13995               0  \n",
       "13996               0  \n",
       "13997               1  \n",
       "13998               1  \n",
       "13999               0  \n",
       "\n",
       "[14000 rows x 20 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trying this out with Josh's Feature Engineering\n",
    "testDf = pd.read_csv(\"WFTest.csv\")\n",
    "trainDf = pd.read_csv(\"WFTrain.csv\")\n",
    "\n",
    "to_datetime = ['PWD_UPDT_TS', 'PH_NUM_UPDT_TS', 'CUST_SINCE_DT','TRAN_TS',\n",
    "               'TRAN_DT', 'ACTVY_DT']\n",
    "for datetime in to_datetime:\n",
    "  trainDf[datetime] = pd.to_datetime(trainDf[datetime], errors='coerce')\n",
    "\n",
    "to_categorical = ['CARR_NAME', 'RGN_NAME', 'STATE_PRVNC_TXT', 'ALERT_TRGR_CD',\n",
    "                  'DVC_TYPE_TXT', 'AUTHC_PRIM_TYPE_CD', 'AUTHC_SCNDRY_STAT_TXT',\n",
    "                  'CUST_STATE','ACTN_CD','ACTN_INTNL_TXT','TRAN_TYPE_CD',\n",
    "                  'FRAUD_NONFRAUD']\n",
    "\n",
    "for category in to_categorical:\n",
    "  trainDf[category] = trainDf[category].astype(\"category\")\n",
    "\n",
    "redundant = ['ACTN_CD', 'TRAN_TYPE_CD','ACTN_INTNL_TXT','ACTVY_DT']\n",
    "trainDf.drop(columns = redundant, inplace=True)\n",
    "\n",
    "trainDf.FRAUD_NONFRAUD = trainDf.FRAUD_NONFRAUD == 'Fraud'\n",
    "trainDf['FRAUD_NONFRAUD'] = trainDf['FRAUD_NONFRAUD'].astype(int)\n",
    "\n",
    "trainDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba77fd3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRAN_AMT</th>\n",
       "      <th>ACCT_PRE_TRAN_AVAIL_BAL</th>\n",
       "      <th>CUST_AGE</th>\n",
       "      <th>OPEN_ACCT_CT</th>\n",
       "      <th>WF_dvc_age</th>\n",
       "      <th>FRAUD_NONFRAUD</th>\n",
       "      <th>DAY_ACC_AGE</th>\n",
       "      <th>DAY_FRM_NUM_UPDT</th>\n",
       "      <th>DAY_FRM_PWD_UPDT</th>\n",
       "      <th>CARR_NAME_att</th>\n",
       "      <th>...</th>\n",
       "      <th>AUTHC_PRIM_TYPE_CD_AFA_PL</th>\n",
       "      <th>AUTHC_PRIM_TYPE_CD_FACE_ID</th>\n",
       "      <th>AUTHC_PRIM_TYPE_CD_TOUCH_ID</th>\n",
       "      <th>AUTHC_PRIM_TYPE_CD_UN_PWD</th>\n",
       "      <th>AUTHC_SCNDRY_STAT_TXT_ALLOW</th>\n",
       "      <th>AUTHC_SCNDRY_STAT_TXT_CHALLENGE_ISSUED</th>\n",
       "      <th>AUTHC_SCNDRY_STAT_TXT_CHALLENGE_SUCCESS</th>\n",
       "      <th>TXT_CASE_INT</th>\n",
       "      <th>TXT_CASE_MATCH</th>\n",
       "      <th>TXT_CASE_MISMATCH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.38</td>\n",
       "      <td>23619.91</td>\n",
       "      <td>47</td>\n",
       "      <td>4</td>\n",
       "      <td>2777</td>\n",
       "      <td>0</td>\n",
       "      <td>10344</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>45</td>\n",
       "      <td>5</td>\n",
       "      <td>2721</td>\n",
       "      <td>0</td>\n",
       "      <td>18269</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54.84</td>\n",
       "      <td>34570.63</td>\n",
       "      <td>36</td>\n",
       "      <td>8</td>\n",
       "      <td>1531</td>\n",
       "      <td>1</td>\n",
       "      <td>9928</td>\n",
       "      <td>704.0</td>\n",
       "      <td>-259.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "      <td>835</td>\n",
       "      <td>0</td>\n",
       "      <td>7222</td>\n",
       "      <td>906.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>497.08</td>\n",
       "      <td>12725.18</td>\n",
       "      <td>81</td>\n",
       "      <td>2</td>\n",
       "      <td>1095</td>\n",
       "      <td>1</td>\n",
       "      <td>12559</td>\n",
       "      <td>415.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13995</th>\n",
       "      <td>1937.21</td>\n",
       "      <td>230.75</td>\n",
       "      <td>55</td>\n",
       "      <td>4</td>\n",
       "      <td>142</td>\n",
       "      <td>0</td>\n",
       "      <td>7220</td>\n",
       "      <td>1336.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13996</th>\n",
       "      <td>114.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>44</td>\n",
       "      <td>10</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>4026</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1317.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13997</th>\n",
       "      <td>493.00</td>\n",
       "      <td>2848.63</td>\n",
       "      <td>54</td>\n",
       "      <td>3</td>\n",
       "      <td>517</td>\n",
       "      <td>1</td>\n",
       "      <td>13350</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13998</th>\n",
       "      <td>491.64</td>\n",
       "      <td>3163.25</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>435.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13999</th>\n",
       "      <td>6.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>60</td>\n",
       "      <td>6</td>\n",
       "      <td>944</td>\n",
       "      <td>0</td>\n",
       "      <td>2959</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14000 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       TRAN_AMT  ACCT_PRE_TRAN_AVAIL_BAL  CUST_AGE  OPEN_ACCT_CT  WF_dvc_age  \\\n",
       "0          5.38                 23619.91        47             4        2777   \n",
       "1         65.19                     0.00        45             5        2721   \n",
       "2         54.84                 34570.63        36             8        1531   \n",
       "3          0.01                     0.00        62             3         835   \n",
       "4        497.08                 12725.18        81             2        1095   \n",
       "...         ...                      ...       ...           ...         ...   \n",
       "13995   1937.21                   230.75        55             4         142   \n",
       "13996    114.38                     0.00        44            10         272   \n",
       "13997    493.00                  2848.63        54             3         517   \n",
       "13998    491.64                  3163.25        21             3           0   \n",
       "13999      6.02                     0.00        60             6         944   \n",
       "\n",
       "       FRAUD_NONFRAUD  DAY_ACC_AGE  DAY_FRM_NUM_UPDT  DAY_FRM_PWD_UPDT  \\\n",
       "0                   0        10344              68.0            1203.0   \n",
       "1                   0        18269               NaN               NaN   \n",
       "2                   1         9928             704.0            -259.0   \n",
       "3                   0         7222             906.0             549.0   \n",
       "4                   1        12559             415.0             180.0   \n",
       "...               ...          ...               ...               ...   \n",
       "13995               0         7220            1336.0               NaN   \n",
       "13996               0         4026               NaN            1317.0   \n",
       "13997               1        13350              -9.0             -19.0   \n",
       "13998               1           71               NaN             435.0   \n",
       "13999               0         2959               NaN               NaN   \n",
       "\n",
       "       CARR_NAME_att  ...  AUTHC_PRIM_TYPE_CD_AFA_PL  \\\n",
       "0                  0  ...                          0   \n",
       "1                  0  ...                          0   \n",
       "2                  0  ...                          0   \n",
       "3                  0  ...                          0   \n",
       "4                  0  ...                          0   \n",
       "...              ...  ...                        ...   \n",
       "13995              0  ...                          0   \n",
       "13996              0  ...                          0   \n",
       "13997              1  ...                          0   \n",
       "13998              0  ...                          0   \n",
       "13999              0  ...                          0   \n",
       "\n",
       "       AUTHC_PRIM_TYPE_CD_FACE_ID  AUTHC_PRIM_TYPE_CD_TOUCH_ID  \\\n",
       "0                               0                            0   \n",
       "1                               1                            0   \n",
       "2                               0                            0   \n",
       "3                               0                            0   \n",
       "4                               0                            0   \n",
       "...                           ...                          ...   \n",
       "13995                           0                            0   \n",
       "13996                           1                            0   \n",
       "13997                           0                            0   \n",
       "13998                           0                            0   \n",
       "13999                           0                            0   \n",
       "\n",
       "       AUTHC_PRIM_TYPE_CD_UN_PWD  AUTHC_SCNDRY_STAT_TXT_ALLOW  \\\n",
       "0                              1                            1   \n",
       "1                              0                            1   \n",
       "2                              1                            1   \n",
       "3                              1                            1   \n",
       "4                              1                            0   \n",
       "...                          ...                          ...   \n",
       "13995                          1                            1   \n",
       "13996                          0                            1   \n",
       "13997                          1                            1   \n",
       "13998                          1                            1   \n",
       "13999                          1                            1   \n",
       "\n",
       "       AUTHC_SCNDRY_STAT_TXT_CHALLENGE_ISSUED  \\\n",
       "0                                           0   \n",
       "1                                           0   \n",
       "2                                           0   \n",
       "3                                           0   \n",
       "4                                           0   \n",
       "...                                       ...   \n",
       "13995                                       0   \n",
       "13996                                       0   \n",
       "13997                                       0   \n",
       "13998                                       0   \n",
       "13999                                       0   \n",
       "\n",
       "       AUTHC_SCNDRY_STAT_TXT_CHALLENGE_SUCCESS  TXT_CASE_INT  TXT_CASE_MATCH  \\\n",
       "0                                            0             0               1   \n",
       "1                                            0             0               1   \n",
       "2                                            0             0               0   \n",
       "3                                            0             0               0   \n",
       "4                                            1             0               0   \n",
       "...                                        ...           ...             ...   \n",
       "13995                                        0             0               1   \n",
       "13996                                        0             0               0   \n",
       "13997                                        0             0               0   \n",
       "13998                                        0             0               0   \n",
       "13999                                        0             0               0   \n",
       "\n",
       "       TXT_CASE_MISMATCH  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      1  \n",
       "3                      1  \n",
       "4                      1  \n",
       "...                  ...  \n",
       "13995                  0  \n",
       "13996                  1  \n",
       "13997                  1  \n",
       "13998                  1  \n",
       "13999                  1  \n",
       "\n",
       "[14000 rows x 45 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Similar data cleaning process as above\n",
    "DfProc = trainDf\n",
    "\n",
    "carrMap = {\n",
    "    'cox communications inc.' : 'cox',\n",
    "    't-mobile usa  inc.' : 'tmobile',\n",
    "    'charter communications inc' : 'charter',\n",
    "    'comcast' : 'comcast',\n",
    "    'comcast cable communications  llc' : 'comcast',\n",
    "    'centurylink communications  llc' : 'century',\n",
    "    'frontier communications of america  inc.' : 'frontier',\n",
    "    'att services inc' : 'att',\n",
    "    'charter communications' : 'charter',\n",
    "    'at&t mobility llc ' : 'att',\n",
    "    'cellco partnership dba verizon wireless' : 'verizon',\n",
    "}\n",
    "\n",
    "regionSet = { 'southwest', 'south central', 'southeast', 'mountain',\n",
    "             'northeast', 'great lakes', 'mid atlantic', 'pacific northwest',\n",
    "             'midwest'}\n",
    "regionMap = {x:x for x in regionSet}\n",
    "    \n",
    "\n",
    "DfProc['CARR_NAME'] = DfProc['CARR_NAME'].map(carrMap).fillna(\"other\")\n",
    "DfProc['RGN_NAME'] = DfProc['RGN_NAME'].map(regionMap).fillna(\"other\")\n",
    "\n",
    "#ADDITIONAL FEATURE ENGINEERING - - - - - - - - - - - - \n",
    "\n",
    "#Normalize date features against transaction date\n",
    "# How old was the account when it made the transaction\n",
    "DfProc['DAY_ACC_AGE'] = (\n",
    "    DfProc['TRAN_TS'] - DfProc['CUST_SINCE_DT']).dt.days\n",
    "# How long was it been since the phone number was updated since the transaction\n",
    "DfProc['DAY_FRM_NUM_UPDT'] = (\n",
    "    DfProc['TRAN_TS'] - DfProc['PH_NUM_UPDT_TS']).dt.days\n",
    "# How long was it been since the password was updated since the transaction\n",
    "DfProc['DAY_FRM_PWD_UPDT'] = (\n",
    "    DfProc['TRAN_TS'] - DfProc['PWD_UPDT_TS']).dt.days\n",
    "\n",
    "# Cleaning \"region\" column to match entries in state column.\n",
    "# States were mapped to their abbreviations, if state outside US its mapped to\n",
    "# \"INT\" for international\n",
    "stateDict = {'nevada' : 'NV', 'california': 'CA', 'utah': 'UT', 'texas': 'TX','arizona': 'AZ', 'wisconsin': 'WI', 'minnesota': 'MN', 'phnum penh' : 'INT','alabama': 'AL', 'florida': 'FL', 'nebraska': 'NE', 'south dakota': 'SD',\n",
    " 'punjab': 'INT', 'north carolina': 'NC', 'new york': 'NY', 'michigan': 'MI','colorado': 'CO', 'massachusetts': 'MA', 'antioquia': 'INT', 'washington': 'WA','arkansas': 'AR', 'new jersey': 'NJ', 'kentucky': 'KY', 'ostergotlands lan': 'INT',\n",
    " 'tennessee': 'TN', 'district of columbia': 'DC', 'georgia': 'GA', 'maryland': 'MD','oregon': 'OR', 'wyoming': 'WY', 'oklahoma': 'OK', 'illinois': 'IL','north dakota': 'ND', 'indiana': 'IN', 'pennsylvania': 'PA', 'distrito nacional': 'INT',\n",
    " 'distrito capital': 'INT', 'iowa': 'IA', 'zuerich': 'INT', 'hamerkaz': 'INT','sonora': 'INT', 'madrid': 'INT', 'new mexico': 'NM', 'new south wales' : 'INT','loire-atlantique' : 'INT', 'carabobo' : 'INT', 'montana' : 'MT', 'idaho' : 'ID',\n",
    " 'hong kong' : 'INT', 'ohio' : 'OH', 'south carolina': 'SC', 'missouri': 'MS', 'colima': 'INT', 'baja california': 'INT', 'noord-brabant': 'INT', 'nairobi area': 'INT', 'baden-wuerttemberg': 'INT', 'virginia' : 'VA','alaska': 'AK', 'hawaii': 'HI', 'kansas': 'KS', 'greater accra': 'INT', 'kingston': 'INT', 'connecticut' : 'CT', 'louisiana': 'LA', 'bolivar': 'INT',\n",
    " 'lagos': 'INT', 'gujarat': 'INT', 'zulia': 'INT', 'morelos': 'INT', 'jalisco': 'INT', 'san salvador': 'INT', 'west bengal': 'INT', 'guerrero': 'INT', 'distrito federal': 'INT',\n",
    " 'mississippi': 'MS', \"saint george's\": 'INT', 'hampshire': 'NH', 'paris': 'INT','mazowieckie': 'INT', 'region metropolitana': 'INT', 'ha noi': 'INT', 'lara': 'INT','maine': 'ME', 'seoul teukbyeolsi': 'INT', 'telangana': 'INT', 'victoria': 'INT',\n",
    " 'kinshasa': 'INT', 'aguascalientes': 'INT', 'western australia': 'INT','andhra pradesh': 'INT', 'sao paulo': 'INT', 'nueva esparta': 'INT','dubayy': 'INT', 'chihuahua': 'INT', 'rhode island': 'ri', 'istanbul': 'INT','guatemala': 'INT', 'gauteng': 'INT', 'michoacan de ocampo': 'INT', \"ra's al khaymah\": 'INT',\n",
    " 'sodermanlands lan': 'INT', 'da nang': 'INT', 'taipei': 'INT','sindh': 'INT','tamaulipas': 'INT','sinaloa': 'INT','liverpool': 'INT','western cape': 'INT', 'aragua': 'INT', 'british columbia': 'INT', 'guanacaste': 'INT','`amman': 'INT',\n",
    " 'hessen': 'INT','ontario': 'INT','delaware': 'DE', 'dublin': 'INT', 'south west': 'INT', 'west virginia': 'WV', 'south australia': 'INT', 'delhi': 'INT', 'pichincha': 'INT', 'new providence': 'INT', 'tokyo': 'INT', 'nordrhein-westfalen' : 'INT'}\n",
    "\n",
    "# Use statedict to create column to describe where transaction originated from\n",
    "DfProc['TXT_STATE'] = DfProc['STATE_PRVNC_TXT'].map(stateDict).fillna(\"None\")\n",
    "\n",
    "#Function to apply to column of transaction location and customer location \n",
    "#To compare if the two match\n",
    "def locationCompare(txtLoc, custLoc):\n",
    "  if txtLoc != custLoc:\n",
    "    if txtLoc == 'INT':\n",
    "      return 'INT'\n",
    "    else:\n",
    "      return 'MISMATCH'\n",
    "  return 'MATCH'\n",
    "\n",
    "#Apply functino above to TXT state and CUST state column\n",
    "DfProc['TXT_CASE'] = DfProc.apply(\n",
    "    lambda x: locationCompare(x['TXT_STATE'], x['CUST_STATE']), axis=1)\n",
    "\n",
    "\n",
    "## This didn't really help Josh so let's skip it\n",
    "# #Read in external dataframe with data for each zip code\n",
    "# zipInfoDf = pd.read_csv('zip_code_rural.csv')\n",
    "# #Get population number (zpop) and population density (lzden )for each zip code\n",
    "# zipInfoDf = zipInfoDf[['zip', 'zpop', 'lzden']]\n",
    "# #Add this information to df\n",
    "# DfProc = DfProc.merge(zipInfoDf, how='left', left_on='CUST_ZIP', right_on='zip')\n",
    "\n",
    "\n",
    "#Similar process to above, we end up keeping the generated features\n",
    "#And removing a lot of the really detailed categorical variables\n",
    "categorical = ['CARR_NAME', 'RGN_NAME', 'STATE_PRVNC_TXT', 'ALERT_TRGR_CD',\n",
    "                'DVC_TYPE_TXT', 'AUTHC_PRIM_TYPE_CD', 'AUTHC_SCNDRY_STAT_TXT',\n",
    "                'CUST_STATE', 'TXT_CASE']\n",
    "\n",
    "remove = ['PWD_UPDT_TS', 'PH_NUM_UPDT_TS', 'CUST_SINCE_DT','TRAN_TS','TRAN_DT',\n",
    "          'CUST_STATE', 'STATE_PRVNC_TXT', 'TXT_STATE', 'CUST_ZIP', 'zip']\n",
    "\n",
    "\n",
    "categoricalDummies = [x for x in categorical if x not in remove]\n",
    "\n",
    "for var in categoricalDummies:\n",
    "    cat_list = pd.get_dummies(DfProc[var], prefix=var)\n",
    "    DfProc=DfProc.join(cat_list)\n",
    "data_vars=DfProc.columns.values.tolist()\n",
    "to_keep=[i for i in data_vars if i not in categorical and i not in remove]\n",
    "DfProc=DfProc[to_keep]\n",
    "\n",
    "DfProc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7621eb23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = DfProc.loc[:, DfProc.columns != 'FRAUD_NONFRAUD'].astype(float)\n",
    "scaler = StandardScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X))\n",
    "Y = DfProc['FRAUD_NONFRAUD']\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "encoded_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bf9a7b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "msno.matrix(X.sample(250))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc4407c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.849367</td>\n",
       "      <td>0.446727</td>\n",
       "      <td>-0.368429</td>\n",
       "      <td>-0.294369</td>\n",
       "      <td>3.241988</td>\n",
       "      <td>0.418580</td>\n",
       "      <td>-1.219265e+00</td>\n",
       "      <td>1.375457e+00</td>\n",
       "      <td>-0.201835</td>\n",
       "      <td>-0.25583</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.232845</td>\n",
       "      <td>-0.402635</td>\n",
       "      <td>-0.229588</td>\n",
       "      <td>0.573391</td>\n",
       "      <td>0.247323</td>\n",
       "      <td>-0.079077</td>\n",
       "      <td>-0.219943</td>\n",
       "      <td>-0.132905</td>\n",
       "      <td>2.237987</td>\n",
       "      <td>-2.107396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.661215</td>\n",
       "      <td>-0.341486</td>\n",
       "      <td>-0.474647</td>\n",
       "      <td>-0.183982</td>\n",
       "      <td>3.158167</td>\n",
       "      <td>1.991848</td>\n",
       "      <td>-9.161884e-17</td>\n",
       "      <td>-1.176828e-17</td>\n",
       "      <td>-0.201835</td>\n",
       "      <td>-0.25583</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.232845</td>\n",
       "      <td>2.483638</td>\n",
       "      <td>-0.229588</td>\n",
       "      <td>-1.744010</td>\n",
       "      <td>0.247323</td>\n",
       "      <td>-0.079077</td>\n",
       "      <td>-0.219943</td>\n",
       "      <td>-0.132905</td>\n",
       "      <td>2.237987</td>\n",
       "      <td>-2.107396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.693775</td>\n",
       "      <td>0.812161</td>\n",
       "      <td>-0.952629</td>\n",
       "      <td>0.147176</td>\n",
       "      <td>1.376969</td>\n",
       "      <td>0.335996</td>\n",
       "      <td>2.377816e-01</td>\n",
       "      <td>-1.435870e+00</td>\n",
       "      <td>-0.201835</td>\n",
       "      <td>-0.25583</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.232845</td>\n",
       "      <td>-0.402635</td>\n",
       "      <td>-0.229588</td>\n",
       "      <td>0.573391</td>\n",
       "      <td>0.247323</td>\n",
       "      <td>-0.079077</td>\n",
       "      <td>-0.219943</td>\n",
       "      <td>-0.132905</td>\n",
       "      <td>-0.446830</td>\n",
       "      <td>0.474519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.866261</td>\n",
       "      <td>-0.341486</td>\n",
       "      <td>0.428207</td>\n",
       "      <td>-0.404755</td>\n",
       "      <td>0.335192</td>\n",
       "      <td>-0.201198</td>\n",
       "      <td>7.005543e-01</td>\n",
       "      <td>1.178590e-01</td>\n",
       "      <td>-0.201835</td>\n",
       "      <td>-0.25583</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.232845</td>\n",
       "      <td>-0.402635</td>\n",
       "      <td>-0.229588</td>\n",
       "      <td>0.573391</td>\n",
       "      <td>0.247323</td>\n",
       "      <td>-0.079077</td>\n",
       "      <td>-0.219943</td>\n",
       "      <td>-0.132905</td>\n",
       "      <td>-0.446830</td>\n",
       "      <td>0.474519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.697438</td>\n",
       "      <td>0.083162</td>\n",
       "      <td>1.437280</td>\n",
       "      <td>-0.515141</td>\n",
       "      <td>0.724362</td>\n",
       "      <td>0.858301</td>\n",
       "      <td>-4.243041e-01</td>\n",
       "      <td>-5.917030e-01</td>\n",
       "      <td>-0.201835</td>\n",
       "      <td>-0.25583</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.232845</td>\n",
       "      <td>-0.402635</td>\n",
       "      <td>-0.229588</td>\n",
       "      <td>0.573391</td>\n",
       "      <td>-4.043291</td>\n",
       "      <td>-0.079077</td>\n",
       "      <td>4.546628</td>\n",
       "      <td>-0.132905</td>\n",
       "      <td>-0.446830</td>\n",
       "      <td>0.474519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13995</th>\n",
       "      <td>5.227844</td>\n",
       "      <td>-0.333786</td>\n",
       "      <td>0.056444</td>\n",
       "      <td>-0.294369</td>\n",
       "      <td>-0.702094</td>\n",
       "      <td>-0.201595</td>\n",
       "      <td>1.685665e+00</td>\n",
       "      <td>-1.176828e-17</td>\n",
       "      <td>-0.201835</td>\n",
       "      <td>-0.25583</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.232845</td>\n",
       "      <td>-0.402635</td>\n",
       "      <td>-0.229588</td>\n",
       "      <td>0.573391</td>\n",
       "      <td>0.247323</td>\n",
       "      <td>-0.079077</td>\n",
       "      <td>-0.219943</td>\n",
       "      <td>-0.132905</td>\n",
       "      <td>2.237987</td>\n",
       "      <td>-2.107396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13996</th>\n",
       "      <td>-0.506472</td>\n",
       "      <td>-0.341486</td>\n",
       "      <td>-0.527757</td>\n",
       "      <td>0.367949</td>\n",
       "      <td>-0.507509</td>\n",
       "      <td>-0.835667</td>\n",
       "      <td>-9.161884e-17</td>\n",
       "      <td>1.594671e+00</td>\n",
       "      <td>-0.201835</td>\n",
       "      <td>-0.25583</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.232845</td>\n",
       "      <td>2.483638</td>\n",
       "      <td>-0.229588</td>\n",
       "      <td>-1.744010</td>\n",
       "      <td>0.247323</td>\n",
       "      <td>-0.079077</td>\n",
       "      <td>-0.219943</td>\n",
       "      <td>-0.132905</td>\n",
       "      <td>-0.446830</td>\n",
       "      <td>0.474519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13997</th>\n",
       "      <td>0.684603</td>\n",
       "      <td>-0.246425</td>\n",
       "      <td>0.003334</td>\n",
       "      <td>-0.404755</td>\n",
       "      <td>-0.140792</td>\n",
       "      <td>1.015330</td>\n",
       "      <td>-1.395669e+00</td>\n",
       "      <td>-9.743665e-01</td>\n",
       "      <td>4.954538</td>\n",
       "      <td>-0.25583</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.232845</td>\n",
       "      <td>-0.402635</td>\n",
       "      <td>-0.229588</td>\n",
       "      <td>0.573391</td>\n",
       "      <td>0.247323</td>\n",
       "      <td>-0.079077</td>\n",
       "      <td>-0.219943</td>\n",
       "      <td>-0.132905</td>\n",
       "      <td>-0.446830</td>\n",
       "      <td>0.474519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13998</th>\n",
       "      <td>0.680325</td>\n",
       "      <td>-0.235926</td>\n",
       "      <td>-1.749266</td>\n",
       "      <td>-0.404755</td>\n",
       "      <td>-0.914640</td>\n",
       "      <td>-1.620812</td>\n",
       "      <td>-9.161884e-17</td>\n",
       "      <td>-1.013552e-01</td>\n",
       "      <td>-0.201835</td>\n",
       "      <td>-0.25583</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.232845</td>\n",
       "      <td>-0.402635</td>\n",
       "      <td>-0.229588</td>\n",
       "      <td>0.573391</td>\n",
       "      <td>0.247323</td>\n",
       "      <td>-0.079077</td>\n",
       "      <td>-0.219943</td>\n",
       "      <td>-0.132905</td>\n",
       "      <td>-0.446830</td>\n",
       "      <td>0.474519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13999</th>\n",
       "      <td>-0.847354</td>\n",
       "      <td>-0.341486</td>\n",
       "      <td>0.321989</td>\n",
       "      <td>-0.073596</td>\n",
       "      <td>0.498344</td>\n",
       "      <td>-1.047488</td>\n",
       "      <td>-9.161884e-17</td>\n",
       "      <td>-1.176828e-17</td>\n",
       "      <td>-0.201835</td>\n",
       "      <td>-0.25583</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.232845</td>\n",
       "      <td>-0.402635</td>\n",
       "      <td>-0.229588</td>\n",
       "      <td>0.573391</td>\n",
       "      <td>0.247323</td>\n",
       "      <td>-0.079077</td>\n",
       "      <td>-0.219943</td>\n",
       "      <td>-0.132905</td>\n",
       "      <td>-0.446830</td>\n",
       "      <td>0.474519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14000 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5   \\\n",
       "0     -0.849367  0.446727 -0.368429 -0.294369  3.241988  0.418580   \n",
       "1     -0.661215 -0.341486 -0.474647 -0.183982  3.158167  1.991848   \n",
       "2     -0.693775  0.812161 -0.952629  0.147176  1.376969  0.335996   \n",
       "3     -0.866261 -0.341486  0.428207 -0.404755  0.335192 -0.201198   \n",
       "4      0.697438  0.083162  1.437280 -0.515141  0.724362  0.858301   \n",
       "...         ...       ...       ...       ...       ...       ...   \n",
       "13995  5.227844 -0.333786  0.056444 -0.294369 -0.702094 -0.201595   \n",
       "13996 -0.506472 -0.341486 -0.527757  0.367949 -0.507509 -0.835667   \n",
       "13997  0.684603 -0.246425  0.003334 -0.404755 -0.140792  1.015330   \n",
       "13998  0.680325 -0.235926 -1.749266 -0.404755 -0.914640 -1.620812   \n",
       "13999 -0.847354 -0.341486  0.321989 -0.073596  0.498344 -1.047488   \n",
       "\n",
       "                 6             7         8        9   ...        34        35  \\\n",
       "0     -1.219265e+00  1.375457e+00 -0.201835 -0.25583  ... -0.232845 -0.402635   \n",
       "1     -9.161884e-17 -1.176828e-17 -0.201835 -0.25583  ... -0.232845  2.483638   \n",
       "2      2.377816e-01 -1.435870e+00 -0.201835 -0.25583  ... -0.232845 -0.402635   \n",
       "3      7.005543e-01  1.178590e-01 -0.201835 -0.25583  ... -0.232845 -0.402635   \n",
       "4     -4.243041e-01 -5.917030e-01 -0.201835 -0.25583  ... -0.232845 -0.402635   \n",
       "...             ...           ...       ...      ...  ...       ...       ...   \n",
       "13995  1.685665e+00 -1.176828e-17 -0.201835 -0.25583  ... -0.232845 -0.402635   \n",
       "13996 -9.161884e-17  1.594671e+00 -0.201835 -0.25583  ... -0.232845  2.483638   \n",
       "13997 -1.395669e+00 -9.743665e-01  4.954538 -0.25583  ... -0.232845 -0.402635   \n",
       "13998 -9.161884e-17 -1.013552e-01 -0.201835 -0.25583  ... -0.232845 -0.402635   \n",
       "13999 -9.161884e-17 -1.176828e-17 -0.201835 -0.25583  ... -0.232845 -0.402635   \n",
       "\n",
       "             36        37        38        39        40        41        42  \\\n",
       "0     -0.229588  0.573391  0.247323 -0.079077 -0.219943 -0.132905  2.237987   \n",
       "1     -0.229588 -1.744010  0.247323 -0.079077 -0.219943 -0.132905  2.237987   \n",
       "2     -0.229588  0.573391  0.247323 -0.079077 -0.219943 -0.132905 -0.446830   \n",
       "3     -0.229588  0.573391  0.247323 -0.079077 -0.219943 -0.132905 -0.446830   \n",
       "4     -0.229588  0.573391 -4.043291 -0.079077  4.546628 -0.132905 -0.446830   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "13995 -0.229588  0.573391  0.247323 -0.079077 -0.219943 -0.132905  2.237987   \n",
       "13996 -0.229588 -1.744010  0.247323 -0.079077 -0.219943 -0.132905 -0.446830   \n",
       "13997 -0.229588  0.573391  0.247323 -0.079077 -0.219943 -0.132905 -0.446830   \n",
       "13998 -0.229588  0.573391  0.247323 -0.079077 -0.219943 -0.132905 -0.446830   \n",
       "13999 -0.229588  0.573391  0.247323 -0.079077 -0.219943 -0.132905 -0.446830   \n",
       "\n",
       "             43  \n",
       "0     -2.107396  \n",
       "1     -2.107396  \n",
       "2      0.474519  \n",
       "3      0.474519  \n",
       "4      0.474519  \n",
       "...         ...  \n",
       "13995 -2.107396  \n",
       "13996  0.474519  \n",
       "13997  0.474519  \n",
       "13998  0.474519  \n",
       "13999  0.474519  \n",
       "\n",
       "[14000 rows x 44 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_mean_imputed = X.fillna(X.mean())\n",
    "X_mean_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eaf1b0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, input_dim = 44, activation='relu')) # 2 Layers Right Now\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b250dc66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Engineered: 81.34% (0.98%)\n"
     ]
    }
   ],
   "source": [
    "estimator = KerasClassifier(build_fn=create_feature_model, epochs= 50, batch_size= 128, verbose= 0)\n",
    "kfold = StratifiedKFold(n_splits= 5, shuffle=True)\n",
    "results = cross_val_score(estimator, X_mean_imputed, encoded_Y, cv=kfold, \n",
    "                          scoring = make_scorer(f1_score, pos_label = 1, labels=[1, 0]))\n",
    "print(\"Feature Engineered: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1794d6c",
   "metadata": {},
   "source": [
    "## Let's Try Imputing Better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb108350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing: 10695\n",
      "Missing: 0\n"
     ]
    }
   ],
   "source": [
    "# Maybe we should try a better imputing? Let's see what happens with imputing. \n",
    "from numpy import isnan\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Convert to numpy array\n",
    "features = np.array(X)\n",
    "\n",
    "# print total missing\n",
    "print('Missing: %d' % sum(isnan(features).flatten()))\n",
    "# define imputer\n",
    "imputer = KNNImputer(missing_values=np.nan)\n",
    "# fit on the dataset\n",
    "imputer.fit(features)\n",
    "# transform the dataset\n",
    "features_trans = imputer.transform(features)\n",
    "# print total missing\n",
    "print('Missing: %d' % sum(isnan(features_trans).flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "34c1f2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_imputed_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, input_dim = 44, activation='relu')) # 2 Layers Right Now\n",
    "    model.add(Dense(5, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e604022f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "99/99 [==============================] - 0s 837us/step - loss: 0.5638 - accuracy: 0.7169\n",
      "Epoch 2/50\n",
      "99/99 [==============================] - 0s 672us/step - loss: 0.4108 - accuracy: 0.8228\n",
      "Epoch 3/50\n",
      "99/99 [==============================] - 0s 669us/step - loss: 0.3586 - accuracy: 0.8445\n",
      "Epoch 4/50\n",
      "99/99 [==============================] - 0s 651us/step - loss: 0.3342 - accuracy: 0.8537\n",
      "Epoch 5/50\n",
      "99/99 [==============================] - 0s 674us/step - loss: 0.3188 - accuracy: 0.8606\n",
      "Epoch 6/50\n",
      "99/99 [==============================] - 0s 626us/step - loss: 0.3076 - accuracy: 0.8664\n",
      "Epoch 7/50\n",
      "99/99 [==============================] - 0s 652us/step - loss: 0.2983 - accuracy: 0.8706\n",
      "Epoch 8/50\n",
      "99/99 [==============================] - 0s 703us/step - loss: 0.2898 - accuracy: 0.8744\n",
      "Epoch 9/50\n",
      "99/99 [==============================] - 0s 775us/step - loss: 0.2809 - accuracy: 0.8790\n",
      "Epoch 10/50\n",
      "99/99 [==============================] - 0s 774us/step - loss: 0.2730 - accuracy: 0.8817\n",
      "Epoch 11/50\n",
      "99/99 [==============================] - 0s 774us/step - loss: 0.2666 - accuracy: 0.8855\n",
      "Epoch 12/50\n",
      "99/99 [==============================] - 0s 815us/step - loss: 0.2624 - accuracy: 0.8864\n",
      "Epoch 13/50\n",
      "99/99 [==============================] - 0s 693us/step - loss: 0.2585 - accuracy: 0.8897\n",
      "Epoch 14/50\n",
      "99/99 [==============================] - 0s 734us/step - loss: 0.2555 - accuracy: 0.8902\n",
      "Epoch 15/50\n",
      "99/99 [==============================] - 0s 692us/step - loss: 0.2535 - accuracy: 0.8909\n",
      "Epoch 16/50\n",
      "99/99 [==============================] - 0s 652us/step - loss: 0.2518 - accuracy: 0.8929\n",
      "Epoch 17/50\n",
      "99/99 [==============================] - 0s 734us/step - loss: 0.2505 - accuracy: 0.8933\n",
      "Epoch 18/50\n",
      "99/99 [==============================] - 0s 652us/step - loss: 0.2493 - accuracy: 0.8940\n",
      "Epoch 19/50\n",
      "99/99 [==============================] - 0s 673us/step - loss: 0.2481 - accuracy: 0.8944\n",
      "Epoch 20/50\n",
      "99/99 [==============================] - 0s 623us/step - loss: 0.2473 - accuracy: 0.8941\n",
      "Epoch 21/50\n",
      "99/99 [==============================] - 0s 627us/step - loss: 0.2465 - accuracy: 0.8963\n",
      "Epoch 22/50\n",
      "99/99 [==============================] - 0s 611us/step - loss: 0.2454 - accuracy: 0.8955\n",
      "Epoch 23/50\n",
      "99/99 [==============================] - 0s 622us/step - loss: 0.2448 - accuracy: 0.8967\n",
      "Epoch 24/50\n",
      "99/99 [==============================] - 0s 634us/step - loss: 0.2438 - accuracy: 0.8976\n",
      "Epoch 25/50\n",
      "99/99 [==============================] - 0s 611us/step - loss: 0.2434 - accuracy: 0.8977\n",
      "Epoch 26/50\n",
      "99/99 [==============================] - 0s 686us/step - loss: 0.2427 - accuracy: 0.8990\n",
      "Epoch 27/50\n",
      "99/99 [==============================] - 0s 652us/step - loss: 0.2421 - accuracy: 0.8981\n",
      "Epoch 28/50\n",
      "99/99 [==============================] - 0s 653us/step - loss: 0.2416 - accuracy: 0.8988\n",
      "Epoch 29/50\n",
      "99/99 [==============================] - 0s 663us/step - loss: 0.2411 - accuracy: 0.8994\n",
      "Epoch 30/50\n",
      "99/99 [==============================] - 0s 670us/step - loss: 0.2405 - accuracy: 0.8989\n",
      "Epoch 31/50\n",
      "99/99 [==============================] - 0s 629us/step - loss: 0.2400 - accuracy: 0.9002\n",
      "Epoch 32/50\n",
      "99/99 [==============================] - 0s 652us/step - loss: 0.2398 - accuracy: 0.8989\n",
      "Epoch 33/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2394 - accuracy: 0.8999\n",
      "Epoch 34/50\n",
      "99/99 [==============================] - 0s 774us/step - loss: 0.2389 - accuracy: 0.9009\n",
      "Epoch 35/50\n",
      "99/99 [==============================] - 0s 733us/step - loss: 0.2384 - accuracy: 0.9006\n",
      "Epoch 36/50\n",
      "99/99 [==============================] - 0s 693us/step - loss: 0.2381 - accuracy: 0.8999\n",
      "Epoch 37/50\n",
      "99/99 [==============================] - 0s 652us/step - loss: 0.2378 - accuracy: 0.9006\n",
      "Epoch 38/50\n",
      "99/99 [==============================] - 0s 643us/step - loss: 0.2376 - accuracy: 0.9001\n",
      "Epoch 39/50\n",
      "99/99 [==============================] - 0s 775us/step - loss: 0.2370 - accuracy: 0.9017\n",
      "Epoch 40/50\n",
      "99/99 [==============================] - 0s 693us/step - loss: 0.2368 - accuracy: 0.9012\n",
      "Epoch 41/50\n",
      "99/99 [==============================] - 0s 663us/step - loss: 0.2364 - accuracy: 0.9022\n",
      "Epoch 42/50\n",
      "99/99 [==============================] - 0s 629us/step - loss: 0.2361 - accuracy: 0.9022\n",
      "Epoch 43/50\n",
      "99/99 [==============================] - 0s 607us/step - loss: 0.2360 - accuracy: 0.9010\n",
      "Epoch 44/50\n",
      "99/99 [==============================] - 0s 684us/step - loss: 0.2357 - accuracy: 0.9020\n",
      "Epoch 45/50\n",
      "99/99 [==============================] - 0s 630us/step - loss: 0.2353 - accuracy: 0.9021\n",
      "Epoch 46/50\n",
      "99/99 [==============================] - 0s 653us/step - loss: 0.2352 - accuracy: 0.9019\n",
      "Epoch 47/50\n",
      "99/99 [==============================] - 0s 774us/step - loss: 0.2353 - accuracy: 0.9025\n",
      "Epoch 48/50\n",
      "99/99 [==============================] - 0s 734us/step - loss: 0.2347 - accuracy: 0.9020\n",
      "Epoch 49/50\n",
      "99/99 [==============================] - 0s 693us/step - loss: 0.2347 - accuracy: 0.9023\n",
      "Epoch 50/50\n",
      "99/99 [==============================] - 0s 650us/step - loss: 0.2347 - accuracy: 0.9021\n",
      "Epoch 1/50\n",
      "99/99 [==============================] - 0s 689us/step - loss: 0.5090 - accuracy: 0.7032\n",
      "Epoch 2/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.4149 - accuracy: 0.7967\n",
      "Epoch 3/50\n",
      "99/99 [==============================] - 0s 695us/step - loss: 0.3792 - accuracy: 0.8459\n",
      "Epoch 4/50\n",
      "99/99 [==============================] - 0s 693us/step - loss: 0.3432 - accuracy: 0.8548\n",
      "Epoch 5/50\n",
      "99/99 [==============================] - 0s 635us/step - loss: 0.3189 - accuracy: 0.8621\n",
      "Epoch 6/50\n",
      "99/99 [==============================] - 0s 649us/step - loss: 0.3061 - accuracy: 0.8656\n",
      "Epoch 7/50\n",
      "99/99 [==============================] - 0s 651us/step - loss: 0.2969 - accuracy: 0.8694\n",
      "Epoch 8/50\n",
      "99/99 [==============================] - 0s 653us/step - loss: 0.2890 - accuracy: 0.8729\n",
      "Epoch 9/50\n",
      "99/99 [==============================] - 0s 634us/step - loss: 0.2821 - accuracy: 0.8756\n",
      "Epoch 10/50\n",
      "99/99 [==============================] - 0s 677us/step - loss: 0.2756 - accuracy: 0.8787\n",
      "Epoch 11/50\n",
      "99/99 [==============================] - 0s 689us/step - loss: 0.2699 - accuracy: 0.8839\n",
      "Epoch 12/50\n",
      "99/99 [==============================] - 0s 707us/step - loss: 0.2654 - accuracy: 0.8860\n",
      "Epoch 13/50\n",
      "99/99 [==============================] - 0s 727us/step - loss: 0.2617 - accuracy: 0.8890\n",
      "Epoch 14/50\n",
      "99/99 [==============================] - 0s 644us/step - loss: 0.2589 - accuracy: 0.8894\n",
      "Epoch 15/50\n",
      "99/99 [==============================] - 0s 693us/step - loss: 0.2562 - accuracy: 0.8910\n",
      "Epoch 16/50\n",
      "99/99 [==============================] - 0s 652us/step - loss: 0.2540 - accuracy: 0.8923\n",
      "Epoch 17/50\n",
      "99/99 [==============================] - 0s 690us/step - loss: 0.2520 - accuracy: 0.8930\n",
      "Epoch 18/50\n",
      "99/99 [==============================] - 0s 652us/step - loss: 0.2504 - accuracy: 0.8944\n",
      "Epoch 19/50\n",
      "99/99 [==============================] - 0s 709us/step - loss: 0.2486 - accuracy: 0.8959\n",
      "Epoch 20/50\n",
      "99/99 [==============================] - 0s 655us/step - loss: 0.2473 - accuracy: 0.8957\n",
      "Epoch 21/50\n",
      "99/99 [==============================] - 0s 652us/step - loss: 0.2463 - accuracy: 0.8965\n",
      "Epoch 22/50\n",
      "99/99 [==============================] - 0s 654us/step - loss: 0.2453 - accuracy: 0.8974\n",
      "Epoch 23/50\n",
      "99/99 [==============================] - 0s 715us/step - loss: 0.2441 - accuracy: 0.8979\n",
      "Epoch 24/50\n",
      "99/99 [==============================] - 0s 774us/step - loss: 0.2432 - accuracy: 0.8981\n",
      "Epoch 25/50\n",
      "99/99 [==============================] - 0s 856us/step - loss: 0.2420 - accuracy: 0.8988\n",
      "Epoch 26/50\n",
      "99/99 [==============================] - 0s 850us/step - loss: 0.2415 - accuracy: 0.8994\n",
      "Epoch 27/50\n",
      "99/99 [==============================] - 0s 733us/step - loss: 0.2407 - accuracy: 0.8990\n",
      "Epoch 28/50\n",
      "99/99 [==============================] - 0s 662us/step - loss: 0.2400 - accuracy: 0.9001\n",
      "Epoch 29/50\n",
      "99/99 [==============================] - 0s 684us/step - loss: 0.2394 - accuracy: 0.9014\n",
      "Epoch 30/50\n",
      "99/99 [==============================] - 0s 815us/step - loss: 0.2386 - accuracy: 0.9011\n",
      "Epoch 31/50\n",
      "99/99 [==============================] - 0s 856us/step - loss: 0.2380 - accuracy: 0.9002\n",
      "Epoch 32/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 0s 856us/step - loss: 0.2378 - accuracy: 0.8999\n",
      "Epoch 33/50\n",
      "99/99 [==============================] - 0s 750us/step - loss: 0.2372 - accuracy: 0.9016\n",
      "Epoch 34/50\n",
      "99/99 [==============================] - 0s 702us/step - loss: 0.2366 - accuracy: 0.9016\n",
      "Epoch 35/50\n",
      "99/99 [==============================] - 0s 652us/step - loss: 0.2360 - accuracy: 0.9013\n",
      "Epoch 36/50\n",
      "99/99 [==============================] - 0s 652us/step - loss: 0.2362 - accuracy: 0.9021\n",
      "Epoch 37/50\n",
      "99/99 [==============================] - 0s 652us/step - loss: 0.2355 - accuracy: 0.9021\n",
      "Epoch 38/50\n",
      "99/99 [==============================] - 0s 652us/step - loss: 0.2352 - accuracy: 0.9020\n",
      "Epoch 39/50\n",
      "99/99 [==============================] - 0s 693us/step - loss: 0.2348 - accuracy: 0.9018\n",
      "Epoch 40/50\n",
      "99/99 [==============================] - 0s 632us/step - loss: 0.2349 - accuracy: 0.9017\n",
      "Epoch 41/50\n",
      "99/99 [==============================] - 0s 651us/step - loss: 0.2344 - accuracy: 0.9021\n",
      "Epoch 42/50\n",
      "99/99 [==============================] - 0s 619us/step - loss: 0.2340 - accuracy: 0.9029\n",
      "Epoch 43/50\n",
      "99/99 [==============================] - 0s 615us/step - loss: 0.2340 - accuracy: 0.9022\n",
      "Epoch 44/50\n",
      "99/99 [==============================] - 0s 691us/step - loss: 0.2336 - accuracy: 0.9028\n",
      "Epoch 45/50\n",
      "99/99 [==============================] - 0s 637us/step - loss: 0.2335 - accuracy: 0.9021\n",
      "Epoch 46/50\n",
      "99/99 [==============================] - 0s 652us/step - loss: 0.2337 - accuracy: 0.9029\n",
      "Epoch 47/50\n",
      "99/99 [==============================] - 0s 652us/step - loss: 0.2333 - accuracy: 0.9027\n",
      "Epoch 48/50\n",
      "99/99 [==============================] - 0s 652us/step - loss: 0.2325 - accuracy: 0.9017\n",
      "Epoch 49/50\n",
      "99/99 [==============================] - 0s 660us/step - loss: 0.2328 - accuracy: 0.9027\n",
      "Epoch 50/50\n",
      "99/99 [==============================] - 0s 611us/step - loss: 0.2324 - accuracy: 0.9031\n",
      "Epoch 1/50\n",
      "99/99 [==============================] - 0s 668us/step - loss: 0.5476 - accuracy: 0.7024\n",
      "Epoch 2/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.4355 - accuracy: 0.7535\n",
      "Epoch 3/50\n",
      "99/99 [==============================] - 0s 611us/step - loss: 0.3904 - accuracy: 0.8387\n",
      "Epoch 4/50\n",
      "99/99 [==============================] - 0s 652us/step - loss: 0.3672 - accuracy: 0.8537\n",
      "Epoch 5/50\n",
      "99/99 [==============================] - 0s 673us/step - loss: 0.3523 - accuracy: 0.8587\n",
      "Epoch 6/50\n",
      "99/99 [==============================] - 0s 641us/step - loss: 0.3412 - accuracy: 0.8640\n",
      "Epoch 7/50\n",
      "99/99 [==============================] - 0s 611us/step - loss: 0.3325 - accuracy: 0.8679\n",
      "Epoch 8/50\n",
      "99/99 [==============================] - 0s 652us/step - loss: 0.3252 - accuracy: 0.8714\n",
      "Epoch 9/50\n",
      "99/99 [==============================] - 0s 611us/step - loss: 0.3192 - accuracy: 0.8740\n",
      "Epoch 10/50\n",
      "99/99 [==============================] - 0s 693us/step - loss: 0.3128 - accuracy: 0.8763\n",
      "Epoch 11/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.3059 - accuracy: 0.8802\n",
      "Epoch 12/50\n",
      "99/99 [==============================] - 0s 652us/step - loss: 0.2980 - accuracy: 0.8853\n",
      "Epoch 13/50\n",
      "99/99 [==============================] - 0s 609us/step - loss: 0.2906 - accuracy: 0.8898\n",
      "Epoch 14/50\n",
      "99/99 [==============================] - 0s 641us/step - loss: 0.2845 - accuracy: 0.8927\n",
      "Epoch 15/50\n",
      "99/99 [==============================] - 0s 734us/step - loss: 0.2794 - accuracy: 0.8934\n",
      "Epoch 16/50\n",
      "99/99 [==============================] - 0s 655us/step - loss: 0.2751 - accuracy: 0.8954\n",
      "Epoch 17/50\n",
      "99/99 [==============================] - 0s 642us/step - loss: 0.2715 - accuracy: 0.8972\n",
      "Epoch 18/50\n",
      "99/99 [==============================] - 0s 652us/step - loss: 0.2683 - accuracy: 0.8971\n",
      "Epoch 19/50\n",
      "99/99 [==============================] - 0s 624us/step - loss: 0.2655 - accuracy: 0.8980\n",
      "Epoch 20/50\n",
      "99/99 [==============================] - 0s 611us/step - loss: 0.2630 - accuracy: 0.8981\n",
      "Epoch 21/50\n",
      "99/99 [==============================] - 0s 613us/step - loss: 0.2609 - accuracy: 0.8989\n",
      "Epoch 22/50\n",
      "99/99 [==============================] - 0s 601us/step - loss: 0.2588 - accuracy: 0.8992\n",
      "Epoch 23/50\n",
      "99/99 [==============================] - 0s 646us/step - loss: 0.2567 - accuracy: 0.8996\n",
      "Epoch 24/50\n",
      "99/99 [==============================] - 0s 654us/step - loss: 0.2550 - accuracy: 0.9006\n",
      "Epoch 25/50\n",
      "99/99 [==============================] - 0s 652us/step - loss: 0.2534 - accuracy: 0.9000\n",
      "Epoch 26/50\n",
      "99/99 [==============================] - 0s 629us/step - loss: 0.2522 - accuracy: 0.9026\n",
      "Epoch 27/50\n",
      "99/99 [==============================] - 0s 623us/step - loss: 0.2508 - accuracy: 0.9011\n",
      "Epoch 28/50\n",
      "99/99 [==============================] - 0s 652us/step - loss: 0.2493 - accuracy: 0.9017\n",
      "Epoch 29/50\n",
      "99/99 [==============================] - 0s 611us/step - loss: 0.2482 - accuracy: 0.9019\n",
      "Epoch 30/50\n",
      "99/99 [==============================] - 0s 646us/step - loss: 0.2473 - accuracy: 0.9018\n",
      "Epoch 31/50\n",
      "99/99 [==============================] - 0s 703us/step - loss: 0.2466 - accuracy: 0.9021\n",
      "Epoch 32/50\n",
      "99/99 [==============================] - 0s 652us/step - loss: 0.2456 - accuracy: 0.9017\n",
      "Epoch 33/50\n",
      "99/99 [==============================] - 0s 660us/step - loss: 0.2448 - accuracy: 0.9023\n",
      "Epoch 34/50\n",
      "99/99 [==============================] - 0s 625us/step - loss: 0.2439 - accuracy: 0.9037\n",
      "Epoch 35/50\n",
      "99/99 [==============================] - 0s 623us/step - loss: 0.2435 - accuracy: 0.9019\n",
      "Epoch 36/50\n",
      "99/99 [==============================] - 0s 656us/step - loss: 0.2427 - accuracy: 0.9032\n",
      "Epoch 37/50\n",
      "99/99 [==============================] - 0s 652us/step - loss: 0.2423 - accuracy: 0.9033\n",
      "Epoch 38/50\n",
      "99/99 [==============================] - 0s 632us/step - loss: 0.2415 - accuracy: 0.9037\n",
      "Epoch 39/50\n",
      "99/99 [==============================] - 0s 611us/step - loss: 0.2409 - accuracy: 0.9036\n",
      "Epoch 40/50\n",
      "99/99 [==============================] - 0s 755us/step - loss: 0.2404 - accuracy: 0.9037\n",
      "Epoch 41/50\n",
      "99/99 [==============================] - 0s 669us/step - loss: 0.2399 - accuracy: 0.9031\n",
      "Epoch 42/50\n",
      "99/99 [==============================] - 0s 652us/step - loss: 0.2394 - accuracy: 0.9033\n",
      "Epoch 43/50\n",
      "99/99 [==============================] - 0s 611us/step - loss: 0.2391 - accuracy: 0.9037\n",
      "Epoch 44/50\n",
      "99/99 [==============================] - 0s 682us/step - loss: 0.2387 - accuracy: 0.9038\n",
      "Epoch 45/50\n",
      "99/99 [==============================] - 0s 703us/step - loss: 0.2383 - accuracy: 0.9041\n",
      "Epoch 46/50\n",
      "99/99 [==============================] - 0s 734us/step - loss: 0.2381 - accuracy: 0.9031\n",
      "Epoch 47/50\n",
      "99/99 [==============================] - 0s 734us/step - loss: 0.2373 - accuracy: 0.9038\n",
      "Epoch 48/50\n",
      "99/99 [==============================] - 0s 678us/step - loss: 0.2372 - accuracy: 0.9041\n",
      "Epoch 49/50\n",
      "99/99 [==============================] - 0s 667us/step - loss: 0.2366 - accuracy: 0.9046\n",
      "Epoch 50/50\n",
      "99/99 [==============================] - 0s 705us/step - loss: 0.2366 - accuracy: 0.9037\n",
      "Epoch 1/50\n",
      "99/99 [==============================] - 0s 761us/step - loss: 0.6073 - accuracy: 0.6798\n",
      "Epoch 2/50\n",
      "99/99 [==============================] - 0s 661us/step - loss: 0.4480 - accuracy: 0.7870\n",
      "Epoch 3/50\n",
      "99/99 [==============================] - 0s 676us/step - loss: 0.3914 - accuracy: 0.8337\n",
      "Epoch 4/50\n",
      "99/99 [==============================] - 0s 624us/step - loss: 0.3515 - accuracy: 0.8540\n",
      "Epoch 5/50\n",
      "99/99 [==============================] - 0s 626us/step - loss: 0.3239 - accuracy: 0.8631\n",
      "Epoch 6/50\n",
      "99/99 [==============================] - 0s 644us/step - loss: 0.3051 - accuracy: 0.8717\n",
      "Epoch 7/50\n",
      "99/99 [==============================] - 0s 656us/step - loss: 0.2923 - accuracy: 0.8763\n",
      "Epoch 8/50\n",
      "99/99 [==============================] - 0s 658us/step - loss: 0.2830 - accuracy: 0.8815\n",
      "Epoch 9/50\n",
      "99/99 [==============================] - 0s 668us/step - loss: 0.2760 - accuracy: 0.8842\n",
      "Epoch 10/50\n",
      "99/99 [==============================] - 0s 652us/step - loss: 0.2709 - accuracy: 0.8863\n",
      "Epoch 11/50\n",
      "99/99 [==============================] - 0s 680us/step - loss: 0.2665 - accuracy: 0.8873\n",
      "Epoch 12/50\n",
      "99/99 [==============================] - 0s 652us/step - loss: 0.2630 - accuracy: 0.8897\n",
      "Epoch 13/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 0s 690us/step - loss: 0.2601 - accuracy: 0.8908\n",
      "Epoch 14/50\n",
      "99/99 [==============================] - 0s 646us/step - loss: 0.2573 - accuracy: 0.8924\n",
      "Epoch 15/50\n",
      "99/99 [==============================] - 0s 673us/step - loss: 0.2550 - accuracy: 0.8921\n",
      "Epoch 16/50\n",
      "99/99 [==============================] - 0s 611us/step - loss: 0.2535 - accuracy: 0.8926\n",
      "Epoch 17/50\n",
      "99/99 [==============================] - 0s 611us/step - loss: 0.2519 - accuracy: 0.8937\n",
      "Epoch 18/50\n",
      "99/99 [==============================] - 0s 652us/step - loss: 0.2508 - accuracy: 0.8943\n",
      "Epoch 19/50\n",
      "99/99 [==============================] - 0s 815us/step - loss: 0.2499 - accuracy: 0.8952\n",
      "Epoch 20/50\n",
      "99/99 [==============================] - 0s 770us/step - loss: 0.2487 - accuracy: 0.8948\n",
      "Epoch 21/50\n",
      "99/99 [==============================] - 0s 717us/step - loss: 0.2475 - accuracy: 0.8951\n",
      "Epoch 22/50\n",
      "99/99 [==============================] - 0s 652us/step - loss: 0.2468 - accuracy: 0.8959\n",
      "Epoch 23/50\n",
      "99/99 [==============================] - 0s 611us/step - loss: 0.2460 - accuracy: 0.8977\n",
      "Epoch 24/50\n",
      "99/99 [==============================] - 0s 652us/step - loss: 0.2454 - accuracy: 0.8970\n",
      "Epoch 25/50\n",
      "99/99 [==============================] - 0s 652us/step - loss: 0.2446 - accuracy: 0.8976\n",
      "Epoch 26/50\n",
      "99/99 [==============================] - 0s 607us/step - loss: 0.2441 - accuracy: 0.8975\n",
      "Epoch 27/50\n",
      "99/99 [==============================] - 0s 666us/step - loss: 0.2435 - accuracy: 0.8979\n",
      "Epoch 28/50\n",
      "99/99 [==============================] - 0s 693us/step - loss: 0.2429 - accuracy: 0.9000\n",
      "Epoch 29/50\n",
      "99/99 [==============================] - 0s 645us/step - loss: 0.2424 - accuracy: 0.8990\n",
      "Epoch 30/50\n",
      "99/99 [==============================] - 0s 656us/step - loss: 0.2418 - accuracy: 0.8998\n",
      "Epoch 31/50\n",
      "99/99 [==============================] - 0s 611us/step - loss: 0.2415 - accuracy: 0.8998\n",
      "Epoch 32/50\n",
      "99/99 [==============================] - 0s 652us/step - loss: 0.2410 - accuracy: 0.9005\n",
      "Epoch 33/50\n",
      "99/99 [==============================] - 0s 652us/step - loss: 0.2405 - accuracy: 0.9012\n",
      "Epoch 34/50\n",
      "99/99 [==============================] - 0s 611us/step - loss: 0.2399 - accuracy: 0.9013\n",
      "Epoch 35/50\n",
      "99/99 [==============================] - 0s 621us/step - loss: 0.2398 - accuracy: 0.9010\n",
      "Epoch 36/50\n",
      "99/99 [==============================] - 0s 640us/step - loss: 0.2390 - accuracy: 0.9015\n",
      "Epoch 37/50\n",
      "99/99 [==============================] - 0s 646us/step - loss: 0.2389 - accuracy: 0.9021\n",
      "Epoch 38/50\n",
      "99/99 [==============================] - 0s 628us/step - loss: 0.2385 - accuracy: 0.9014\n",
      "Epoch 39/50\n",
      "99/99 [==============================] - 0s 632us/step - loss: 0.2380 - accuracy: 0.9025\n",
      "Epoch 40/50\n",
      "99/99 [==============================] - 0s 652us/step - loss: 0.2379 - accuracy: 0.9025\n",
      "Epoch 41/50\n",
      "99/99 [==============================] - 0s 652us/step - loss: 0.2372 - accuracy: 0.9027\n",
      "Epoch 42/50\n",
      "99/99 [==============================] - 0s 686us/step - loss: 0.2369 - accuracy: 0.9025\n",
      "Epoch 43/50\n",
      "99/99 [==============================] - 0s 679us/step - loss: 0.2367 - accuracy: 0.9025\n",
      "Epoch 44/50\n",
      "99/99 [==============================] - 0s 631us/step - loss: 0.2364 - accuracy: 0.9029\n",
      "Epoch 45/50\n",
      "99/99 [==============================] - 0s 652us/step - loss: 0.2360 - accuracy: 0.9043\n",
      "Epoch 46/50\n",
      "99/99 [==============================] - 0s 652us/step - loss: 0.2356 - accuracy: 0.9032\n",
      "Epoch 47/50\n",
      "99/99 [==============================] - 0s 611us/step - loss: 0.2355 - accuracy: 0.9037\n",
      "Epoch 48/50\n",
      "99/99 [==============================] - 0s 611us/step - loss: 0.2351 - accuracy: 0.9030\n",
      "Epoch 49/50\n",
      "99/99 [==============================] - 0s 652us/step - loss: 0.2348 - accuracy: 0.9058\n",
      "Epoch 50/50\n",
      "99/99 [==============================] - 0s 656us/step - loss: 0.2348 - accuracy: 0.9037\n",
      "Epoch 1/50\n",
      "99/99 [==============================] - 0s 708us/step - loss: 0.6258 - accuracy: 0.6651\n",
      "Epoch 2/50\n",
      "99/99 [==============================] - 0s 611us/step - loss: 0.4296 - accuracy: 0.8061\n",
      "Epoch 3/50\n",
      "99/99 [==============================] - 0s 652us/step - loss: 0.3728 - accuracy: 0.8293\n",
      "Epoch 4/50\n",
      "99/99 [==============================] - 0s 643us/step - loss: 0.3445 - accuracy: 0.8444\n",
      "Epoch 5/50\n",
      "99/99 [==============================] - 0s 663us/step - loss: 0.3255 - accuracy: 0.8551\n",
      "Epoch 6/50\n",
      "99/99 [==============================] - 0s 686us/step - loss: 0.3117 - accuracy: 0.8630\n",
      "Epoch 7/50\n",
      "99/99 [==============================] - 0s 675us/step - loss: 0.3009 - accuracy: 0.8672\n",
      "Epoch 8/50\n",
      "99/99 [==============================] - 0s 669us/step - loss: 0.2913 - accuracy: 0.8725\n",
      "Epoch 9/50\n",
      "99/99 [==============================] - 0s 652us/step - loss: 0.2830 - accuracy: 0.8775\n",
      "Epoch 10/50\n",
      "99/99 [==============================] - 0s 642us/step - loss: 0.2759 - accuracy: 0.8806\n",
      "Epoch 11/50\n",
      "99/99 [==============================] - 0s 652us/step - loss: 0.2693 - accuracy: 0.8850\n",
      "Epoch 12/50\n",
      "99/99 [==============================] - 0s 652us/step - loss: 0.2638 - accuracy: 0.8872\n",
      "Epoch 13/50\n",
      "99/99 [==============================] - 0s 693us/step - loss: 0.2599 - accuracy: 0.8895\n",
      "Epoch 14/50\n",
      "99/99 [==============================] - 0s 635us/step - loss: 0.2567 - accuracy: 0.8922\n",
      "Epoch 15/50\n",
      "99/99 [==============================] - 0s 652us/step - loss: 0.2538 - accuracy: 0.8939\n",
      "Epoch 16/50\n",
      "99/99 [==============================] - 0s 612us/step - loss: 0.2518 - accuracy: 0.8941\n",
      "Epoch 17/50\n",
      "99/99 [==============================] - 0s 698us/step - loss: 0.2503 - accuracy: 0.8959\n",
      "Epoch 18/50\n",
      "99/99 [==============================] - 0s 690us/step - loss: 0.2488 - accuracy: 0.8960\n",
      "Epoch 19/50\n",
      "99/99 [==============================] - 0s 652us/step - loss: 0.2472 - accuracy: 0.8964\n",
      "Epoch 20/50\n",
      "99/99 [==============================] - 0s 652us/step - loss: 0.2461 - accuracy: 0.8961\n",
      "Epoch 21/50\n",
      "99/99 [==============================] - 0s 644us/step - loss: 0.2452 - accuracy: 0.8982\n",
      "Epoch 22/50\n",
      "99/99 [==============================] - 0s 620us/step - loss: 0.2444 - accuracy: 0.8993\n",
      "Epoch 23/50\n",
      "99/99 [==============================] - 0s 611us/step - loss: 0.2439 - accuracy: 0.8987\n",
      "Epoch 24/50\n",
      "99/99 [==============================] - 0s 596us/step - loss: 0.2431 - accuracy: 0.9000\n",
      "Epoch 25/50\n",
      "99/99 [==============================] - 0s 652us/step - loss: 0.2423 - accuracy: 0.9009\n",
      "Epoch 26/50\n",
      "99/99 [==============================] - 0s 766us/step - loss: 0.2420 - accuracy: 0.9001\n",
      "Epoch 27/50\n",
      "99/99 [==============================] - 0s 699us/step - loss: 0.2414 - accuracy: 0.9002\n",
      "Epoch 28/50\n",
      "99/99 [==============================] - 0s 678us/step - loss: 0.2407 - accuracy: 0.9009\n",
      "Epoch 29/50\n",
      "99/99 [==============================] - 0s 678us/step - loss: 0.2399 - accuracy: 0.9010\n",
      "Epoch 30/50\n",
      "99/99 [==============================] - 0s 611us/step - loss: 0.2401 - accuracy: 0.9024\n",
      "Epoch 31/50\n",
      "99/99 [==============================] - 0s 657us/step - loss: 0.2393 - accuracy: 0.9010\n",
      "Epoch 32/50\n",
      "99/99 [==============================] - 0s 652us/step - loss: 0.2389 - accuracy: 0.9018\n",
      "Epoch 33/50\n",
      "99/99 [==============================] - 0s 652us/step - loss: 0.2386 - accuracy: 0.9027\n",
      "Epoch 34/50\n",
      "99/99 [==============================] - 0s 658us/step - loss: 0.2378 - accuracy: 0.9019\n",
      "Epoch 35/50\n",
      "99/99 [==============================] - 0s 683us/step - loss: 0.2372 - accuracy: 0.9030\n",
      "Epoch 36/50\n",
      "99/99 [==============================] - 0s 611us/step - loss: 0.2367 - accuracy: 0.9037\n",
      "Epoch 37/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2362 - accuracy: 0.9024\n",
      "Epoch 38/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.2361 - accuracy: 0.9031\n",
      "Epoch 39/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2358 - accuracy: 0.9041\n",
      "Epoch 40/50\n",
      "99/99 [==============================] - 0s 545us/step - loss: 0.2350 - accuracy: 0.9028\n",
      "Epoch 41/50\n",
      "99/99 [==============================] - 0s 478us/step - loss: 0.2351 - accuracy: 0.9035\n",
      "Epoch 42/50\n",
      "99/99 [==============================] - 0s 545us/step - loss: 0.2345 - accuracy: 0.9039\n",
      "Epoch 43/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2340 - accuracy: 0.9044\n",
      "Epoch 44/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 0s 638us/step - loss: 0.2340 - accuracy: 0.9044\n",
      "Epoch 45/50\n",
      "99/99 [==============================] - 0s 545us/step - loss: 0.2339 - accuracy: 0.9050\n",
      "Epoch 46/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2337 - accuracy: 0.9044\n",
      "Epoch 47/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.2335 - accuracy: 0.9040\n",
      "Epoch 48/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2333 - accuracy: 0.9046\n",
      "Epoch 49/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2326 - accuracy: 0.9047\n",
      "Epoch 50/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.2328 - accuracy: 0.9051\n",
      "Epoch 1/50\n",
      "99/99 [==============================] - 0s 740us/step - loss: 0.6497 - accuracy: 0.6266\n",
      "Epoch 2/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.4550 - accuracy: 0.8240\n",
      "Epoch 3/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.3770 - accuracy: 0.8469\n",
      "Epoch 4/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.3429 - accuracy: 0.8544\n",
      "Epoch 5/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.3245 - accuracy: 0.8611\n",
      "Epoch 6/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.3124 - accuracy: 0.8660\n",
      "Epoch 7/50\n",
      "99/99 [==============================] - 0s 649us/step - loss: 0.3028 - accuracy: 0.8683\n",
      "Epoch 8/50\n",
      "99/99 [==============================] - 0s 689us/step - loss: 0.2950 - accuracy: 0.8713\n",
      "Epoch 9/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2881 - accuracy: 0.8766\n",
      "Epoch 10/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.2819 - accuracy: 0.8797\n",
      "Epoch 11/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2767 - accuracy: 0.8840\n",
      "Epoch 12/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2722 - accuracy: 0.8869\n",
      "Epoch 13/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.2682 - accuracy: 0.8889\n",
      "Epoch 14/50\n",
      "99/99 [==============================] - 0s 545us/step - loss: 0.2653 - accuracy: 0.8914\n",
      "Epoch 15/50\n",
      "99/99 [==============================] - 0s 478us/step - loss: 0.2631 - accuracy: 0.8921\n",
      "Epoch 16/50\n",
      "99/99 [==============================] - 0s 556us/step - loss: 0.2611 - accuracy: 0.8930\n",
      "Epoch 17/50\n",
      "99/99 [==============================] - 0s 689us/step - loss: 0.2597 - accuracy: 0.8923\n",
      "Epoch 18/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.2579 - accuracy: 0.8947\n",
      "Epoch 19/50\n",
      "99/99 [==============================] - 0s 556us/step - loss: 0.2560 - accuracy: 0.8941\n",
      "Epoch 20/50\n",
      "99/99 [==============================] - 0s 529us/step - loss: 0.2545 - accuracy: 0.8957\n",
      "Epoch 21/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.2530 - accuracy: 0.8963\n",
      "Epoch 22/50\n",
      "99/99 [==============================] - 0s 545us/step - loss: 0.2516 - accuracy: 0.8968\n",
      "Epoch 23/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2502 - accuracy: 0.8967\n",
      "Epoch 24/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.2485 - accuracy: 0.8967\n",
      "Epoch 25/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2471 - accuracy: 0.8982\n",
      "Epoch 26/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.2459 - accuracy: 0.8981\n",
      "Epoch 27/50\n",
      "99/99 [==============================] - 0s 545us/step - loss: 0.2451 - accuracy: 0.8996\n",
      "Epoch 28/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2441 - accuracy: 0.8984\n",
      "Epoch 29/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.2432 - accuracy: 0.8999\n",
      "Epoch 30/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2423 - accuracy: 0.8995\n",
      "Epoch 31/50\n",
      "99/99 [==============================] - 0s 545us/step - loss: 0.2416 - accuracy: 0.8990\n",
      "Epoch 32/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.2410 - accuracy: 0.8983\n",
      "Epoch 33/50\n",
      "99/99 [==============================] - 0s 545us/step - loss: 0.2404 - accuracy: 0.8994\n",
      "Epoch 34/50\n",
      "99/99 [==============================] - 0s 863us/step - loss: 0.2397 - accuracy: 0.8994\n",
      "Epoch 35/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.2393 - accuracy: 0.9002\n",
      "Epoch 36/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2388 - accuracy: 0.9005\n",
      "Epoch 37/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2382 - accuracy: 0.9012\n",
      "Epoch 38/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.2376 - accuracy: 0.9007\n",
      "Epoch 39/50\n",
      "99/99 [==============================] - 0s 864us/step - loss: 0.2378 - accuracy: 0.9004\n",
      "Epoch 40/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2367 - accuracy: 0.9016\n",
      "Epoch 41/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.2364 - accuracy: 0.9025\n",
      "Epoch 42/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2359 - accuracy: 0.9029\n",
      "Epoch 43/50\n",
      "99/99 [==============================] - 0s 545us/step - loss: 0.2355 - accuracy: 0.9027\n",
      "Epoch 44/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.2353 - accuracy: 0.9024\n",
      "Epoch 45/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2353 - accuracy: 0.9028\n",
      "Epoch 46/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2349 - accuracy: 0.9033\n",
      "Epoch 47/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.2345 - accuracy: 0.9039\n",
      "Epoch 48/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2342 - accuracy: 0.9047\n",
      "Epoch 49/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2338 - accuracy: 0.9027\n",
      "Epoch 50/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.2335 - accuracy: 0.9036\n",
      "Epoch 1/50\n",
      "99/99 [==============================] - 0s 740us/step - loss: 0.6681 - accuracy: 0.6483\n",
      "Epoch 2/50\n",
      "99/99 [==============================] - 0s 545us/step - loss: 0.5071 - accuracy: 0.7963\n",
      "Epoch 3/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.3802 - accuracy: 0.8359\n",
      "Epoch 4/50\n",
      "99/99 [==============================] - 0s 545us/step - loss: 0.3396 - accuracy: 0.8518\n",
      "Epoch 5/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.3202 - accuracy: 0.8606\n",
      "Epoch 6/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.3070 - accuracy: 0.8666\n",
      "Epoch 7/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2967 - accuracy: 0.8717\n",
      "Epoch 8/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2878 - accuracy: 0.8743\n",
      "Epoch 9/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.2804 - accuracy: 0.8798\n",
      "Epoch 10/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2744 - accuracy: 0.8833\n",
      "Epoch 11/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2693 - accuracy: 0.8858\n",
      "Epoch 12/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.2654 - accuracy: 0.8885\n",
      "Epoch 13/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2622 - accuracy: 0.8891\n",
      "Epoch 14/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2595 - accuracy: 0.8910\n",
      "Epoch 15/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.2569 - accuracy: 0.8920\n",
      "Epoch 16/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2548 - accuracy: 0.8922\n",
      "Epoch 17/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2528 - accuracy: 0.8940\n",
      "Epoch 18/50\n",
      "99/99 [==============================] - 0s 478us/step - loss: 0.2516 - accuracy: 0.8941\n",
      "Epoch 19/50\n",
      "99/99 [==============================] - 0s 545us/step - loss: 0.2502 - accuracy: 0.8949\n",
      "Epoch 20/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2490 - accuracy: 0.8948\n",
      "Epoch 21/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.2478 - accuracy: 0.8954\n",
      "Epoch 22/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2469 - accuracy: 0.8961\n",
      "Epoch 23/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2463 - accuracy: 0.8955\n",
      "Epoch 24/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.2451 - accuracy: 0.8960\n",
      "Epoch 25/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 0s 705us/step - loss: 0.2447 - accuracy: 0.8967\n",
      "Epoch 26/50\n",
      "99/99 [==============================] - 0s 545us/step - loss: 0.2437 - accuracy: 0.8977\n",
      "Epoch 27/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.2431 - accuracy: 0.8988\n",
      "Epoch 28/50\n",
      "99/99 [==============================] - 0s 545us/step - loss: 0.2425 - accuracy: 0.8977\n",
      "Epoch 29/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2417 - accuracy: 0.8980\n",
      "Epoch 30/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.2411 - accuracy: 0.8987\n",
      "Epoch 31/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2407 - accuracy: 0.8983\n",
      "Epoch 32/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.2401 - accuracy: 0.8989\n",
      "Epoch 33/50\n",
      "99/99 [==============================] - 0s 478us/step - loss: 0.2395 - accuracy: 0.8981\n",
      "Epoch 34/50\n",
      "99/99 [==============================] - 0s 545us/step - loss: 0.2388 - accuracy: 0.8990\n",
      "Epoch 35/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.2387 - accuracy: 0.8987\n",
      "Epoch 36/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2382 - accuracy: 0.8998\n",
      "Epoch 37/50\n",
      "99/99 [==============================] - 0s 700us/step - loss: 0.2376 - accuracy: 0.9003\n",
      "Epoch 38/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.2374 - accuracy: 0.8998\n",
      "Epoch 39/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2368 - accuracy: 0.9012\n",
      "Epoch 40/50\n",
      "99/99 [==============================] - 0s 545us/step - loss: 0.2364 - accuracy: 0.9009\n",
      "Epoch 41/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.2362 - accuracy: 0.8998\n",
      "Epoch 42/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2358 - accuracy: 0.9003\n",
      "Epoch 43/50\n",
      "99/99 [==============================] - 0s 545us/step - loss: 0.2355 - accuracy: 0.9013\n",
      "Epoch 44/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.2351 - accuracy: 0.9006\n",
      "Epoch 45/50\n",
      "99/99 [==============================] - 0s 545us/step - loss: 0.2349 - accuracy: 0.9018\n",
      "Epoch 46/50\n",
      "99/99 [==============================] - 0s 545us/step - loss: 0.2346 - accuracy: 0.9021\n",
      "Epoch 47/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.2343 - accuracy: 0.9018\n",
      "Epoch 48/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2339 - accuracy: 0.9020\n",
      "Epoch 49/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2339 - accuracy: 0.9017\n",
      "Epoch 50/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.2337 - accuracy: 0.9023\n",
      "Epoch 1/50\n",
      "99/99 [==============================] - 0s 663us/step - loss: 0.7537 - accuracy: 0.5301\n",
      "Epoch 2/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.4706 - accuracy: 0.8156\n",
      "Epoch 3/50\n",
      "99/99 [==============================] - 0s 478us/step - loss: 0.3694 - accuracy: 0.8350\n",
      "Epoch 4/50\n",
      "99/99 [==============================] - 0s 545us/step - loss: 0.3404 - accuracy: 0.8469\n",
      "Epoch 5/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.3242 - accuracy: 0.8556\n",
      "Epoch 6/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.3118 - accuracy: 0.8620\n",
      "Epoch 7/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.3022 - accuracy: 0.8667\n",
      "Epoch 8/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.2935 - accuracy: 0.8703\n",
      "Epoch 9/50\n",
      "99/99 [==============================] - 0s 478us/step - loss: 0.2853 - accuracy: 0.8729\n",
      "Epoch 10/50\n",
      "99/99 [==============================] - 0s 545us/step - loss: 0.2772 - accuracy: 0.8783\n",
      "Epoch 11/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.2703 - accuracy: 0.8813\n",
      "Epoch 12/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2647 - accuracy: 0.8854\n",
      "Epoch 13/50\n",
      "99/99 [==============================] - 0s 545us/step - loss: 0.2596 - accuracy: 0.8882\n",
      "Epoch 14/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.2557 - accuracy: 0.8903\n",
      "Epoch 15/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2525 - accuracy: 0.8915\n",
      "Epoch 16/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2499 - accuracy: 0.8927\n",
      "Epoch 17/50\n",
      "99/99 [==============================] - 0s 797us/step - loss: 0.2476 - accuracy: 0.8955\n",
      "Epoch 18/50\n",
      "99/99 [==============================] - 0s 478us/step - loss: 0.2463 - accuracy: 0.8963\n",
      "Epoch 19/50\n",
      "99/99 [==============================] - 0s 545us/step - loss: 0.2450 - accuracy: 0.8971\n",
      "Epoch 20/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.2435 - accuracy: 0.8969\n",
      "Epoch 21/50\n",
      "99/99 [==============================] - 0s 545us/step - loss: 0.2428 - accuracy: 0.8979\n",
      "Epoch 22/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2420 - accuracy: 0.8979\n",
      "Epoch 23/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.2410 - accuracy: 0.8982\n",
      "Epoch 24/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2404 - accuracy: 0.8993\n",
      "Epoch 25/50\n",
      "99/99 [==============================] - 0s 545us/step - loss: 0.2399 - accuracy: 0.8989\n",
      "Epoch 26/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.2393 - accuracy: 0.9011\n",
      "Epoch 27/50\n",
      "99/99 [==============================] - 0s 545us/step - loss: 0.2391 - accuracy: 0.8994\n",
      "Epoch 28/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2382 - accuracy: 0.9005\n",
      "Epoch 29/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.2380 - accuracy: 0.9013\n",
      "Epoch 30/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2377 - accuracy: 0.9004\n",
      "Epoch 31/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.2374 - accuracy: 0.8994\n",
      "Epoch 32/50\n",
      "99/99 [==============================] - 0s 545us/step - loss: 0.2370 - accuracy: 0.9005\n",
      "Epoch 33/50\n",
      "99/99 [==============================] - 0s 545us/step - loss: 0.2368 - accuracy: 0.8988\n",
      "Epoch 34/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.2364 - accuracy: 0.8998\n",
      "Epoch 35/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2365 - accuracy: 0.9006\n",
      "Epoch 36/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2358 - accuracy: 0.9010\n",
      "Epoch 37/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.2357 - accuracy: 0.9006\n",
      "Epoch 38/50\n",
      "99/99 [==============================] - 0s 545us/step - loss: 0.2355 - accuracy: 0.9001\n",
      "Epoch 39/50\n",
      "99/99 [==============================] - 0s 545us/step - loss: 0.2353 - accuracy: 0.9015\n",
      "Epoch 40/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.2350 - accuracy: 0.9010\n",
      "Epoch 41/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2347 - accuracy: 0.9016\n",
      "Epoch 42/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2344 - accuracy: 0.9019\n",
      "Epoch 43/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.2342 - accuracy: 0.9010\n",
      "Epoch 44/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2342 - accuracy: 0.9013\n",
      "Epoch 45/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2341 - accuracy: 0.9013\n",
      "Epoch 46/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.2341 - accuracy: 0.9013\n",
      "Epoch 47/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2336 - accuracy: 0.9023\n",
      "Epoch 48/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2332 - accuracy: 0.9017\n",
      "Epoch 49/50\n",
      "99/99 [==============================] - 0s 797us/step - loss: 0.2334 - accuracy: 0.9022\n",
      "Epoch 50/50\n",
      "99/99 [==============================] - 0s 545us/step - loss: 0.2330 - accuracy: 0.9024\n",
      "Epoch 1/50\n",
      "99/99 [==============================] - 0s 580us/step - loss: 0.5613 - accuracy: 0.7183\n",
      "Epoch 2/50\n",
      "99/99 [==============================] - 0s 705us/step - loss: 0.4016 - accuracy: 0.8269\n",
      "Epoch 3/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.3618 - accuracy: 0.8417\n",
      "Epoch 4/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.3428 - accuracy: 0.8489\n",
      "Epoch 5/50\n",
      "99/99 [==============================] - 0s 700us/step - loss: 0.3296 - accuracy: 0.8518\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 0s 638us/step - loss: 0.3186 - accuracy: 0.8598\n",
      "Epoch 7/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.3079 - accuracy: 0.8637\n",
      "Epoch 8/50\n",
      "99/99 [==============================] - 0s 545us/step - loss: 0.2985 - accuracy: 0.8687\n",
      "Epoch 9/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.2899 - accuracy: 0.8716\n",
      "Epoch 10/50\n",
      "99/99 [==============================] - 0s 545us/step - loss: 0.2822 - accuracy: 0.8772\n",
      "Epoch 11/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2759 - accuracy: 0.8792\n",
      "Epoch 12/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.2706 - accuracy: 0.8830\n",
      "Epoch 13/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2665 - accuracy: 0.8848\n",
      "Epoch 14/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2625 - accuracy: 0.8889\n",
      "Epoch 15/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.2597 - accuracy: 0.8899\n",
      "Epoch 16/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2572 - accuracy: 0.8918\n",
      "Epoch 17/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2553 - accuracy: 0.8923\n",
      "Epoch 18/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.2533 - accuracy: 0.8937\n",
      "Epoch 19/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2517 - accuracy: 0.8945\n",
      "Epoch 20/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2503 - accuracy: 0.8952\n",
      "Epoch 21/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.2487 - accuracy: 0.8967\n",
      "Epoch 22/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2478 - accuracy: 0.8963\n",
      "Epoch 23/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2467 - accuracy: 0.8968\n",
      "Epoch 24/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.2456 - accuracy: 0.8991\n",
      "Epoch 25/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2445 - accuracy: 0.8987\n",
      "Epoch 26/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2435 - accuracy: 0.8996\n",
      "Epoch 27/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.2425 - accuracy: 0.9002\n",
      "Epoch 28/50\n",
      "99/99 [==============================] - 0s 545us/step - loss: 0.2417 - accuracy: 0.9014\n",
      "Epoch 29/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2404 - accuracy: 0.8998\n",
      "Epoch 30/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.2400 - accuracy: 0.9002\n",
      "Epoch 31/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2390 - accuracy: 0.9002\n",
      "Epoch 32/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2381 - accuracy: 0.9007\n",
      "Epoch 33/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.2372 - accuracy: 0.9015\n",
      "Epoch 34/50\n",
      "99/99 [==============================] - 0s 545us/step - loss: 0.2367 - accuracy: 0.9013\n",
      "Epoch 35/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2363 - accuracy: 0.9014\n",
      "Epoch 36/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.2354 - accuracy: 0.9021\n",
      "Epoch 37/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2351 - accuracy: 0.9017\n",
      "Epoch 38/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.2342 - accuracy: 0.9019\n",
      "Epoch 39/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.2340 - accuracy: 0.9012\n",
      "Epoch 40/50\n",
      "99/99 [==============================] - 0s 545us/step - loss: 0.2337 - accuracy: 0.9027\n",
      "Epoch 41/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.2330 - accuracy: 0.9019\n",
      "Epoch 42/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2324 - accuracy: 0.9031\n",
      "Epoch 43/50\n",
      "99/99 [==============================] - 0s 545us/step - loss: 0.2318 - accuracy: 0.9025\n",
      "Epoch 44/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.2314 - accuracy: 0.9041\n",
      "Epoch 45/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2310 - accuracy: 0.9032\n",
      "Epoch 46/50\n",
      "99/99 [==============================] - 0s 545us/step - loss: 0.2304 - accuracy: 0.9036\n",
      "Epoch 47/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.2305 - accuracy: 0.9048\n",
      "Epoch 48/50\n",
      "99/99 [==============================] - 0s 545us/step - loss: 0.2296 - accuracy: 0.9055\n",
      "Epoch 49/50\n",
      "99/99 [==============================] - 0s 545us/step - loss: 0.2291 - accuracy: 0.9055\n",
      "Epoch 50/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.2288 - accuracy: 0.9048\n",
      "Epoch 1/50\n",
      "99/99 [==============================] - 0s 581us/step - loss: 0.6999 - accuracy: 0.6101\n",
      "Epoch 2/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.5115 - accuracy: 0.7643\n",
      "Epoch 3/50\n",
      "99/99 [==============================] - 0s 797us/step - loss: 0.4031 - accuracy: 0.8245\n",
      "Epoch 4/50\n",
      "99/99 [==============================] - 0s 545us/step - loss: 0.3490 - accuracy: 0.8515\n",
      "Epoch 5/50\n",
      "99/99 [==============================] - 0s 545us/step - loss: 0.3233 - accuracy: 0.8602\n",
      "Epoch 6/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.3066 - accuracy: 0.8684\n",
      "Epoch 7/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2934 - accuracy: 0.8748\n",
      "Epoch 8/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2838 - accuracy: 0.8800\n",
      "Epoch 9/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.2764 - accuracy: 0.8823\n",
      "Epoch 10/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2706 - accuracy: 0.8847\n",
      "Epoch 11/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2663 - accuracy: 0.8858\n",
      "Epoch 12/50\n",
      "99/99 [==============================] - 0s 649us/step - loss: 0.2623 - accuracy: 0.8873\n",
      "Epoch 13/50\n",
      "99/99 [==============================] - 0s 689us/step - loss: 0.2597 - accuracy: 0.8873\n",
      "Epoch 14/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2575 - accuracy: 0.8897\n",
      "Epoch 15/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.2558 - accuracy: 0.8902\n",
      "Epoch 16/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2540 - accuracy: 0.8913\n",
      "Epoch 17/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2529 - accuracy: 0.8913\n",
      "Epoch 18/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.2514 - accuracy: 0.8921\n",
      "Epoch 19/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2501 - accuracy: 0.8922\n",
      "Epoch 20/50\n",
      "99/99 [==============================] - 0s 545us/step - loss: 0.2491 - accuracy: 0.8929\n",
      "Epoch 21/50\n",
      "99/99 [==============================] - 0s 648us/step - loss: 0.2482 - accuracy: 0.8929\n",
      "Epoch 22/50\n",
      "99/99 [==============================] - 0s 694us/step - loss: 0.2477 - accuracy: 0.8938\n",
      "Epoch 23/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2467 - accuracy: 0.8955\n",
      "Epoch 24/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.2460 - accuracy: 0.8944\n",
      "Epoch 25/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2457 - accuracy: 0.8933\n",
      "Epoch 26/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2451 - accuracy: 0.8956\n",
      "Epoch 27/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.2444 - accuracy: 0.8952\n",
      "Epoch 28/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2438 - accuracy: 0.8963\n",
      "Epoch 29/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2430 - accuracy: 0.8950\n",
      "Epoch 30/50\n",
      "99/99 [==============================] - 0s 864us/step - loss: 0.2421 - accuracy: 0.8944\n",
      "Epoch 31/50\n",
      "99/99 [==============================] - 0s 797us/step - loss: 0.2421 - accuracy: 0.8961\n",
      "Epoch 32/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2411 - accuracy: 0.8966\n",
      "Epoch 33/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2407 - accuracy: 0.8971\n",
      "Epoch 34/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2403 - accuracy: 0.8961\n",
      "Epoch 35/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.2400 - accuracy: 0.8960\n",
      "Epoch 36/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2392 - accuracy: 0.8977\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 0s 704us/step - loss: 0.2390 - accuracy: 0.8966\n",
      "Epoch 38/50\n",
      "99/99 [==============================] - 0s 797us/step - loss: 0.2382 - accuracy: 0.8987\n",
      "Epoch 39/50\n",
      "99/99 [==============================] - 0s 545us/step - loss: 0.2379 - accuracy: 0.8978\n",
      "Epoch 40/50\n",
      "99/99 [==============================] - 0s 545us/step - loss: 0.2375 - accuracy: 0.8979\n",
      "Epoch 41/50\n",
      "99/99 [==============================] - 0s 797us/step - loss: 0.2375 - accuracy: 0.8986\n",
      "Epoch 42/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2369 - accuracy: 0.8979\n",
      "Epoch 43/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2369 - accuracy: 0.8990\n",
      "Epoch 44/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.2362 - accuracy: 0.8988\n",
      "Epoch 45/50\n",
      "99/99 [==============================] - 0s 704us/step - loss: 0.2363 - accuracy: 0.8994\n",
      "Epoch 46/50\n",
      "99/99 [==============================] - 0s 545us/step - loss: 0.2355 - accuracy: 0.8995\n",
      "Epoch 47/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.2355 - accuracy: 0.8990\n",
      "Epoch 48/50\n",
      "99/99 [==============================] - 0s 545us/step - loss: 0.2351 - accuracy: 0.9002\n",
      "Epoch 49/50\n",
      "99/99 [==============================] - 0s 545us/step - loss: 0.2349 - accuracy: 0.8997\n",
      "Epoch 50/50\n",
      "99/99 [==============================] - 0s 638us/step - loss: 0.2348 - accuracy: 0.8994\n",
      "Feature Engineered: 81.65% (1.13%)\n"
     ]
    }
   ],
   "source": [
    "estimator = KerasClassifier(build_fn=create_feature_imputed_model, epochs= 50, batch_size= 128, verbose= 1)\n",
    "kfold = StratifiedKFold(n_splits= 10, shuffle=True)\n",
    "results = cross_val_score(estimator, features_trans, encoded_Y, cv=kfold, \n",
    "                          scoring = make_scorer(f1_score, pos_label = 1, labels=[1, 0]))\n",
    "print(\"Feature Engineered: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
