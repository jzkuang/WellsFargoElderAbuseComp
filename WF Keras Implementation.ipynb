{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d122c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regular Importing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34c12563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.37.0 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (1.41.0)\n",
      "Requirement already satisfied: absl-py~=0.10 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (0.14.1)\n",
      "Requirement already satisfied: h5py~=3.1.0 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (3.18.1)\n",
      "Requirement already satisfied: google-pasta~=0.2 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tensorboard~=2.6 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: keras~=2.6 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: tensorflow-estimator~=2.6 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: numpy~=1.19.2 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (1.19.5)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: clang~=5.0 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (5.0)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (0.37.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: gast==0.4.0 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (1.35.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.26.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (49.2.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.26.6)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2021.5.30)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: keras in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.6.0)\n"
     ]
    }
   ],
   "source": [
    "# Keras Importing\n",
    "!pip install tensorflow\n",
    "!pip install keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7229a9a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: missingno in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.5.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from missingno) (1.19.5)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from missingno) (3.4.3)\n",
      "Requirement already satisfied: seaborn in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from missingno) (0.11.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from missingno) (1.7.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->missingno) (1.3.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->missingno) (2.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->missingno) (8.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->missingno) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->missingno) (0.10.0)\n",
      "Requirement already satisfied: six in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from cycler>=0.10->matplotlib->missingno) (1.15.0)\n",
      "Requirement already satisfied: pandas>=0.23 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from seaborn->missingno) (1.3.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\ihear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas>=0.23->seaborn->missingno) (2021.1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importing for seeing the missing Data\n",
    "!pip install missingno\n",
    "import missingno as msno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ff033d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRAN_AMT</th>\n",
       "      <th>ACCT_PRE_TRAN_AVAIL_BAL</th>\n",
       "      <th>CUST_AGE</th>\n",
       "      <th>OPEN_ACCT_CT</th>\n",
       "      <th>WF_dvc_age</th>\n",
       "      <th>PWD_UPDT_TS</th>\n",
       "      <th>CARR_NAME</th>\n",
       "      <th>RGN_NAME</th>\n",
       "      <th>STATE_PRVNC_TXT</th>\n",
       "      <th>ALERT_TRGR_CD</th>\n",
       "      <th>...</th>\n",
       "      <th>CUST_STATE</th>\n",
       "      <th>PH_NUM_UPDT_TS</th>\n",
       "      <th>CUST_SINCE_DT</th>\n",
       "      <th>TRAN_TS</th>\n",
       "      <th>TRAN_DT</th>\n",
       "      <th>ACTN_CD</th>\n",
       "      <th>ACTN_INTNL_TXT</th>\n",
       "      <th>TRAN_TYPE_CD</th>\n",
       "      <th>ACTVY_DT</th>\n",
       "      <th>FRAUD_NONFRAUD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.38</td>\n",
       "      <td>23619.91</td>\n",
       "      <td>47</td>\n",
       "      <td>4</td>\n",
       "      <td>2777</td>\n",
       "      <td>1/16/2018 11:3:58</td>\n",
       "      <td>cox communications inc.</td>\n",
       "      <td>southwest</td>\n",
       "      <td>nevada</td>\n",
       "      <td>MOBL</td>\n",
       "      <td>...</td>\n",
       "      <td>NV</td>\n",
       "      <td>2/24/2021 15:55:10</td>\n",
       "      <td>1993-01-06 00:00:00</td>\n",
       "      <td>5/3/2021 18:3:58</td>\n",
       "      <td>5/3/2021</td>\n",
       "      <td>SCHPMT</td>\n",
       "      <td>P2P_COMMIT</td>\n",
       "      <td>P2P</td>\n",
       "      <td>5/3/2021</td>\n",
       "      <td>Non-Fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>45</td>\n",
       "      <td>5</td>\n",
       "      <td>2721</td>\n",
       "      <td>NaN</td>\n",
       "      <td>charter communications</td>\n",
       "      <td>southwest</td>\n",
       "      <td>california</td>\n",
       "      <td>MOBL</td>\n",
       "      <td>...</td>\n",
       "      <td>CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1971-01-07 00:00:00</td>\n",
       "      <td>1/13/2021 19:19:37</td>\n",
       "      <td>1/13/2021</td>\n",
       "      <td>SCHPMT</td>\n",
       "      <td>P2P_COMMIT</td>\n",
       "      <td>P2P</td>\n",
       "      <td>1/13/2021</td>\n",
       "      <td>Non-Fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54.84</td>\n",
       "      <td>34570.63</td>\n",
       "      <td>36</td>\n",
       "      <td>8</td>\n",
       "      <td>1531</td>\n",
       "      <td>12/22/2021 10:42:51</td>\n",
       "      <td>utah broadband llc</td>\n",
       "      <td>mountain</td>\n",
       "      <td>utah</td>\n",
       "      <td>ONLN</td>\n",
       "      <td>...</td>\n",
       "      <td>MD</td>\n",
       "      <td>5/5/2019 1:8:39</td>\n",
       "      <td>1994-02-01 00:00:00</td>\n",
       "      <td>4/8/2021 9:42:51</td>\n",
       "      <td>4/8/2021</td>\n",
       "      <td>SCHPMT</td>\n",
       "      <td>P2P_COMMIT</td>\n",
       "      <td>P2P</td>\n",
       "      <td>4/8/2021</td>\n",
       "      <td>Fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "      <td>835</td>\n",
       "      <td>2/8/2020 7:28:31</td>\n",
       "      <td>t-mobile usa  inc.</td>\n",
       "      <td>southwest</td>\n",
       "      <td>california</td>\n",
       "      <td>MOBL</td>\n",
       "      <td>...</td>\n",
       "      <td>NV</td>\n",
       "      <td>2/16/2019 6:45:37</td>\n",
       "      <td>2001-11-01 00:00:00</td>\n",
       "      <td>8/10/2021 15:28:31</td>\n",
       "      <td>8/10/2021</td>\n",
       "      <td>SCHPMT</td>\n",
       "      <td>P2P_COMMIT</td>\n",
       "      <td>P2P</td>\n",
       "      <td>8/10/2021</td>\n",
       "      <td>Non-Fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>497.08</td>\n",
       "      <td>12725.18</td>\n",
       "      <td>81</td>\n",
       "      <td>2</td>\n",
       "      <td>1095</td>\n",
       "      <td>12/28/2020 12:12:44</td>\n",
       "      <td>cogent communications</td>\n",
       "      <td>south central</td>\n",
       "      <td>texas</td>\n",
       "      <td>MOBL</td>\n",
       "      <td>...</td>\n",
       "      <td>UT</td>\n",
       "      <td>5/8/2020 10:27:6</td>\n",
       "      <td>1987-02-07 00:00:00</td>\n",
       "      <td>6/27/2021 11:12:44</td>\n",
       "      <td>6/27/2021</td>\n",
       "      <td>SCHPMT</td>\n",
       "      <td>P2P_COMMIT</td>\n",
       "      <td>P2P</td>\n",
       "      <td>6/27/2021</td>\n",
       "      <td>Fraud</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TRAN_AMT  ACCT_PRE_TRAN_AVAIL_BAL  CUST_AGE  OPEN_ACCT_CT  WF_dvc_age  \\\n",
       "0      5.38                 23619.91        47             4        2777   \n",
       "1     65.19                     0.00        45             5        2721   \n",
       "2     54.84                 34570.63        36             8        1531   \n",
       "3      0.01                     0.00        62             3         835   \n",
       "4    497.08                 12725.18        81             2        1095   \n",
       "\n",
       "           PWD_UPDT_TS                CARR_NAME       RGN_NAME  \\\n",
       "0    1/16/2018 11:3:58  cox communications inc.      southwest   \n",
       "1                  NaN   charter communications      southwest   \n",
       "2  12/22/2021 10:42:51       utah broadband llc       mountain   \n",
       "3     2/8/2020 7:28:31       t-mobile usa  inc.      southwest   \n",
       "4  12/28/2020 12:12:44    cogent communications  south central   \n",
       "\n",
       "  STATE_PRVNC_TXT ALERT_TRGR_CD  ... CUST_STATE      PH_NUM_UPDT_TS  \\\n",
       "0          nevada          MOBL  ...         NV  2/24/2021 15:55:10   \n",
       "1      california          MOBL  ...         CA                 NaN   \n",
       "2            utah          ONLN  ...         MD     5/5/2019 1:8:39   \n",
       "3      california          MOBL  ...         NV   2/16/2019 6:45:37   \n",
       "4           texas          MOBL  ...         UT    5/8/2020 10:27:6   \n",
       "\n",
       "         CUST_SINCE_DT             TRAN_TS    TRAN_DT ACTN_CD ACTN_INTNL_TXT  \\\n",
       "0  1993-01-06 00:00:00    5/3/2021 18:3:58   5/3/2021  SCHPMT     P2P_COMMIT   \n",
       "1  1971-01-07 00:00:00  1/13/2021 19:19:37  1/13/2021  SCHPMT     P2P_COMMIT   \n",
       "2  1994-02-01 00:00:00    4/8/2021 9:42:51   4/8/2021  SCHPMT     P2P_COMMIT   \n",
       "3  2001-11-01 00:00:00  8/10/2021 15:28:31  8/10/2021  SCHPMT     P2P_COMMIT   \n",
       "4  1987-02-07 00:00:00  6/27/2021 11:12:44  6/27/2021  SCHPMT     P2P_COMMIT   \n",
       "\n",
       "  TRAN_TYPE_CD   ACTVY_DT FRAUD_NONFRAUD  \n",
       "0          P2P   5/3/2021      Non-Fraud  \n",
       "1          P2P  1/13/2021      Non-Fraud  \n",
       "2          P2P   4/8/2021          Fraud  \n",
       "3          P2P  8/10/2021      Non-Fraud  \n",
       "4          P2P  6/27/2021          Fraud  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Loading\n",
    "testDf = pd.read_csv(\"WFTest.csv\")\n",
    "trainDf = pd.read_csv(\"WFTrain.csv\")\n",
    "trainDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "429cf18e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRAN_AMT</th>\n",
       "      <th>ACCT_PRE_TRAN_AVAIL_BAL</th>\n",
       "      <th>CUST_AGE</th>\n",
       "      <th>OPEN_ACCT_CT</th>\n",
       "      <th>WF_dvc_age</th>\n",
       "      <th>CUST_ZIP</th>\n",
       "      <th>CARR_NAME_24 shells</th>\n",
       "      <th>CARR_NAME_3ds communications llc</th>\n",
       "      <th>CARR_NAME_432 internet  llc</th>\n",
       "      <th>CARR_NAME_702 communications</th>\n",
       "      <th>...</th>\n",
       "      <th>CUST_STATE_TX</th>\n",
       "      <th>CUST_STATE_UT</th>\n",
       "      <th>CUST_STATE_VA</th>\n",
       "      <th>CUST_STATE_WA</th>\n",
       "      <th>CUST_STATE_WI</th>\n",
       "      <th>CUST_STATE_WV</th>\n",
       "      <th>CUST_STATE_WY</th>\n",
       "      <th>ACTN_CD_SCHPMT</th>\n",
       "      <th>ACTN_INTNL_TXT_P2P_COMMIT</th>\n",
       "      <th>TRAN_TYPE_CD_P2P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.38</td>\n",
       "      <td>23619.91</td>\n",
       "      <td>47.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2777.0</td>\n",
       "      <td>89002.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>45.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2721.0</td>\n",
       "      <td>94541.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54.84</td>\n",
       "      <td>34570.63</td>\n",
       "      <td>36.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1531.0</td>\n",
       "      <td>21811.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>62.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>835.0</td>\n",
       "      <td>89822.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>497.08</td>\n",
       "      <td>12725.18</td>\n",
       "      <td>81.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1095.0</td>\n",
       "      <td>84108.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13995</th>\n",
       "      <td>1937.21</td>\n",
       "      <td>230.75</td>\n",
       "      <td>55.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>92503.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13996</th>\n",
       "      <td>114.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>44.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>272.0</td>\n",
       "      <td>80478.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13997</th>\n",
       "      <td>493.00</td>\n",
       "      <td>2848.63</td>\n",
       "      <td>54.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>517.0</td>\n",
       "      <td>33579.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13998</th>\n",
       "      <td>491.64</td>\n",
       "      <td>3163.25</td>\n",
       "      <td>21.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91702.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13999</th>\n",
       "      <td>6.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>60.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>944.0</td>\n",
       "      <td>7407.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14000 rows × 771 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       TRAN_AMT  ACCT_PRE_TRAN_AVAIL_BAL  CUST_AGE  OPEN_ACCT_CT  WF_dvc_age  \\\n",
       "0          5.38                 23619.91      47.0           4.0      2777.0   \n",
       "1         65.19                     0.00      45.0           5.0      2721.0   \n",
       "2         54.84                 34570.63      36.0           8.0      1531.0   \n",
       "3          0.01                     0.00      62.0           3.0       835.0   \n",
       "4        497.08                 12725.18      81.0           2.0      1095.0   \n",
       "...         ...                      ...       ...           ...         ...   \n",
       "13995   1937.21                   230.75      55.0           4.0       142.0   \n",
       "13996    114.38                     0.00      44.0          10.0       272.0   \n",
       "13997    493.00                  2848.63      54.0           3.0       517.0   \n",
       "13998    491.64                  3163.25      21.0           3.0         0.0   \n",
       "13999      6.02                     0.00      60.0           6.0       944.0   \n",
       "\n",
       "       CUST_ZIP  CARR_NAME_24 shells  CARR_NAME_3ds communications llc  \\\n",
       "0       89002.0                    0                                 0   \n",
       "1       94541.0                    0                                 0   \n",
       "2       21811.0                    0                                 0   \n",
       "3       89822.0                    0                                 0   \n",
       "4       84108.0                    0                                 0   \n",
       "...         ...                  ...                               ...   \n",
       "13995   92503.0                    0                                 0   \n",
       "13996   80478.0                    0                                 0   \n",
       "13997   33579.0                    0                                 0   \n",
       "13998   91702.0                    0                                 0   \n",
       "13999    7407.0                    0                                 0   \n",
       "\n",
       "       CARR_NAME_432 internet  llc  CARR_NAME_702 communications  ...  \\\n",
       "0                                0                             0  ...   \n",
       "1                                0                             0  ...   \n",
       "2                                0                             0  ...   \n",
       "3                                0                             0  ...   \n",
       "4                                0                             0  ...   \n",
       "...                            ...                           ...  ...   \n",
       "13995                            0                             0  ...   \n",
       "13996                            0                             0  ...   \n",
       "13997                            0                             0  ...   \n",
       "13998                            0                             0  ...   \n",
       "13999                            0                             0  ...   \n",
       "\n",
       "       CUST_STATE_TX  CUST_STATE_UT  CUST_STATE_VA  CUST_STATE_WA  \\\n",
       "0                  0              0              0              0   \n",
       "1                  0              0              0              0   \n",
       "2                  0              0              0              0   \n",
       "3                  0              0              0              0   \n",
       "4                  0              1              0              0   \n",
       "...              ...            ...            ...            ...   \n",
       "13995              0              0              0              0   \n",
       "13996              0              0              0              0   \n",
       "13997              0              0              0              0   \n",
       "13998              0              0              0              0   \n",
       "13999              0              0              0              0   \n",
       "\n",
       "       CUST_STATE_WI  CUST_STATE_WV  CUST_STATE_WY  ACTN_CD_SCHPMT  \\\n",
       "0                  0              0              0               1   \n",
       "1                  0              0              0               1   \n",
       "2                  0              0              0               1   \n",
       "3                  0              0              0               1   \n",
       "4                  0              0              0               1   \n",
       "...              ...            ...            ...             ...   \n",
       "13995              0              0              0               1   \n",
       "13996              0              0              0               1   \n",
       "13997              0              0              0               1   \n",
       "13998              0              0              0               1   \n",
       "13999              0              0              0               1   \n",
       "\n",
       "       ACTN_INTNL_TXT_P2P_COMMIT  TRAN_TYPE_CD_P2P  \n",
       "0                              1                 1  \n",
       "1                              1                 1  \n",
       "2                              1                 1  \n",
       "3                              1                 1  \n",
       "4                              1                 1  \n",
       "...                          ...               ...  \n",
       "13995                          1                 1  \n",
       "13996                          1                 1  \n",
       "13997                          1                 1  \n",
       "13998                          1                 1  \n",
       "13999                          1                 1  \n",
       "\n",
       "[14000 rows x 771 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting up the Features\n",
    "numerical = ['TRAN_AMT', 'ACCT_PRE_TRAN_AVAIL_BAL','CUST_AGE',\n",
    "             'OPEN_ACCT_CT', 'WF_dvc_age', 'CUST_ZIP']\n",
    "categorical = ['CARR_NAME', 'RGN_NAME', 'STATE_PRVNC_TXT', 'ALERT_TRGR_CD',\n",
    "                  'DVC_TYPE_TXT', 'AUTHC_PRIM_TYPE_CD', 'AUTHC_SCNDRY_STAT_TXT',\n",
    "                  'CUST_STATE','ACTN_CD','ACTN_INTNL_TXT','TRAN_TYPE_CD']\n",
    "X_cat = pd.get_dummies(trainDf[categorical])\n",
    "X_num = trainDf[numerical].astype(float)\n",
    "X = pd.concat([X_num, X_cat], axis = 1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a608d18a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the Y values\n",
    "Y = trainDf[\"FRAUD_NONFRAUD\"]\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "encoded_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9fef138a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Metric\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "50dbbc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the baseline\n",
    "def create_base_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(350, input_dim= 771, activation='relu')) # 2 Layers Right Now\n",
    "    model.add(Dense(175, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c2c8302e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "88/88 [==============================] - 1s 4ms/step - loss: 201.1359 - accuracy: 0.6481\n",
      "Epoch 2/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 48.9683 - accuracy: 0.7004\n",
      "Epoch 3/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 29.3696 - accuracy: 0.7507\n",
      "Epoch 4/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 20.1089 - accuracy: 0.7611\n",
      "Epoch 5/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 30.1518 - accuracy: 0.7422\n",
      "Epoch 6/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 49.1889 - accuracy: 0.7292\n",
      "Epoch 7/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 25.2470 - accuracy: 0.7576\n",
      "Epoch 8/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 14.2615 - accuracy: 0.7830\n",
      "Epoch 9/50\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 29.0306 - accuracy: 0.7435\n",
      "Epoch 10/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 14.9381 - accuracy: 0.7668\n",
      "Epoch 11/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 12.8503 - accuracy: 0.7829\n",
      "Epoch 12/50\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 12.5475 - accuracy: 0.7812\n",
      "Epoch 13/50\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 13.5232 - accuracy: 0.7789\n",
      "Epoch 14/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 12.7398 - accuracy: 0.7680\n",
      "Epoch 15/50\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 11.0283 - accuracy: 0.7876\n",
      "Epoch 16/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 10.8052 - accuracy: 0.7943\n",
      "Epoch 17/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 11.6569 - accuracy: 0.7772\n",
      "Epoch 18/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 20.1838 - accuracy: 0.7691\n",
      "Epoch 19/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 7.3583 - accuracy: 0.8112\n",
      "Epoch 20/50\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 7.8717 - accuracy: 0.7993\n",
      "Epoch 21/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 8.4555 - accuracy: 0.7925\n",
      "Epoch 22/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 11.0810 - accuracy: 0.7815\n",
      "Epoch 23/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 10.0406 - accuracy: 0.7878\n",
      "Epoch 24/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 7.0876 - accuracy: 0.8059\n",
      "Epoch 25/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 12.0811 - accuracy: 0.7798\n",
      "Epoch 26/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 7.1625 - accuracy: 0.8121\n",
      "Epoch 27/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 6.5088 - accuracy: 0.8031\n",
      "Epoch 28/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 5.7902 - accuracy: 0.8153\n",
      "Epoch 29/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 8.8141 - accuracy: 0.7804\n",
      "Epoch 30/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 4.8097 - accuracy: 0.8173\n",
      "Epoch 31/50\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 5.0866 - accuracy: 0.8115\n",
      "Epoch 32/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 7.5217 - accuracy: 0.8011\n",
      "Epoch 33/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 4.4077 - accuracy: 0.8143\n",
      "Epoch 34/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 6.6535 - accuracy: 0.7941\n",
      "Epoch 35/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 6.1220 - accuracy: 0.8082\n",
      "Epoch 36/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 4.6853 - accuracy: 0.8171\n",
      "Epoch 37/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 5.0867 - accuracy: 0.8034\n",
      "Epoch 38/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 3.7874 - accuracy: 0.8242\n",
      "Epoch 39/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 4.7785 - accuracy: 0.8054\n",
      "Epoch 40/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 3.3461 - accuracy: 0.8197\n",
      "Epoch 41/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 4.5796 - accuracy: 0.8126\n",
      "Epoch 42/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 2.8598 - accuracy: 0.8267\n",
      "Epoch 43/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 4.6323 - accuracy: 0.8060\n",
      "Epoch 44/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 4.1828 - accuracy: 0.8085\n",
      "Epoch 45/50\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 3.9895 - accuracy: 0.8222\n",
      "Epoch 46/50\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 4.6456 - accuracy: 0.7952\n",
      "Epoch 47/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 3.7984 - accuracy: 0.8107\n",
      "Epoch 48/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 3.6863 - accuracy: 0.8221\n",
      "Epoch 49/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 3.9664 - accuracy: 0.8011\n",
      "Epoch 50/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 4.7022 - accuracy: 0.7915\n",
      "Epoch 1/50\n",
      "88/88 [==============================] - 1s 4ms/step - loss: 225.9821 - accuracy: 0.6440\n",
      "Epoch 2/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 37.9915 - accuracy: 0.7100\n",
      "Epoch 3/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 37.2400 - accuracy: 0.7296\n",
      "Epoch 4/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 19.8973 - accuracy: 0.7608\n",
      "Epoch 5/50\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 47.7247 - accuracy: 0.7208\n",
      "Epoch 6/50\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 25.1648 - accuracy: 0.7571\n",
      "Epoch 7/50\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 29.5214 - accuracy: 0.7401\n",
      "Epoch 8/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 14.0684 - accuracy: 0.7865\n",
      "Epoch 9/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 26.0275 - accuracy: 0.7518\n",
      "Epoch 10/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 15.4442 - accuracy: 0.7872\n",
      "Epoch 11/50\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 25.1357 - accuracy: 0.7605\n",
      "Epoch 12/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 14.4637 - accuracy: 0.7929\n",
      "Epoch 13/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 17.0114 - accuracy: 0.7763\n",
      "Epoch 14/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 11.6582 - accuracy: 0.7942\n",
      "Epoch 15/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 16.8210 - accuracy: 0.7761\n",
      "Epoch 16/50\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 28.6410 - accuracy: 0.7563\n",
      "Epoch 17/50\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 12.9477 - accuracy: 0.7968\n",
      "Epoch 18/50\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 12.2023 - accuracy: 0.7900\n",
      "Epoch 19/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 14.4462 - accuracy: 0.7834\n",
      "Epoch 20/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 10.2147 - accuracy: 0.7989\n",
      "Epoch 21/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 17.2913 - accuracy: 0.7707\n",
      "Epoch 22/50\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 10.2277 - accuracy: 0.8018\n",
      "Epoch 23/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 9.6407 - accuracy: 0.8036\n",
      "Epoch 24/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 9.7526 - accuracy: 0.7916\n",
      "Epoch 25/50\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 8.4754 - accuracy: 0.8065\n",
      "Epoch 26/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 9.7095 - accuracy: 0.7994\n",
      "Epoch 27/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 9.2003 - accuracy: 0.7999\n",
      "Epoch 28/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 8.3998 - accuracy: 0.8045\n",
      "Epoch 29/50\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 14.9112 - accuracy: 0.7831\n",
      "Epoch 30/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 9.3176 - accuracy: 0.7885\n",
      "Epoch 31/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 7.5698 - accuracy: 0.8040\n",
      "Epoch 32/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 7.8978 - accuracy: 0.8047\n",
      "Epoch 33/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 7.4226 - accuracy: 0.8045\n",
      "Epoch 34/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 5.9244 - accuracy: 0.8165\n",
      "Epoch 35/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 7.3575 - accuracy: 0.7933\n",
      "Epoch 36/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 5.9020 - accuracy: 0.8138\n",
      "Epoch 37/50\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 7.0811 - accuracy: 0.8056\n",
      "Epoch 38/50\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 4.6712 - accuracy: 0.8171\n",
      "Epoch 39/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 5.6389 - accuracy: 0.8078\n",
      "Epoch 40/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 5.8688 - accuracy: 0.8077\n",
      "Epoch 41/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 4.9163 - accuracy: 0.8096\n",
      "Epoch 42/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 4.5045 - accuracy: 0.8170\n",
      "Epoch 43/50\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 4.2042 - accuracy: 0.8150\n",
      "Epoch 44/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 4.2545 - accuracy: 0.8161\n",
      "Epoch 45/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 3.8819 - accuracy: 0.8243\n",
      "Epoch 46/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 3.4856 - accuracy: 0.8239\n",
      "Epoch 47/50\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 5.3325 - accuracy: 0.7938\n",
      "Epoch 48/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 3.9166 - accuracy: 0.8252\n",
      "Epoch 49/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 3.9776 - accuracy: 0.8249\n",
      "Epoch 50/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 4.6972 - accuracy: 0.8023\n",
      "Epoch 1/50\n",
      "88/88 [==============================] - 1s 4ms/step - loss: 232.5295 - accuracy: 0.6464\n",
      "Epoch 2/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 44.4634 - accuracy: 0.7021\n",
      "Epoch 3/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 52.6340 - accuracy: 0.7109\n",
      "Epoch 4/50\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 26.1217 - accuracy: 0.7619\n",
      "Epoch 5/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 36.4916 - accuracy: 0.7394\n",
      "Epoch 6/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 32.1439 - accuracy: 0.7467\n",
      "Epoch 7/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 35.8125 - accuracy: 0.7375\n",
      "Epoch 8/50\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 17.8426 - accuracy: 0.7695\n",
      "Epoch 9/50\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 15.9995 - accuracy: 0.7779\n",
      "Epoch 10/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 21.4168 - accuracy: 0.7622\n",
      "Epoch 11/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 20.2788 - accuracy: 0.7704\n",
      "Epoch 12/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 13.7206 - accuracy: 0.7897\n",
      "Epoch 13/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 14.8697 - accuracy: 0.7876\n",
      "Epoch 14/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 17.8214 - accuracy: 0.7809\n",
      "Epoch 15/50\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 20.6492 - accuracy: 0.7668\n",
      "Epoch 16/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 13.7782 - accuracy: 0.7777\n",
      "Epoch 17/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 10.0604 - accuracy: 0.7940\n",
      "Epoch 18/50\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 10.7624 - accuracy: 0.7876\n",
      "Epoch 19/50\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 8.6717 - accuracy: 0.8029\n",
      "Epoch 20/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 18.2071 - accuracy: 0.7735\n",
      "Epoch 21/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 8.8673 - accuracy: 0.7976\n",
      "Epoch 22/50\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 7.3037 - accuracy: 0.8113\n",
      "Epoch 23/50\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 7.2177 - accuracy: 0.8010\n",
      "Epoch 24/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 9.8622 - accuracy: 0.7874\n",
      "Epoch 25/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 7.9151 - accuracy: 0.8012\n",
      "Epoch 26/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 9.0389 - accuracy: 0.7921\n",
      "Epoch 27/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 9.7767 - accuracy: 0.7949\n",
      "Epoch 28/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 7.8755 - accuracy: 0.7985\n",
      "Epoch 29/50\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 9.7085 - accuracy: 0.7894\n",
      "Epoch 30/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 6.8099 - accuracy: 0.8037\n",
      "Epoch 31/50\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 10.0067 - accuracy: 0.7833\n",
      "Epoch 32/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 6.6523 - accuracy: 0.8066\n",
      "Epoch 33/50\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 5.4191 - accuracy: 0.8103\n",
      "Epoch 34/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 6.4502 - accuracy: 0.8004\n",
      "Epoch 35/50\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 8.7280 - accuracy: 0.7934\n",
      "Epoch 36/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 4.7289 - accuracy: 0.8184\n",
      "Epoch 37/50\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 5.2936 - accuracy: 0.8088\n",
      "Epoch 38/50\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 4.1233 - accuracy: 0.8214\n",
      "Epoch 39/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 3.6522 - accuracy: 0.8202\n",
      "Epoch 40/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 4.4181 - accuracy: 0.8102\n",
      "Epoch 41/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 5.0796 - accuracy: 0.7982\n",
      "Epoch 42/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 4.0929 - accuracy: 0.8133\n",
      "Epoch 43/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 5.1030 - accuracy: 0.8055\n",
      "Epoch 44/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 5.6047 - accuracy: 0.7933\n",
      "Epoch 45/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 5.4794 - accuracy: 0.8060\n",
      "Epoch 46/50\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 4.2671 - accuracy: 0.8100\n",
      "Epoch 47/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 3.3379 - accuracy: 0.8196\n",
      "Epoch 48/50\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 4.0087 - accuracy: 0.8112\n",
      "Epoch 49/50\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 3.8279 - accuracy: 0.8102\n",
      "Epoch 50/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 3.7112 - accuracy: 0.8145\n",
      "Epoch 1/50\n",
      "88/88 [==============================] - 1s 4ms/step - loss: 328.5654 - accuracy: 0.6131\n",
      "Epoch 2/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 39.5450 - accuracy: 0.7135\n",
      "Epoch 3/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 36.6354 - accuracy: 0.7215\n",
      "Epoch 4/50\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 40.6130 - accuracy: 0.7105\n",
      "Epoch 5/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 43.8598 - accuracy: 0.7305\n",
      "Epoch 6/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 42.9652 - accuracy: 0.7356\n",
      "Epoch 7/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 31.4893 - accuracy: 0.7456\n",
      "Epoch 8/50\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 32.4498 - accuracy: 0.7308\n",
      "Epoch 9/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 27.4177 - accuracy: 0.7461\n",
      "Epoch 10/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 39.5034 - accuracy: 0.7378\n",
      "Epoch 11/50\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 13.5801 - accuracy: 0.7879\n",
      "Epoch 12/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 15.2623 - accuracy: 0.7662\n",
      "Epoch 13/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 25.0153 - accuracy: 0.7503\n",
      "Epoch 14/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 21.4884 - accuracy: 0.7612\n",
      "Epoch 15/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 0s 4ms/step - loss: 13.4975 - accuracy: 0.7829\n",
      "Epoch 16/50\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 18.3658 - accuracy: 0.7557\n",
      "Epoch 17/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 13.8898 - accuracy: 0.7788\n",
      "Epoch 18/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 21.2357 - accuracy: 0.7693\n",
      "Epoch 19/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 13.8275 - accuracy: 0.7843\n",
      "Epoch 20/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 10.8673 - accuracy: 0.7817\n",
      "Epoch 21/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 11.0662 - accuracy: 0.7854\n",
      "Epoch 22/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 13.0013 - accuracy: 0.7710\n",
      "Epoch 23/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 6.6502 - accuracy: 0.8103\n",
      "Epoch 24/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 15.3886 - accuracy: 0.7796\n",
      "Epoch 25/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 8.4394 - accuracy: 0.7899\n",
      "Epoch 26/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 8.2755 - accuracy: 0.7963\n",
      "Epoch 27/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 11.0341 - accuracy: 0.7804\n",
      "Epoch 28/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 11.6047 - accuracy: 0.7799\n",
      "Epoch 29/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 10.5290 - accuracy: 0.7849\n",
      "Epoch 30/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 6.2307 - accuracy: 0.8146\n",
      "Epoch 31/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 7.5806 - accuracy: 0.7925\n",
      "Epoch 32/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 7.0702 - accuracy: 0.8098\n",
      "Epoch 33/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 8.7999 - accuracy: 0.7932\n",
      "Epoch 34/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 6.5253 - accuracy: 0.7949\n",
      "Epoch 35/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 7.1216 - accuracy: 0.7964\n",
      "Epoch 36/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 11.9048 - accuracy: 0.7869\n",
      "Epoch 37/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 9.6230 - accuracy: 0.7854\n",
      "Epoch 38/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 5.8635 - accuracy: 0.8077\n",
      "Epoch 39/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 9.4088 - accuracy: 0.7836\n",
      "Epoch 40/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 4.6134 - accuracy: 0.8091\n",
      "Epoch 41/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 4.3646 - accuracy: 0.8095\n",
      "Epoch 42/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 5.5709 - accuracy: 0.7991\n",
      "Epoch 43/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 6.7449 - accuracy: 0.7973\n",
      "Epoch 44/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 7.4454 - accuracy: 0.7945\n",
      "Epoch 45/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 6.5158 - accuracy: 0.7932\n",
      "Epoch 46/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 4.7686 - accuracy: 0.8132\n",
      "Epoch 47/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 4.0549 - accuracy: 0.8128\n",
      "Epoch 48/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 4.1021 - accuracy: 0.8138\n",
      "Epoch 49/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 4.8043 - accuracy: 0.8025\n",
      "Epoch 50/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 3.3871 - accuracy: 0.8147\n",
      "Epoch 1/50\n",
      "88/88 [==============================] - 1s 4ms/step - loss: 363.4981 - accuracy: 0.6374\n",
      "Epoch 2/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 33.6137 - accuracy: 0.7048\n",
      "Epoch 3/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 36.9791 - accuracy: 0.7279\n",
      "Epoch 4/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 32.9975 - accuracy: 0.7284\n",
      "Epoch 5/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 42.4278 - accuracy: 0.7288\n",
      "Epoch 6/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 30.1300 - accuracy: 0.7479\n",
      "Epoch 7/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 25.1330 - accuracy: 0.7613\n",
      "Epoch 8/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 20.5399 - accuracy: 0.7653\n",
      "Epoch 9/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 17.3421 - accuracy: 0.7682\n",
      "Epoch 10/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 26.0296 - accuracy: 0.7567\n",
      "Epoch 11/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 14.0992 - accuracy: 0.7872\n",
      "Epoch 12/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 15.9410 - accuracy: 0.7823\n",
      "Epoch 13/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 17.6519 - accuracy: 0.7817\n",
      "Epoch 14/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 15.9971 - accuracy: 0.7789\n",
      "Epoch 15/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 15.7752 - accuracy: 0.7754\n",
      "Epoch 16/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 13.6447 - accuracy: 0.7917\n",
      "Epoch 17/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 18.3904 - accuracy: 0.7771\n",
      "Epoch 18/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 12.2743 - accuracy: 0.7907\n",
      "Epoch 19/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 11.5700 - accuracy: 0.7901\n",
      "Epoch 20/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 9.4999 - accuracy: 0.7968\n",
      "Epoch 21/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 11.0596 - accuracy: 0.7856\n",
      "Epoch 22/50\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 18.1993 - accuracy: 0.7753\n",
      "Epoch 23/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 14.7479 - accuracy: 0.7776\n",
      "Epoch 24/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 10.9574 - accuracy: 0.7931\n",
      "Epoch 25/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 7.4876 - accuracy: 0.8077\n",
      "Epoch 26/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 8.5238 - accuracy: 0.8037\n",
      "Epoch 27/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 11.8029 - accuracy: 0.7821\n",
      "Epoch 28/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 8.7949 - accuracy: 0.7971\n",
      "Epoch 29/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 9.6660 - accuracy: 0.7906\n",
      "Epoch 30/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 5.3932 - accuracy: 0.8179\n",
      "Epoch 31/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 9.2873 - accuracy: 0.7956\n",
      "Epoch 32/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 5.1206 - accuracy: 0.8139\n",
      "Epoch 33/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 6.7420 - accuracy: 0.8108\n",
      "Epoch 34/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 5.6368 - accuracy: 0.8160\n",
      "Epoch 35/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 9.3999 - accuracy: 0.7940\n",
      "Epoch 36/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 6.8474 - accuracy: 0.8115\n",
      "Epoch 37/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 5.2180 - accuracy: 0.8194\n",
      "Epoch 38/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 6.3282 - accuracy: 0.8023\n",
      "Epoch 39/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 7.0714 - accuracy: 0.8024\n",
      "Epoch 40/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 4.6874 - accuracy: 0.8179\n",
      "Epoch 41/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 5.5239 - accuracy: 0.8190\n",
      "Epoch 42/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 4.3833 - accuracy: 0.8202\n",
      "Epoch 43/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 4.2088 - accuracy: 0.8240\n",
      "Epoch 44/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 5.1173 - accuracy: 0.8192\n",
      "Epoch 45/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 3.7806 - accuracy: 0.8177\n",
      "Epoch 46/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 3.7597 - accuracy: 0.8262\n",
      "Epoch 47/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 6.9503 - accuracy: 0.7811\n",
      "Epoch 48/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 4.4673 - accuracy: 0.8201\n",
      "Epoch 49/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 3.0547 - accuracy: 0.8291\n",
      "Epoch 50/50\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 3.2183 - accuracy: 0.8287\n",
      "Baseline: 88.36% (3.02%)\n"
     ]
    }
   ],
   "source": [
    "estimator = KerasClassifier(build_fn=create_base_model, epochs= 50, batch_size= 128, verbose=0)\n",
    "kfold = StratifiedKFold(n_splits= 5, shuffle=True)\n",
    "results = cross_val_score(estimator, X, encoded_Y, cv=kfold, \n",
    "                             scoring= make_scorer(f1_score, pos_label = 1, labels=[1, 0]))\n",
    "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47f6e3e",
   "metadata": {},
   "source": [
    "So, we get a baseline of ~90% just by training Keras on the default features. There's quite a lot of them, so this doesn't seem really optimal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bef1dd",
   "metadata": {},
   "source": [
    "## Let's Try Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53fc9983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRAN_AMT</th>\n",
       "      <th>ACCT_PRE_TRAN_AVAIL_BAL</th>\n",
       "      <th>CUST_AGE</th>\n",
       "      <th>OPEN_ACCT_CT</th>\n",
       "      <th>WF_dvc_age</th>\n",
       "      <th>PWD_UPDT_TS</th>\n",
       "      <th>CARR_NAME</th>\n",
       "      <th>RGN_NAME</th>\n",
       "      <th>STATE_PRVNC_TXT</th>\n",
       "      <th>ALERT_TRGR_CD</th>\n",
       "      <th>DVC_TYPE_TXT</th>\n",
       "      <th>AUTHC_PRIM_TYPE_CD</th>\n",
       "      <th>AUTHC_SCNDRY_STAT_TXT</th>\n",
       "      <th>CUST_ZIP</th>\n",
       "      <th>CUST_STATE</th>\n",
       "      <th>PH_NUM_UPDT_TS</th>\n",
       "      <th>CUST_SINCE_DT</th>\n",
       "      <th>TRAN_TS</th>\n",
       "      <th>TRAN_DT</th>\n",
       "      <th>FRAUD_NONFRAUD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.38</td>\n",
       "      <td>23619.91</td>\n",
       "      <td>47</td>\n",
       "      <td>4</td>\n",
       "      <td>2777</td>\n",
       "      <td>2018-01-16 11:03:58</td>\n",
       "      <td>cox communications inc.</td>\n",
       "      <td>southwest</td>\n",
       "      <td>nevada</td>\n",
       "      <td>MOBL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UN_PWD</td>\n",
       "      <td>ALLOW</td>\n",
       "      <td>89002</td>\n",
       "      <td>NV</td>\n",
       "      <td>2021-02-24 15:55:10</td>\n",
       "      <td>1993-01-06</td>\n",
       "      <td>2021-05-03 18:03:58</td>\n",
       "      <td>2021-05-03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>45</td>\n",
       "      <td>5</td>\n",
       "      <td>2721</td>\n",
       "      <td>NaT</td>\n",
       "      <td>charter communications</td>\n",
       "      <td>southwest</td>\n",
       "      <td>california</td>\n",
       "      <td>MOBL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FACE_ID</td>\n",
       "      <td>ALLOW</td>\n",
       "      <td>94541</td>\n",
       "      <td>CA</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1971-01-07</td>\n",
       "      <td>2021-01-13 19:19:37</td>\n",
       "      <td>2021-01-13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54.84</td>\n",
       "      <td>34570.63</td>\n",
       "      <td>36</td>\n",
       "      <td>8</td>\n",
       "      <td>1531</td>\n",
       "      <td>2021-12-22 10:42:51</td>\n",
       "      <td>utah broadband llc</td>\n",
       "      <td>mountain</td>\n",
       "      <td>utah</td>\n",
       "      <td>ONLN</td>\n",
       "      <td>DESKTOP</td>\n",
       "      <td>UN_PWD</td>\n",
       "      <td>ALLOW</td>\n",
       "      <td>21811</td>\n",
       "      <td>MD</td>\n",
       "      <td>2019-05-05 01:08:39</td>\n",
       "      <td>1994-02-01</td>\n",
       "      <td>2021-04-08 09:42:51</td>\n",
       "      <td>2021-04-08</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "      <td>835</td>\n",
       "      <td>2020-02-08 07:28:31</td>\n",
       "      <td>t-mobile usa  inc.</td>\n",
       "      <td>southwest</td>\n",
       "      <td>california</td>\n",
       "      <td>MOBL</td>\n",
       "      <td>MOBILE</td>\n",
       "      <td>UN_PWD</td>\n",
       "      <td>ALLOW</td>\n",
       "      <td>89822</td>\n",
       "      <td>NV</td>\n",
       "      <td>2019-02-16 06:45:37</td>\n",
       "      <td>2001-11-01</td>\n",
       "      <td>2021-08-10 15:28:31</td>\n",
       "      <td>2021-08-10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>497.08</td>\n",
       "      <td>12725.18</td>\n",
       "      <td>81</td>\n",
       "      <td>2</td>\n",
       "      <td>1095</td>\n",
       "      <td>2020-12-28 12:12:44</td>\n",
       "      <td>cogent communications</td>\n",
       "      <td>south central</td>\n",
       "      <td>texas</td>\n",
       "      <td>MOBL</td>\n",
       "      <td>MOBILE</td>\n",
       "      <td>UN_PWD</td>\n",
       "      <td>CHALLENGE_SUCCESS</td>\n",
       "      <td>84108</td>\n",
       "      <td>UT</td>\n",
       "      <td>2020-05-08 10:27:06</td>\n",
       "      <td>1987-02-07</td>\n",
       "      <td>2021-06-27 11:12:44</td>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13995</th>\n",
       "      <td>1937.21</td>\n",
       "      <td>230.75</td>\n",
       "      <td>55</td>\n",
       "      <td>4</td>\n",
       "      <td>142</td>\n",
       "      <td>NaT</td>\n",
       "      <td>cellco partnership dba verizon wireless</td>\n",
       "      <td>southwest</td>\n",
       "      <td>california</td>\n",
       "      <td>MOBL</td>\n",
       "      <td>MOBILE</td>\n",
       "      <td>UN_PWD</td>\n",
       "      <td>ALLOW</td>\n",
       "      <td>92503</td>\n",
       "      <td>CA</td>\n",
       "      <td>2017-07-15 06:58:59</td>\n",
       "      <td>2001-06-05</td>\n",
       "      <td>2021-03-12 12:11:59</td>\n",
       "      <td>2021-03-12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13996</th>\n",
       "      <td>114.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>44</td>\n",
       "      <td>10</td>\n",
       "      <td>272</td>\n",
       "      <td>2017-11-02 04:28:20</td>\n",
       "      <td>t-mobile usa  inc.</td>\n",
       "      <td>southwest</td>\n",
       "      <td>california</td>\n",
       "      <td>MOBL</td>\n",
       "      <td>MOBILE</td>\n",
       "      <td>FACE_ID</td>\n",
       "      <td>ALLOW</td>\n",
       "      <td>80478</td>\n",
       "      <td>CO</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2010-06-03</td>\n",
       "      <td>2021-06-11 09:28:20</td>\n",
       "      <td>2021-06-11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13997</th>\n",
       "      <td>493.00</td>\n",
       "      <td>2848.63</td>\n",
       "      <td>54</td>\n",
       "      <td>3</td>\n",
       "      <td>517</td>\n",
       "      <td>2021-06-03 19:31:15</td>\n",
       "      <td>att services inc</td>\n",
       "      <td>southwest</td>\n",
       "      <td>california</td>\n",
       "      <td>MOBL</td>\n",
       "      <td>DESKTOP</td>\n",
       "      <td>UN_PWD</td>\n",
       "      <td>ALLOW</td>\n",
       "      <td>33579</td>\n",
       "      <td>FL</td>\n",
       "      <td>2021-05-25 08:50:05</td>\n",
       "      <td>1984-10-27</td>\n",
       "      <td>2021-05-16 12:31:15</td>\n",
       "      <td>2021-05-16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13998</th>\n",
       "      <td>491.64</td>\n",
       "      <td>3163.25</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-03-02 11:34:54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ONLN</td>\n",
       "      <td>DESKTOP</td>\n",
       "      <td>UN_PWD</td>\n",
       "      <td>ALLOW</td>\n",
       "      <td>91702</td>\n",
       "      <td>CA</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>2021-05-11 12:34:54</td>\n",
       "      <td>2021-05-11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13999</th>\n",
       "      <td>6.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>60</td>\n",
       "      <td>6</td>\n",
       "      <td>944</td>\n",
       "      <td>NaT</td>\n",
       "      <td>charter communications inc</td>\n",
       "      <td>south central</td>\n",
       "      <td>texas</td>\n",
       "      <td>MOBL</td>\n",
       "      <td>MOBILE</td>\n",
       "      <td>UN_PWD</td>\n",
       "      <td>ALLOW</td>\n",
       "      <td>7407</td>\n",
       "      <td>NJ</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2013-01-09</td>\n",
       "      <td>2021-02-15 16:38:00</td>\n",
       "      <td>2021-02-15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14000 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       TRAN_AMT  ACCT_PRE_TRAN_AVAIL_BAL  CUST_AGE  OPEN_ACCT_CT  WF_dvc_age  \\\n",
       "0          5.38                 23619.91        47             4        2777   \n",
       "1         65.19                     0.00        45             5        2721   \n",
       "2         54.84                 34570.63        36             8        1531   \n",
       "3          0.01                     0.00        62             3         835   \n",
       "4        497.08                 12725.18        81             2        1095   \n",
       "...         ...                      ...       ...           ...         ...   \n",
       "13995   1937.21                   230.75        55             4         142   \n",
       "13996    114.38                     0.00        44            10         272   \n",
       "13997    493.00                  2848.63        54             3         517   \n",
       "13998    491.64                  3163.25        21             3           0   \n",
       "13999      6.02                     0.00        60             6         944   \n",
       "\n",
       "              PWD_UPDT_TS                                CARR_NAME  \\\n",
       "0     2018-01-16 11:03:58                  cox communications inc.   \n",
       "1                     NaT                   charter communications   \n",
       "2     2021-12-22 10:42:51                       utah broadband llc   \n",
       "3     2020-02-08 07:28:31                       t-mobile usa  inc.   \n",
       "4     2020-12-28 12:12:44                    cogent communications   \n",
       "...                   ...                                      ...   \n",
       "13995                 NaT  cellco partnership dba verizon wireless   \n",
       "13996 2017-11-02 04:28:20                       t-mobile usa  inc.   \n",
       "13997 2021-06-03 19:31:15                         att services inc   \n",
       "13998 2020-03-02 11:34:54                                      NaN   \n",
       "13999                 NaT               charter communications inc   \n",
       "\n",
       "            RGN_NAME STATE_PRVNC_TXT ALERT_TRGR_CD DVC_TYPE_TXT  \\\n",
       "0          southwest          nevada          MOBL          NaN   \n",
       "1          southwest      california          MOBL          NaN   \n",
       "2           mountain            utah          ONLN      DESKTOP   \n",
       "3          southwest      california          MOBL       MOBILE   \n",
       "4      south central           texas          MOBL       MOBILE   \n",
       "...              ...             ...           ...          ...   \n",
       "13995      southwest      california          MOBL       MOBILE   \n",
       "13996      southwest      california          MOBL       MOBILE   \n",
       "13997      southwest      california          MOBL      DESKTOP   \n",
       "13998            NaN             NaN          ONLN      DESKTOP   \n",
       "13999  south central           texas          MOBL       MOBILE   \n",
       "\n",
       "      AUTHC_PRIM_TYPE_CD AUTHC_SCNDRY_STAT_TXT  CUST_ZIP CUST_STATE  \\\n",
       "0                 UN_PWD                 ALLOW     89002         NV   \n",
       "1                FACE_ID                 ALLOW     94541         CA   \n",
       "2                 UN_PWD                 ALLOW     21811         MD   \n",
       "3                 UN_PWD                 ALLOW     89822         NV   \n",
       "4                 UN_PWD     CHALLENGE_SUCCESS     84108         UT   \n",
       "...                  ...                   ...       ...        ...   \n",
       "13995             UN_PWD                 ALLOW     92503         CA   \n",
       "13996            FACE_ID                 ALLOW     80478         CO   \n",
       "13997             UN_PWD                 ALLOW     33579         FL   \n",
       "13998             UN_PWD                 ALLOW     91702         CA   \n",
       "13999             UN_PWD                 ALLOW      7407         NJ   \n",
       "\n",
       "           PH_NUM_UPDT_TS CUST_SINCE_DT             TRAN_TS    TRAN_DT  \\\n",
       "0     2021-02-24 15:55:10    1993-01-06 2021-05-03 18:03:58 2021-05-03   \n",
       "1                     NaT    1971-01-07 2021-01-13 19:19:37 2021-01-13   \n",
       "2     2019-05-05 01:08:39    1994-02-01 2021-04-08 09:42:51 2021-04-08   \n",
       "3     2019-02-16 06:45:37    2001-11-01 2021-08-10 15:28:31 2021-08-10   \n",
       "4     2020-05-08 10:27:06    1987-02-07 2021-06-27 11:12:44 2021-06-27   \n",
       "...                   ...           ...                 ...        ...   \n",
       "13995 2017-07-15 06:58:59    2001-06-05 2021-03-12 12:11:59 2021-03-12   \n",
       "13996                 NaT    2010-06-03 2021-06-11 09:28:20 2021-06-11   \n",
       "13997 2021-05-25 08:50:05    1984-10-27 2021-05-16 12:31:15 2021-05-16   \n",
       "13998                 NaT    2021-03-01 2021-05-11 12:34:54 2021-05-11   \n",
       "13999                 NaT    2013-01-09 2021-02-15 16:38:00 2021-02-15   \n",
       "\n",
       "       FRAUD_NONFRAUD  \n",
       "0                   0  \n",
       "1                   0  \n",
       "2                   1  \n",
       "3                   0  \n",
       "4                   1  \n",
       "...               ...  \n",
       "13995               0  \n",
       "13996               0  \n",
       "13997               1  \n",
       "13998               1  \n",
       "13999               0  \n",
       "\n",
       "[14000 rows x 20 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trying this out with Josh's Feature Engineering\n",
    "testDf = pd.read_csv(\"WFTest.csv\")\n",
    "trainDf = pd.read_csv(\"WFTrain.csv\")\n",
    "\n",
    "to_datetime = ['PWD_UPDT_TS', 'PH_NUM_UPDT_TS', 'CUST_SINCE_DT','TRAN_TS',\n",
    "               'TRAN_DT', 'ACTVY_DT']\n",
    "for datetime in to_datetime:\n",
    "  trainDf[datetime] = pd.to_datetime(trainDf[datetime], errors='coerce')\n",
    "\n",
    "to_categorical = ['CARR_NAME', 'RGN_NAME', 'STATE_PRVNC_TXT', 'ALERT_TRGR_CD',\n",
    "                  'DVC_TYPE_TXT', 'AUTHC_PRIM_TYPE_CD', 'AUTHC_SCNDRY_STAT_TXT',\n",
    "                  'CUST_STATE','ACTN_CD','ACTN_INTNL_TXT','TRAN_TYPE_CD',\n",
    "                  'FRAUD_NONFRAUD']\n",
    "\n",
    "for category in to_categorical:\n",
    "  trainDf[category] = trainDf[category].astype(\"category\")\n",
    "\n",
    "redundant = ['ACTN_CD', 'TRAN_TYPE_CD','ACTN_INTNL_TXT','ACTVY_DT']\n",
    "trainDf.drop(columns = redundant, inplace=True)\n",
    "\n",
    "trainDf.FRAUD_NONFRAUD = trainDf.FRAUD_NONFRAUD == 'Fraud'\n",
    "trainDf['FRAUD_NONFRAUD'] = trainDf['FRAUD_NONFRAUD'].astype(int)\n",
    "\n",
    "trainDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba77fd3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRAN_AMT</th>\n",
       "      <th>ACCT_PRE_TRAN_AVAIL_BAL</th>\n",
       "      <th>CUST_AGE</th>\n",
       "      <th>OPEN_ACCT_CT</th>\n",
       "      <th>WF_dvc_age</th>\n",
       "      <th>FRAUD_NONFRAUD</th>\n",
       "      <th>DAY_ACC_AGE</th>\n",
       "      <th>DAY_FRM_NUM_UPDT</th>\n",
       "      <th>DAY_FRM_PWD_UPDT</th>\n",
       "      <th>CARR_NAME_att</th>\n",
       "      <th>...</th>\n",
       "      <th>AUTHC_PRIM_TYPE_CD_AFA_PL</th>\n",
       "      <th>AUTHC_PRIM_TYPE_CD_FACE_ID</th>\n",
       "      <th>AUTHC_PRIM_TYPE_CD_TOUCH_ID</th>\n",
       "      <th>AUTHC_PRIM_TYPE_CD_UN_PWD</th>\n",
       "      <th>AUTHC_SCNDRY_STAT_TXT_ALLOW</th>\n",
       "      <th>AUTHC_SCNDRY_STAT_TXT_CHALLENGE_ISSUED</th>\n",
       "      <th>AUTHC_SCNDRY_STAT_TXT_CHALLENGE_SUCCESS</th>\n",
       "      <th>TXT_CASE_INT</th>\n",
       "      <th>TXT_CASE_MATCH</th>\n",
       "      <th>TXT_CASE_MISMATCH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.38</td>\n",
       "      <td>23619.91</td>\n",
       "      <td>47</td>\n",
       "      <td>4</td>\n",
       "      <td>2777</td>\n",
       "      <td>0</td>\n",
       "      <td>10344</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>45</td>\n",
       "      <td>5</td>\n",
       "      <td>2721</td>\n",
       "      <td>0</td>\n",
       "      <td>18269</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54.84</td>\n",
       "      <td>34570.63</td>\n",
       "      <td>36</td>\n",
       "      <td>8</td>\n",
       "      <td>1531</td>\n",
       "      <td>1</td>\n",
       "      <td>9928</td>\n",
       "      <td>704.0</td>\n",
       "      <td>-259.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "      <td>835</td>\n",
       "      <td>0</td>\n",
       "      <td>7222</td>\n",
       "      <td>906.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>497.08</td>\n",
       "      <td>12725.18</td>\n",
       "      <td>81</td>\n",
       "      <td>2</td>\n",
       "      <td>1095</td>\n",
       "      <td>1</td>\n",
       "      <td>12559</td>\n",
       "      <td>415.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13995</th>\n",
       "      <td>1937.21</td>\n",
       "      <td>230.75</td>\n",
       "      <td>55</td>\n",
       "      <td>4</td>\n",
       "      <td>142</td>\n",
       "      <td>0</td>\n",
       "      <td>7220</td>\n",
       "      <td>1336.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13996</th>\n",
       "      <td>114.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>44</td>\n",
       "      <td>10</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>4026</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1317.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13997</th>\n",
       "      <td>493.00</td>\n",
       "      <td>2848.63</td>\n",
       "      <td>54</td>\n",
       "      <td>3</td>\n",
       "      <td>517</td>\n",
       "      <td>1</td>\n",
       "      <td>13350</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13998</th>\n",
       "      <td>491.64</td>\n",
       "      <td>3163.25</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>435.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13999</th>\n",
       "      <td>6.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>60</td>\n",
       "      <td>6</td>\n",
       "      <td>944</td>\n",
       "      <td>0</td>\n",
       "      <td>2959</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14000 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       TRAN_AMT  ACCT_PRE_TRAN_AVAIL_BAL  CUST_AGE  OPEN_ACCT_CT  WF_dvc_age  \\\n",
       "0          5.38                 23619.91        47             4        2777   \n",
       "1         65.19                     0.00        45             5        2721   \n",
       "2         54.84                 34570.63        36             8        1531   \n",
       "3          0.01                     0.00        62             3         835   \n",
       "4        497.08                 12725.18        81             2        1095   \n",
       "...         ...                      ...       ...           ...         ...   \n",
       "13995   1937.21                   230.75        55             4         142   \n",
       "13996    114.38                     0.00        44            10         272   \n",
       "13997    493.00                  2848.63        54             3         517   \n",
       "13998    491.64                  3163.25        21             3           0   \n",
       "13999      6.02                     0.00        60             6         944   \n",
       "\n",
       "       FRAUD_NONFRAUD  DAY_ACC_AGE  DAY_FRM_NUM_UPDT  DAY_FRM_PWD_UPDT  \\\n",
       "0                   0        10344              68.0            1203.0   \n",
       "1                   0        18269               NaN               NaN   \n",
       "2                   1         9928             704.0            -259.0   \n",
       "3                   0         7222             906.0             549.0   \n",
       "4                   1        12559             415.0             180.0   \n",
       "...               ...          ...               ...               ...   \n",
       "13995               0         7220            1336.0               NaN   \n",
       "13996               0         4026               NaN            1317.0   \n",
       "13997               1        13350              -9.0             -19.0   \n",
       "13998               1           71               NaN             435.0   \n",
       "13999               0         2959               NaN               NaN   \n",
       "\n",
       "       CARR_NAME_att  ...  AUTHC_PRIM_TYPE_CD_AFA_PL  \\\n",
       "0                  0  ...                          0   \n",
       "1                  0  ...                          0   \n",
       "2                  0  ...                          0   \n",
       "3                  0  ...                          0   \n",
       "4                  0  ...                          0   \n",
       "...              ...  ...                        ...   \n",
       "13995              0  ...                          0   \n",
       "13996              0  ...                          0   \n",
       "13997              1  ...                          0   \n",
       "13998              0  ...                          0   \n",
       "13999              0  ...                          0   \n",
       "\n",
       "       AUTHC_PRIM_TYPE_CD_FACE_ID  AUTHC_PRIM_TYPE_CD_TOUCH_ID  \\\n",
       "0                               0                            0   \n",
       "1                               1                            0   \n",
       "2                               0                            0   \n",
       "3                               0                            0   \n",
       "4                               0                            0   \n",
       "...                           ...                          ...   \n",
       "13995                           0                            0   \n",
       "13996                           1                            0   \n",
       "13997                           0                            0   \n",
       "13998                           0                            0   \n",
       "13999                           0                            0   \n",
       "\n",
       "       AUTHC_PRIM_TYPE_CD_UN_PWD  AUTHC_SCNDRY_STAT_TXT_ALLOW  \\\n",
       "0                              1                            1   \n",
       "1                              0                            1   \n",
       "2                              1                            1   \n",
       "3                              1                            1   \n",
       "4                              1                            0   \n",
       "...                          ...                          ...   \n",
       "13995                          1                            1   \n",
       "13996                          0                            1   \n",
       "13997                          1                            1   \n",
       "13998                          1                            1   \n",
       "13999                          1                            1   \n",
       "\n",
       "       AUTHC_SCNDRY_STAT_TXT_CHALLENGE_ISSUED  \\\n",
       "0                                           0   \n",
       "1                                           0   \n",
       "2                                           0   \n",
       "3                                           0   \n",
       "4                                           0   \n",
       "...                                       ...   \n",
       "13995                                       0   \n",
       "13996                                       0   \n",
       "13997                                       0   \n",
       "13998                                       0   \n",
       "13999                                       0   \n",
       "\n",
       "       AUTHC_SCNDRY_STAT_TXT_CHALLENGE_SUCCESS  TXT_CASE_INT  TXT_CASE_MATCH  \\\n",
       "0                                            0             0               1   \n",
       "1                                            0             0               1   \n",
       "2                                            0             0               0   \n",
       "3                                            0             0               0   \n",
       "4                                            1             0               0   \n",
       "...                                        ...           ...             ...   \n",
       "13995                                        0             0               1   \n",
       "13996                                        0             0               0   \n",
       "13997                                        0             0               0   \n",
       "13998                                        0             0               0   \n",
       "13999                                        0             0               0   \n",
       "\n",
       "       TXT_CASE_MISMATCH  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      1  \n",
       "3                      1  \n",
       "4                      1  \n",
       "...                  ...  \n",
       "13995                  0  \n",
       "13996                  1  \n",
       "13997                  1  \n",
       "13998                  1  \n",
       "13999                  1  \n",
       "\n",
       "[14000 rows x 45 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Similar data cleaning process as above\n",
    "DfProc = trainDf\n",
    "\n",
    "carrMap = {\n",
    "    'cox communications inc.' : 'cox',\n",
    "    't-mobile usa  inc.' : 'tmobile',\n",
    "    'charter communications inc' : 'charter',\n",
    "    'comcast' : 'comcast',\n",
    "    'comcast cable communications  llc' : 'comcast',\n",
    "    'centurylink communications  llc' : 'century',\n",
    "    'frontier communications of america  inc.' : 'frontier',\n",
    "    'att services inc' : 'att',\n",
    "    'charter communications' : 'charter',\n",
    "    'at&t mobility llc ' : 'att',\n",
    "    'cellco partnership dba verizon wireless' : 'verizon',\n",
    "}\n",
    "\n",
    "regionSet = { 'southwest', 'south central', 'southeast', 'mountain',\n",
    "             'northeast', 'great lakes', 'mid atlantic', 'pacific northwest',\n",
    "             'midwest'}\n",
    "regionMap = {x:x for x in regionSet}\n",
    "    \n",
    "\n",
    "DfProc['CARR_NAME'] = DfProc['CARR_NAME'].map(carrMap).fillna(\"other\")\n",
    "DfProc['RGN_NAME'] = DfProc['RGN_NAME'].map(regionMap).fillna(\"other\")\n",
    "\n",
    "#ADDITIONAL FEATURE ENGINEERING - - - - - - - - - - - - \n",
    "\n",
    "#Normalize date features against transaction date\n",
    "# How old was the account when it made the transaction\n",
    "DfProc['DAY_ACC_AGE'] = (\n",
    "    DfProc['TRAN_TS'] - DfProc['CUST_SINCE_DT']).dt.days\n",
    "# How long was it been since the phone number was updated since the transaction\n",
    "DfProc['DAY_FRM_NUM_UPDT'] = (\n",
    "    DfProc['TRAN_TS'] - DfProc['PH_NUM_UPDT_TS']).dt.days\n",
    "# How long was it been since the password was updated since the transaction\n",
    "DfProc['DAY_FRM_PWD_UPDT'] = (\n",
    "    DfProc['TRAN_TS'] - DfProc['PWD_UPDT_TS']).dt.days\n",
    "\n",
    "# Cleaning \"region\" column to match entries in state column.\n",
    "# States were mapped to their abbreviations, if state outside US its mapped to\n",
    "# \"INT\" for international\n",
    "stateDict = {'nevada' : 'NV', 'california': 'CA', 'utah': 'UT', 'texas': 'TX','arizona': 'AZ', 'wisconsin': 'WI', 'minnesota': 'MN', 'phnum penh' : 'INT','alabama': 'AL', 'florida': 'FL', 'nebraska': 'NE', 'south dakota': 'SD',\n",
    " 'punjab': 'INT', 'north carolina': 'NC', 'new york': 'NY', 'michigan': 'MI','colorado': 'CO', 'massachusetts': 'MA', 'antioquia': 'INT', 'washington': 'WA','arkansas': 'AR', 'new jersey': 'NJ', 'kentucky': 'KY', 'ostergotlands lan': 'INT',\n",
    " 'tennessee': 'TN', 'district of columbia': 'DC', 'georgia': 'GA', 'maryland': 'MD','oregon': 'OR', 'wyoming': 'WY', 'oklahoma': 'OK', 'illinois': 'IL','north dakota': 'ND', 'indiana': 'IN', 'pennsylvania': 'PA', 'distrito nacional': 'INT',\n",
    " 'distrito capital': 'INT', 'iowa': 'IA', 'zuerich': 'INT', 'hamerkaz': 'INT','sonora': 'INT', 'madrid': 'INT', 'new mexico': 'NM', 'new south wales' : 'INT','loire-atlantique' : 'INT', 'carabobo' : 'INT', 'montana' : 'MT', 'idaho' : 'ID',\n",
    " 'hong kong' : 'INT', 'ohio' : 'OH', 'south carolina': 'SC', 'missouri': 'MS', 'colima': 'INT', 'baja california': 'INT', 'noord-brabant': 'INT', 'nairobi area': 'INT', 'baden-wuerttemberg': 'INT', 'virginia' : 'VA','alaska': 'AK', 'hawaii': 'HI', 'kansas': 'KS', 'greater accra': 'INT', 'kingston': 'INT', 'connecticut' : 'CT', 'louisiana': 'LA', 'bolivar': 'INT',\n",
    " 'lagos': 'INT', 'gujarat': 'INT', 'zulia': 'INT', 'morelos': 'INT', 'jalisco': 'INT', 'san salvador': 'INT', 'west bengal': 'INT', 'guerrero': 'INT', 'distrito federal': 'INT',\n",
    " 'mississippi': 'MS', \"saint george's\": 'INT', 'hampshire': 'NH', 'paris': 'INT','mazowieckie': 'INT', 'region metropolitana': 'INT', 'ha noi': 'INT', 'lara': 'INT','maine': 'ME', 'seoul teukbyeolsi': 'INT', 'telangana': 'INT', 'victoria': 'INT',\n",
    " 'kinshasa': 'INT', 'aguascalientes': 'INT', 'western australia': 'INT','andhra pradesh': 'INT', 'sao paulo': 'INT', 'nueva esparta': 'INT','dubayy': 'INT', 'chihuahua': 'INT', 'rhode island': 'ri', 'istanbul': 'INT','guatemala': 'INT', 'gauteng': 'INT', 'michoacan de ocampo': 'INT', \"ra's al khaymah\": 'INT',\n",
    " 'sodermanlands lan': 'INT', 'da nang': 'INT', 'taipei': 'INT','sindh': 'INT','tamaulipas': 'INT','sinaloa': 'INT','liverpool': 'INT','western cape': 'INT', 'aragua': 'INT', 'british columbia': 'INT', 'guanacaste': 'INT','`amman': 'INT',\n",
    " 'hessen': 'INT','ontario': 'INT','delaware': 'DE', 'dublin': 'INT', 'south west': 'INT', 'west virginia': 'WV', 'south australia': 'INT', 'delhi': 'INT', 'pichincha': 'INT', 'new providence': 'INT', 'tokyo': 'INT', 'nordrhein-westfalen' : 'INT'}\n",
    "\n",
    "# Use statedict to create column to describe where transaction originated from\n",
    "DfProc['TXT_STATE'] = DfProc['STATE_PRVNC_TXT'].map(stateDict).fillna(\"None\")\n",
    "\n",
    "#Function to apply to column of transaction location and customer location \n",
    "#To compare if the two match\n",
    "def locationCompare(txtLoc, custLoc):\n",
    "  if txtLoc != custLoc:\n",
    "    if txtLoc == 'INT':\n",
    "      return 'INT'\n",
    "    else:\n",
    "      return 'MISMATCH'\n",
    "  return 'MATCH'\n",
    "\n",
    "#Apply functino above to TXT state and CUST state column\n",
    "DfProc['TXT_CASE'] = DfProc.apply(\n",
    "    lambda x: locationCompare(x['TXT_STATE'], x['CUST_STATE']), axis=1)\n",
    "\n",
    "\n",
    "## This didn't really help Josh so let's skip it\n",
    "# #Read in external dataframe with data for each zip code\n",
    "# zipInfoDf = pd.read_csv('zip_code_rural.csv')\n",
    "# #Get population number (zpop) and population density (lzden )for each zip code\n",
    "# zipInfoDf = zipInfoDf[['zip', 'zpop', 'lzden']]\n",
    "# #Add this information to df\n",
    "# DfProc = DfProc.merge(zipInfoDf, how='left', left_on='CUST_ZIP', right_on='zip')\n",
    "\n",
    "\n",
    "#Similar process to above, we end up keeping the generated features\n",
    "#And removing a lot of the really detailed categorical variables\n",
    "categorical = ['CARR_NAME', 'RGN_NAME', 'STATE_PRVNC_TXT', 'ALERT_TRGR_CD',\n",
    "                'DVC_TYPE_TXT', 'AUTHC_PRIM_TYPE_CD', 'AUTHC_SCNDRY_STAT_TXT',\n",
    "                'CUST_STATE', 'TXT_CASE']\n",
    "\n",
    "remove = ['PWD_UPDT_TS', 'PH_NUM_UPDT_TS', 'CUST_SINCE_DT','TRAN_TS','TRAN_DT',\n",
    "          'CUST_STATE', 'STATE_PRVNC_TXT', 'TXT_STATE', 'CUST_ZIP', 'zip']\n",
    "\n",
    "\n",
    "categoricalDummies = [x for x in categorical if x not in remove]\n",
    "\n",
    "for var in categoricalDummies:\n",
    "    cat_list = pd.get_dummies(DfProc[var], prefix=var)\n",
    "    DfProc=DfProc.join(cat_list)\n",
    "data_vars=DfProc.columns.values.tolist()\n",
    "to_keep=[i for i in data_vars if i not in categorical and i not in remove]\n",
    "DfProc=DfProc[to_keep]\n",
    "\n",
    "DfProc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7621eb23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = DfProc.loc[:, DfProc.columns != 'FRAUD_NONFRAUD'].astype(float)\n",
    "scaler = StandardScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X))\n",
    "Y = DfProc['FRAUD_NONFRAUD']\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "encoded_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf9a7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "msno.matrix(X.sample(250))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fc4407c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.849367</td>\n",
       "      <td>0.446727</td>\n",
       "      <td>-0.368429</td>\n",
       "      <td>-0.294369</td>\n",
       "      <td>3.241988</td>\n",
       "      <td>0.418580</td>\n",
       "      <td>-1.219265e+00</td>\n",
       "      <td>1.375457e+00</td>\n",
       "      <td>-0.201835</td>\n",
       "      <td>-0.25583</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.232845</td>\n",
       "      <td>-0.402635</td>\n",
       "      <td>-0.229588</td>\n",
       "      <td>0.573391</td>\n",
       "      <td>0.247323</td>\n",
       "      <td>-0.079077</td>\n",
       "      <td>-0.219943</td>\n",
       "      <td>-0.132905</td>\n",
       "      <td>2.237987</td>\n",
       "      <td>-2.107396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.661215</td>\n",
       "      <td>-0.341486</td>\n",
       "      <td>-0.474647</td>\n",
       "      <td>-0.183982</td>\n",
       "      <td>3.158167</td>\n",
       "      <td>1.991848</td>\n",
       "      <td>-9.161884e-17</td>\n",
       "      <td>-1.176828e-17</td>\n",
       "      <td>-0.201835</td>\n",
       "      <td>-0.25583</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.232845</td>\n",
       "      <td>2.483638</td>\n",
       "      <td>-0.229588</td>\n",
       "      <td>-1.744010</td>\n",
       "      <td>0.247323</td>\n",
       "      <td>-0.079077</td>\n",
       "      <td>-0.219943</td>\n",
       "      <td>-0.132905</td>\n",
       "      <td>2.237987</td>\n",
       "      <td>-2.107396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.693775</td>\n",
       "      <td>0.812161</td>\n",
       "      <td>-0.952629</td>\n",
       "      <td>0.147176</td>\n",
       "      <td>1.376969</td>\n",
       "      <td>0.335996</td>\n",
       "      <td>2.377816e-01</td>\n",
       "      <td>-1.435870e+00</td>\n",
       "      <td>-0.201835</td>\n",
       "      <td>-0.25583</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.232845</td>\n",
       "      <td>-0.402635</td>\n",
       "      <td>-0.229588</td>\n",
       "      <td>0.573391</td>\n",
       "      <td>0.247323</td>\n",
       "      <td>-0.079077</td>\n",
       "      <td>-0.219943</td>\n",
       "      <td>-0.132905</td>\n",
       "      <td>-0.446830</td>\n",
       "      <td>0.474519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.866261</td>\n",
       "      <td>-0.341486</td>\n",
       "      <td>0.428207</td>\n",
       "      <td>-0.404755</td>\n",
       "      <td>0.335192</td>\n",
       "      <td>-0.201198</td>\n",
       "      <td>7.005543e-01</td>\n",
       "      <td>1.178590e-01</td>\n",
       "      <td>-0.201835</td>\n",
       "      <td>-0.25583</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.232845</td>\n",
       "      <td>-0.402635</td>\n",
       "      <td>-0.229588</td>\n",
       "      <td>0.573391</td>\n",
       "      <td>0.247323</td>\n",
       "      <td>-0.079077</td>\n",
       "      <td>-0.219943</td>\n",
       "      <td>-0.132905</td>\n",
       "      <td>-0.446830</td>\n",
       "      <td>0.474519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.697438</td>\n",
       "      <td>0.083162</td>\n",
       "      <td>1.437280</td>\n",
       "      <td>-0.515141</td>\n",
       "      <td>0.724362</td>\n",
       "      <td>0.858301</td>\n",
       "      <td>-4.243041e-01</td>\n",
       "      <td>-5.917030e-01</td>\n",
       "      <td>-0.201835</td>\n",
       "      <td>-0.25583</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.232845</td>\n",
       "      <td>-0.402635</td>\n",
       "      <td>-0.229588</td>\n",
       "      <td>0.573391</td>\n",
       "      <td>-4.043291</td>\n",
       "      <td>-0.079077</td>\n",
       "      <td>4.546628</td>\n",
       "      <td>-0.132905</td>\n",
       "      <td>-0.446830</td>\n",
       "      <td>0.474519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13995</th>\n",
       "      <td>5.227844</td>\n",
       "      <td>-0.333786</td>\n",
       "      <td>0.056444</td>\n",
       "      <td>-0.294369</td>\n",
       "      <td>-0.702094</td>\n",
       "      <td>-0.201595</td>\n",
       "      <td>1.685665e+00</td>\n",
       "      <td>-1.176828e-17</td>\n",
       "      <td>-0.201835</td>\n",
       "      <td>-0.25583</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.232845</td>\n",
       "      <td>-0.402635</td>\n",
       "      <td>-0.229588</td>\n",
       "      <td>0.573391</td>\n",
       "      <td>0.247323</td>\n",
       "      <td>-0.079077</td>\n",
       "      <td>-0.219943</td>\n",
       "      <td>-0.132905</td>\n",
       "      <td>2.237987</td>\n",
       "      <td>-2.107396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13996</th>\n",
       "      <td>-0.506472</td>\n",
       "      <td>-0.341486</td>\n",
       "      <td>-0.527757</td>\n",
       "      <td>0.367949</td>\n",
       "      <td>-0.507509</td>\n",
       "      <td>-0.835667</td>\n",
       "      <td>-9.161884e-17</td>\n",
       "      <td>1.594671e+00</td>\n",
       "      <td>-0.201835</td>\n",
       "      <td>-0.25583</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.232845</td>\n",
       "      <td>2.483638</td>\n",
       "      <td>-0.229588</td>\n",
       "      <td>-1.744010</td>\n",
       "      <td>0.247323</td>\n",
       "      <td>-0.079077</td>\n",
       "      <td>-0.219943</td>\n",
       "      <td>-0.132905</td>\n",
       "      <td>-0.446830</td>\n",
       "      <td>0.474519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13997</th>\n",
       "      <td>0.684603</td>\n",
       "      <td>-0.246425</td>\n",
       "      <td>0.003334</td>\n",
       "      <td>-0.404755</td>\n",
       "      <td>-0.140792</td>\n",
       "      <td>1.015330</td>\n",
       "      <td>-1.395669e+00</td>\n",
       "      <td>-9.743665e-01</td>\n",
       "      <td>4.954538</td>\n",
       "      <td>-0.25583</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.232845</td>\n",
       "      <td>-0.402635</td>\n",
       "      <td>-0.229588</td>\n",
       "      <td>0.573391</td>\n",
       "      <td>0.247323</td>\n",
       "      <td>-0.079077</td>\n",
       "      <td>-0.219943</td>\n",
       "      <td>-0.132905</td>\n",
       "      <td>-0.446830</td>\n",
       "      <td>0.474519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13998</th>\n",
       "      <td>0.680325</td>\n",
       "      <td>-0.235926</td>\n",
       "      <td>-1.749266</td>\n",
       "      <td>-0.404755</td>\n",
       "      <td>-0.914640</td>\n",
       "      <td>-1.620812</td>\n",
       "      <td>-9.161884e-17</td>\n",
       "      <td>-1.013552e-01</td>\n",
       "      <td>-0.201835</td>\n",
       "      <td>-0.25583</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.232845</td>\n",
       "      <td>-0.402635</td>\n",
       "      <td>-0.229588</td>\n",
       "      <td>0.573391</td>\n",
       "      <td>0.247323</td>\n",
       "      <td>-0.079077</td>\n",
       "      <td>-0.219943</td>\n",
       "      <td>-0.132905</td>\n",
       "      <td>-0.446830</td>\n",
       "      <td>0.474519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13999</th>\n",
       "      <td>-0.847354</td>\n",
       "      <td>-0.341486</td>\n",
       "      <td>0.321989</td>\n",
       "      <td>-0.073596</td>\n",
       "      <td>0.498344</td>\n",
       "      <td>-1.047488</td>\n",
       "      <td>-9.161884e-17</td>\n",
       "      <td>-1.176828e-17</td>\n",
       "      <td>-0.201835</td>\n",
       "      <td>-0.25583</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.232845</td>\n",
       "      <td>-0.402635</td>\n",
       "      <td>-0.229588</td>\n",
       "      <td>0.573391</td>\n",
       "      <td>0.247323</td>\n",
       "      <td>-0.079077</td>\n",
       "      <td>-0.219943</td>\n",
       "      <td>-0.132905</td>\n",
       "      <td>-0.446830</td>\n",
       "      <td>0.474519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14000 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5   \\\n",
       "0     -0.849367  0.446727 -0.368429 -0.294369  3.241988  0.418580   \n",
       "1     -0.661215 -0.341486 -0.474647 -0.183982  3.158167  1.991848   \n",
       "2     -0.693775  0.812161 -0.952629  0.147176  1.376969  0.335996   \n",
       "3     -0.866261 -0.341486  0.428207 -0.404755  0.335192 -0.201198   \n",
       "4      0.697438  0.083162  1.437280 -0.515141  0.724362  0.858301   \n",
       "...         ...       ...       ...       ...       ...       ...   \n",
       "13995  5.227844 -0.333786  0.056444 -0.294369 -0.702094 -0.201595   \n",
       "13996 -0.506472 -0.341486 -0.527757  0.367949 -0.507509 -0.835667   \n",
       "13997  0.684603 -0.246425  0.003334 -0.404755 -0.140792  1.015330   \n",
       "13998  0.680325 -0.235926 -1.749266 -0.404755 -0.914640 -1.620812   \n",
       "13999 -0.847354 -0.341486  0.321989 -0.073596  0.498344 -1.047488   \n",
       "\n",
       "                 6             7         8        9   ...        34        35  \\\n",
       "0     -1.219265e+00  1.375457e+00 -0.201835 -0.25583  ... -0.232845 -0.402635   \n",
       "1     -9.161884e-17 -1.176828e-17 -0.201835 -0.25583  ... -0.232845  2.483638   \n",
       "2      2.377816e-01 -1.435870e+00 -0.201835 -0.25583  ... -0.232845 -0.402635   \n",
       "3      7.005543e-01  1.178590e-01 -0.201835 -0.25583  ... -0.232845 -0.402635   \n",
       "4     -4.243041e-01 -5.917030e-01 -0.201835 -0.25583  ... -0.232845 -0.402635   \n",
       "...             ...           ...       ...      ...  ...       ...       ...   \n",
       "13995  1.685665e+00 -1.176828e-17 -0.201835 -0.25583  ... -0.232845 -0.402635   \n",
       "13996 -9.161884e-17  1.594671e+00 -0.201835 -0.25583  ... -0.232845  2.483638   \n",
       "13997 -1.395669e+00 -9.743665e-01  4.954538 -0.25583  ... -0.232845 -0.402635   \n",
       "13998 -9.161884e-17 -1.013552e-01 -0.201835 -0.25583  ... -0.232845 -0.402635   \n",
       "13999 -9.161884e-17 -1.176828e-17 -0.201835 -0.25583  ... -0.232845 -0.402635   \n",
       "\n",
       "             36        37        38        39        40        41        42  \\\n",
       "0     -0.229588  0.573391  0.247323 -0.079077 -0.219943 -0.132905  2.237987   \n",
       "1     -0.229588 -1.744010  0.247323 -0.079077 -0.219943 -0.132905  2.237987   \n",
       "2     -0.229588  0.573391  0.247323 -0.079077 -0.219943 -0.132905 -0.446830   \n",
       "3     -0.229588  0.573391  0.247323 -0.079077 -0.219943 -0.132905 -0.446830   \n",
       "4     -0.229588  0.573391 -4.043291 -0.079077  4.546628 -0.132905 -0.446830   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "13995 -0.229588  0.573391  0.247323 -0.079077 -0.219943 -0.132905  2.237987   \n",
       "13996 -0.229588 -1.744010  0.247323 -0.079077 -0.219943 -0.132905 -0.446830   \n",
       "13997 -0.229588  0.573391  0.247323 -0.079077 -0.219943 -0.132905 -0.446830   \n",
       "13998 -0.229588  0.573391  0.247323 -0.079077 -0.219943 -0.132905 -0.446830   \n",
       "13999 -0.229588  0.573391  0.247323 -0.079077 -0.219943 -0.132905 -0.446830   \n",
       "\n",
       "             43  \n",
       "0     -2.107396  \n",
       "1     -2.107396  \n",
       "2      0.474519  \n",
       "3      0.474519  \n",
       "4      0.474519  \n",
       "...         ...  \n",
       "13995 -2.107396  \n",
       "13996  0.474519  \n",
       "13997  0.474519  \n",
       "13998  0.474519  \n",
       "13999  0.474519  \n",
       "\n",
       "[14000 rows x 44 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_mean_imputed = X.fillna(X.mean())\n",
    "X_mean_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eaf1b0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, input_dim = 44, activation='relu')) # 2 Layers Right Now\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "        model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b250dc66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.6371 - accuracy: 0.6483\n",
      "Epoch 2/50\n",
      "99/99 [==============================] - 0s 984us/step - loss: 0.4080 - accuracy: 0.8271\n",
      "Epoch 3/50\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.3353 - accuracy: 0.85 - 0s 849us/step - loss: 0.3349 - accuracy: 0.8533\n",
      "Epoch 4/50\n",
      "99/99 [==============================] - 0s 917us/step - loss: 0.3016 - accuracy: 0.8684\n",
      "Epoch 5/50\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.2804 - accuracy: 0.8768\n",
      "Epoch 6/50\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.2655 - accuracy: 0.8840\n",
      "Epoch 7/50\n",
      "99/99 [==============================] - 0s 989us/step - loss: 0.2559 - accuracy: 0.8891\n",
      "Epoch 8/50\n",
      "99/99 [==============================] - 0s 918us/step - loss: 0.2503 - accuracy: 0.8929\n",
      "Epoch 9/50\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.2454 - accuracy: 0.8964\n",
      "Epoch 10/50\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.2424 - accuracy: 0.8986\n",
      "Epoch 11/50\n",
      "99/99 [==============================] - 0s 991us/step - loss: 0.2397 - accuracy: 0.9011\n",
      "Epoch 12/50\n",
      "99/99 [==============================] - 0s 815us/step - loss: 0.2372 - accuracy: 0.9006\n",
      "Epoch 13/50\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.2353 - accuracy: 0.9017\n",
      "Epoch 14/50\n",
      "99/99 [==============================] - 0s 915us/step - loss: 0.2338 - accuracy: 0.9023\n",
      "Epoch 15/50\n",
      "99/99 [==============================] - 0s 849us/step - loss: 0.2320 - accuracy: 0.9020\n",
      "Epoch 16/50\n",
      "99/99 [==============================] - 0s 919us/step - loss: 0.2307 - accuracy: 0.9044\n",
      "Epoch 17/50\n",
      "99/99 [==============================] - 0s 918us/step - loss: 0.2296 - accuracy: 0.9044\n",
      "Epoch 18/50\n",
      "99/99 [==============================] - 0s 918us/step - loss: 0.2283 - accuracy: 0.9067\n",
      "Epoch 19/50\n",
      "99/99 [==============================] - 0s 917us/step - loss: 0.2273 - accuracy: 0.9063\n",
      "Epoch 20/50\n",
      "99/99 [==============================] - 0s 816us/step - loss: 0.2262 - accuracy: 0.9063\n",
      "Epoch 21/50\n",
      "99/99 [==============================] - 0s 921us/step - loss: 0.2258 - accuracy: 0.9072\n",
      "Epoch 22/50\n",
      "99/99 [==============================] - 0s 882us/step - loss: 0.2249 - accuracy: 0.9068\n",
      "Epoch 23/50\n",
      "99/99 [==============================] - 0s 714us/step - loss: 0.2235 - accuracy: 0.9071\n",
      "Epoch 24/50\n",
      "99/99 [==============================] - 0s 919us/step - loss: 0.2228 - accuracy: 0.9087\n",
      "Epoch 25/50\n",
      "99/99 [==============================] - 0s 813us/step - loss: 0.2222 - accuracy: 0.9091\n",
      "Epoch 26/50\n",
      "99/99 [==============================] - 0s 819us/step - loss: 0.2219 - accuracy: 0.9082\n",
      "Epoch 27/50\n",
      "99/99 [==============================] - 0s 817us/step - loss: 0.2210 - accuracy: 0.9090\n",
      "Epoch 28/50\n",
      "99/99 [==============================] - 0s 817us/step - loss: 0.2200 - accuracy: 0.9095\n",
      "Epoch 29/50\n",
      "99/99 [==============================] - 0s 920us/step - loss: 0.2201 - accuracy: 0.9095\n",
      "Epoch 30/50\n",
      "99/99 [==============================] - 0s 917us/step - loss: 0.2194 - accuracy: 0.9102\n",
      "Epoch 31/50\n",
      "99/99 [==============================] - 0s 919us/step - loss: 0.2185 - accuracy: 0.9096\n",
      "Epoch 32/50\n",
      "99/99 [==============================] - 0s 816us/step - loss: 0.2179 - accuracy: 0.9106\n",
      "Epoch 33/50\n",
      "99/99 [==============================] - 0s 812us/step - loss: 0.2175 - accuracy: 0.9102\n",
      "Epoch 34/50\n",
      "99/99 [==============================] - 0s 817us/step - loss: 0.2171 - accuracy: 0.9107\n",
      "Epoch 35/50\n",
      "99/99 [==============================] - 0s 915us/step - loss: 0.2162 - accuracy: 0.9094\n",
      "Epoch 36/50\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.2157 - accuracy: 0.9101\n",
      "Epoch 37/50\n",
      "99/99 [==============================] - 0s 817us/step - loss: 0.2152 - accuracy: 0.9110\n",
      "Epoch 38/50\n",
      "99/99 [==============================] - 0s 816us/step - loss: 0.2147 - accuracy: 0.9110\n",
      "Epoch 39/50\n",
      "99/99 [==============================] - 0s 905us/step - loss: 0.2145 - accuracy: 0.9115\n",
      "Epoch 40/50\n",
      "99/99 [==============================] - 0s 885us/step - loss: 0.2141 - accuracy: 0.9115\n",
      "Epoch 41/50\n",
      "99/99 [==============================] - 0s 855us/step - loss: 0.2134 - accuracy: 0.9117\n",
      "Epoch 42/50\n",
      "99/99 [==============================] - 0s 825us/step - loss: 0.2128 - accuracy: 0.9119\n",
      "Epoch 43/50\n",
      "99/99 [==============================] - 0s 683us/step - loss: 0.2123 - accuracy: 0.9115\n",
      "Epoch 44/50\n",
      "99/99 [==============================] - 0s 815us/step - loss: 0.2120 - accuracy: 0.9133\n",
      "Epoch 45/50\n",
      "99/99 [==============================] - 0s 919us/step - loss: 0.2118 - accuracy: 0.9128\n",
      "Epoch 46/50\n",
      "99/99 [==============================] - 0s 815us/step - loss: 0.2112 - accuracy: 0.9134\n",
      "Epoch 47/50\n",
      "99/99 [==============================] - 0s 921us/step - loss: 0.2111 - accuracy: 0.9121\n",
      "Epoch 48/50\n",
      "99/99 [==============================] - 0s 815us/step - loss: 0.2107 - accuracy: 0.9121\n",
      "Epoch 49/50\n",
      "99/99 [==============================] - 0s 817us/step - loss: 0.2103 - accuracy: 0.9129\n",
      "Epoch 50/50\n",
      "99/99 [==============================] - 0s 814us/step - loss: 0.2098 - accuracy: 0.9133\n",
      "Epoch 1/50\n",
      "99/99 [==============================] - 0s 919us/step - loss: 0.5487 - accuracy: 0.7414\n",
      "Epoch 2/50\n",
      "99/99 [==============================] - 0s 923us/step - loss: 0.3855 - accuracy: 0.8249\n",
      "Epoch 3/50\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.3414 - accuracy: 0.8469\n",
      "Epoch 4/50\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.3204 - accuracy: 0.8564\n",
      "Epoch 5/50\n",
      "99/99 [==============================] - 0s 814us/step - loss: 0.3053 - accuracy: 0.8650\n",
      "Epoch 6/50\n",
      "99/99 [==============================] - 0s 821us/step - loss: 0.2918 - accuracy: 0.8723\n",
      "Epoch 7/50\n",
      "99/99 [==============================] - 0s 819us/step - loss: 0.2792 - accuracy: 0.8802\n",
      "Epoch 8/50\n",
      "99/99 [==============================] - 0s 817us/step - loss: 0.2685 - accuracy: 0.8851\n",
      "Epoch 9/50\n",
      "99/99 [==============================] - 0s 714us/step - loss: 0.2599 - accuracy: 0.8890\n",
      "Epoch 10/50\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.2529 - accuracy: 0.89 - 0s 919us/step - loss: 0.2541 - accuracy: 0.8925\n",
      "Epoch 11/50\n",
      "99/99 [==============================] - 0s 815us/step - loss: 0.2499 - accuracy: 0.8959\n",
      "Epoch 12/50\n",
      "99/99 [==============================] - 0s 826us/step - loss: 0.2471 - accuracy: 0.8972\n",
      "Epoch 13/50\n",
      "99/99 [==============================] - 0s 919us/step - loss: 0.2444 - accuracy: 0.8996\n",
      "Epoch 14/50\n",
      "99/99 [==============================] - 0s 816us/step - loss: 0.2429 - accuracy: 0.8997\n",
      "Epoch 15/50\n",
      "99/99 [==============================] - 0s 813us/step - loss: 0.2410 - accuracy: 0.8997\n",
      "Epoch 16/50\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.2394 - accuracy: 0.9017\n",
      "Epoch 17/50\n",
      "99/99 [==============================] - 0s 816us/step - loss: 0.2379 - accuracy: 0.9014\n",
      "Epoch 18/50\n",
      "99/99 [==============================] - 0s 919us/step - loss: 0.2364 - accuracy: 0.9017\n",
      "Epoch 19/50\n",
      "99/99 [==============================] - 0s 817us/step - loss: 0.2352 - accuracy: 0.9029\n",
      "Epoch 20/50\n",
      "99/99 [==============================] - 0s 907us/step - loss: 0.2342 - accuracy: 0.9029\n",
      "Epoch 21/50\n",
      "99/99 [==============================] - 0s 818us/step - loss: 0.2332 - accuracy: 0.9044\n",
      "Epoch 22/50\n",
      "99/99 [==============================] - 0s 917us/step - loss: 0.2321 - accuracy: 0.9035\n",
      "Epoch 23/50\n",
      "99/99 [==============================] - 0s 816us/step - loss: 0.2314 - accuracy: 0.9044\n",
      "Epoch 24/50\n",
      "99/99 [==============================] - 0s 816us/step - loss: 0.2306 - accuracy: 0.9048\n",
      "Epoch 25/50\n",
      "99/99 [==============================] - 0s 817us/step - loss: 0.2297 - accuracy: 0.9040\n",
      "Epoch 26/50\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.2293 - accuracy: 0.9039\n",
      "Epoch 27/50\n",
      "99/99 [==============================] - 0s 818us/step - loss: 0.2288 - accuracy: 0.9042\n",
      "Epoch 28/50\n",
      "99/99 [==============================] - 0s 919us/step - loss: 0.2278 - accuracy: 0.9048\n",
      "Epoch 29/50\n",
      "99/99 [==============================] - 0s 918us/step - loss: 0.2273 - accuracy: 0.9065\n",
      "Epoch 30/50\n",
      "99/99 [==============================] - 0s 919us/step - loss: 0.2266 - accuracy: 0.9044\n",
      "Epoch 31/50\n",
      "99/99 [==============================] - 0s 918us/step - loss: 0.2262 - accuracy: 0.9052\n",
      "Epoch 32/50\n",
      "99/99 [==============================] - 0s 816us/step - loss: 0.2256 - accuracy: 0.9061\n",
      "Epoch 33/50\n",
      "99/99 [==============================] - 0s 713us/step - loss: 0.2252 - accuracy: 0.9067\n",
      "Epoch 34/50\n",
      "99/99 [==============================] - 0s 919us/step - loss: 0.2248 - accuracy: 0.9065\n",
      "Epoch 35/50\n",
      "99/99 [==============================] - 0s 919us/step - loss: 0.2242 - accuracy: 0.9059\n",
      "Epoch 36/50\n",
      "99/99 [==============================] - 0s 918us/step - loss: 0.2239 - accuracy: 0.9073\n",
      "Epoch 37/50\n",
      "99/99 [==============================] - 0s 817us/step - loss: 0.2234 - accuracy: 0.9059\n",
      "Epoch 38/50\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.2228 - accuracy: 0.9073\n",
      "Epoch 39/50\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.2221 - accuracy: 0.9062\n",
      "Epoch 40/50\n",
      "99/99 [==============================] - 0s 817us/step - loss: 0.2219 - accuracy: 0.9076\n",
      "Epoch 41/50\n",
      "99/99 [==============================] - 0s 917us/step - loss: 0.2216 - accuracy: 0.9079\n",
      "Epoch 42/50\n",
      "99/99 [==============================] - 0s 917us/step - loss: 0.2216 - accuracy: 0.9078\n",
      "Epoch 43/50\n",
      "99/99 [==============================] - 0s 921us/step - loss: 0.2211 - accuracy: 0.9081\n",
      "Epoch 44/50\n",
      "99/99 [==============================] - 0s 920us/step - loss: 0.2209 - accuracy: 0.9079\n",
      "Epoch 45/50\n",
      "99/99 [==============================] - 0s 918us/step - loss: 0.2207 - accuracy: 0.9080\n",
      "Epoch 46/50\n",
      "99/99 [==============================] - 0s 918us/step - loss: 0.2200 - accuracy: 0.9080\n",
      "Epoch 47/50\n",
      "99/99 [==============================] - 0s 814us/step - loss: 0.2197 - accuracy: 0.9075\n",
      "Epoch 48/50\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.2192 - accuracy: 0.9088\n",
      "Epoch 49/50\n",
      "99/99 [==============================] - 0s 817us/step - loss: 0.2192 - accuracy: 0.9083\n",
      "Epoch 50/50\n",
      "99/99 [==============================] - 0s 816us/step - loss: 0.2188 - accuracy: 0.9096\n",
      "Epoch 1/50\n",
      "99/99 [==============================] - 0s 919us/step - loss: 0.5504 - accuracy: 0.6910\n",
      "Epoch 2/50\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.3856 - accuracy: 0.8206\n",
      "Epoch 3/50\n",
      "99/99 [==============================] - 0s 919us/step - loss: 0.3317 - accuracy: 0.8468\n",
      "Epoch 4/50\n",
      "99/99 [==============================] - 0s 918us/step - loss: 0.3023 - accuracy: 0.8656\n",
      "Epoch 5/50\n",
      "99/99 [==============================] - 0s 818us/step - loss: 0.2842 - accuracy: 0.8759\n",
      "Epoch 6/50\n",
      "99/99 [==============================] - 0s 817us/step - loss: 0.2713 - accuracy: 0.8828\n",
      "Epoch 7/50\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.2616 - accuracy: 0.8883\n",
      "Epoch 8/50\n",
      "99/99 [==============================] - 0s 921us/step - loss: 0.2550 - accuracy: 0.8906\n",
      "Epoch 9/50\n",
      "99/99 [==============================] - 0s 813us/step - loss: 0.2499 - accuracy: 0.8915\n",
      "Epoch 10/50\n",
      "99/99 [==============================] - 0s 816us/step - loss: 0.2465 - accuracy: 0.8933\n",
      "Epoch 11/50\n",
      "99/99 [==============================] - 0s 918us/step - loss: 0.2434 - accuracy: 0.8968\n",
      "Epoch 12/50\n",
      "99/99 [==============================] - 0s 916us/step - loss: 0.2405 - accuracy: 0.8982\n",
      "Epoch 13/50\n",
      "99/99 [==============================] - 0s 813us/step - loss: 0.2382 - accuracy: 0.8994\n",
      "Epoch 14/50\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.2361 - accuracy: 0.9011\n",
      "Epoch 15/50\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.2348 - accuracy: 0.9019\n",
      "Epoch 16/50\n",
      "99/99 [==============================] - 0s 815us/step - loss: 0.2331 - accuracy: 0.9026\n",
      "Epoch 17/50\n",
      "99/99 [==============================] - 0s 919us/step - loss: 0.2318 - accuracy: 0.9036\n",
      "Epoch 18/50\n",
      "99/99 [==============================] - 0s 919us/step - loss: 0.2305 - accuracy: 0.9052\n",
      "Epoch 19/50\n",
      "99/99 [==============================] - 0s 915us/step - loss: 0.2291 - accuracy: 0.9046\n",
      "Epoch 20/50\n",
      "99/99 [==============================] - 0s 833us/step - loss: 0.2282 - accuracy: 0.9059\n",
      "Epoch 21/50\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.2258 - accuracy: 0.90 - 0s 1ms/step - loss: 0.2273 - accuracy: 0.9060\n",
      "Epoch 22/50\n",
      "99/99 [==============================] - 0s 934us/step - loss: 0.2268 - accuracy: 0.9060\n",
      "Epoch 23/50\n",
      "99/99 [==============================] - 0s 900us/step - loss: 0.2256 - accuracy: 0.9062\n",
      "Epoch 24/50\n",
      "99/99 [==============================] - 0s 796us/step - loss: 0.2253 - accuracy: 0.9078\n",
      "Epoch 25/50\n",
      "99/99 [==============================] - 0s 920us/step - loss: 0.2241 - accuracy: 0.9086\n",
      "Epoch 26/50\n",
      "99/99 [==============================] - 0s 920us/step - loss: 0.2239 - accuracy: 0.9083\n",
      "Epoch 27/50\n",
      "99/99 [==============================] - 0s 918us/step - loss: 0.2232 - accuracy: 0.9086\n",
      "Epoch 28/50\n",
      "99/99 [==============================] - 0s 914us/step - loss: 0.2225 - accuracy: 0.9089\n",
      "Epoch 29/50\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.2222 - accuracy: 0.9094\n",
      "Epoch 30/50\n",
      "99/99 [==============================] - 0s 921us/step - loss: 0.2213 - accuracy: 0.9088\n",
      "Epoch 31/50\n",
      "99/99 [==============================] - 0s 916us/step - loss: 0.2209 - accuracy: 0.9089\n",
      "Epoch 32/50\n",
      "99/99 [==============================] - 0s 924us/step - loss: 0.2205 - accuracy: 0.9097\n",
      "Epoch 33/50\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.2202 - accuracy: 0.9089\n",
      "Epoch 34/50\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.2193 - accuracy: 0.9087\n",
      "Epoch 35/50\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.2190 - accuracy: 0.9101\n",
      "Epoch 36/50\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.2186 - accuracy: 0.9106\n",
      "Epoch 37/50\n",
      "99/99 [==============================] - 0s 915us/step - loss: 0.2182 - accuracy: 0.9109\n",
      "Epoch 38/50\n",
      "99/99 [==============================] - 0s 817us/step - loss: 0.2176 - accuracy: 0.9108\n",
      "Epoch 39/50\n",
      "99/99 [==============================] - 0s 817us/step - loss: 0.2171 - accuracy: 0.9104\n",
      "Epoch 40/50\n",
      "99/99 [==============================] - 0s 918us/step - loss: 0.2165 - accuracy: 0.9119\n",
      "Epoch 41/50\n",
      "99/99 [==============================] - 0s 918us/step - loss: 0.2163 - accuracy: 0.9102\n",
      "Epoch 42/50\n",
      "99/99 [==============================] - 0s 916us/step - loss: 0.2159 - accuracy: 0.9107\n",
      "Epoch 43/50\n",
      "99/99 [==============================] - 0s 952us/step - loss: 0.2151 - accuracy: 0.9118\n",
      "Epoch 44/50\n",
      "99/99 [==============================] - 0s 955us/step - loss: 0.2150 - accuracy: 0.9120\n",
      "Epoch 45/50\n",
      "99/99 [==============================] - 0s 956us/step - loss: 0.2151 - accuracy: 0.9116\n",
      "Epoch 46/50\n",
      "99/99 [==============================] - 0s 984us/step - loss: 0.2145 - accuracy: 0.9108\n",
      "Epoch 47/50\n",
      "99/99 [==============================] - 0s 816us/step - loss: 0.2139 - accuracy: 0.9118\n",
      "Epoch 48/50\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.2135 - accuracy: 0.9113\n",
      "Epoch 49/50\n",
      "99/99 [==============================] - 0s 919us/step - loss: 0.2133 - accuracy: 0.9112\n",
      "Epoch 50/50\n",
      "99/99 [==============================] - 0s 917us/step - loss: 0.2129 - accuracy: 0.9124\n",
      "Epoch 1/50\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.5907 - accuracy: 0.6958\n",
      "Epoch 2/50\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.4089 - accuracy: 0.8184\n",
      "Epoch 3/50\n",
      "99/99 [==============================] - 0s 961us/step - loss: 0.3412 - accuracy: 0.8460\n",
      "Epoch 4/50\n",
      "99/99 [==============================] - 0s 832us/step - loss: 0.3100 - accuracy: 0.8628\n",
      "Epoch 5/50\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.2911 - accuracy: 0.87 - 0s 864us/step - loss: 0.2914 - accuracy: 0.8702\n",
      "Epoch 6/50\n",
      "99/99 [==============================] - 0s 843us/step - loss: 0.2779 - accuracy: 0.8783\n",
      "Epoch 7/50\n",
      "99/99 [==============================] - 0s 899us/step - loss: 0.2678 - accuracy: 0.8829\n",
      "Epoch 8/50\n",
      "99/99 [==============================] - 0s 893us/step - loss: 0.2603 - accuracy: 0.8862\n",
      "Epoch 9/50\n",
      "99/99 [==============================] - 0s 903us/step - loss: 0.2550 - accuracy: 0.8895\n",
      "Epoch 10/50\n",
      "99/99 [==============================] - 0s 960us/step - loss: 0.2511 - accuracy: 0.8920\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 0s 945us/step - loss: 0.2480 - accuracy: 0.8943\n",
      "Epoch 12/50\n",
      "99/99 [==============================] - 0s 966us/step - loss: 0.2453 - accuracy: 0.8948\n",
      "Epoch 13/50\n",
      "99/99 [==============================] - 0s 839us/step - loss: 0.2432 - accuracy: 0.8969\n",
      "Epoch 14/50\n",
      "99/99 [==============================] - 0s 897us/step - loss: 0.2409 - accuracy: 0.8993\n",
      "Epoch 15/50\n",
      "99/99 [==============================] - 0s 856us/step - loss: 0.2391 - accuracy: 0.8987\n",
      "Epoch 16/50\n",
      "99/99 [==============================] - 0s 962us/step - loss: 0.2374 - accuracy: 0.9009\n",
      "Epoch 17/50\n",
      "99/99 [==============================] - 0s 899us/step - loss: 0.2362 - accuracy: 0.9022\n",
      "Epoch 18/50\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.2355 - accuracy: 0.9029\n",
      "Epoch 19/50\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.2344 - accuracy: 0.9033\n",
      "Epoch 20/50\n",
      "99/99 [==============================] - 0s 958us/step - loss: 0.2330 - accuracy: 0.9033\n",
      "Epoch 21/50\n",
      "99/99 [==============================] - 0s 956us/step - loss: 0.2321 - accuracy: 0.9044\n",
      "Epoch 22/50\n",
      "99/99 [==============================] - 0s 964us/step - loss: 0.2314 - accuracy: 0.9039\n",
      "Epoch 23/50\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.2309 - accuracy: 0.9048\n",
      "Epoch 24/50\n",
      "99/99 [==============================] - 0s 808us/step - loss: 0.2300 - accuracy: 0.9052\n",
      "Epoch 25/50\n",
      "99/99 [==============================] - 0s 841us/step - loss: 0.2292 - accuracy: 0.9057\n",
      "Epoch 26/50\n",
      "99/99 [==============================] - 0s 895us/step - loss: 0.2283 - accuracy: 0.9050\n",
      "Epoch 27/50\n",
      "99/99 [==============================] - 0s 837us/step - loss: 0.2273 - accuracy: 0.9056\n",
      "Epoch 28/50\n",
      "99/99 [==============================] - 0s 903us/step - loss: 0.2266 - accuracy: 0.9060\n",
      "Epoch 29/50\n",
      "99/99 [==============================] - 0s 893us/step - loss: 0.2259 - accuracy: 0.9070\n",
      "Epoch 30/50\n",
      "99/99 [==============================] - 0s 828us/step - loss: 0.2255 - accuracy: 0.9071\n",
      "Epoch 31/50\n",
      "99/99 [==============================] - 0s 864us/step - loss: 0.2247 - accuracy: 0.9083\n",
      "Epoch 32/50\n",
      "99/99 [==============================] - 0s 840us/step - loss: 0.2244 - accuracy: 0.9073\n",
      "Epoch 33/50\n",
      "99/99 [==============================] - 0s 836us/step - loss: 0.2233 - accuracy: 0.9083\n",
      "Epoch 34/50\n",
      "99/99 [==============================] - 0s 847us/step - loss: 0.2228 - accuracy: 0.9079\n",
      "Epoch 35/50\n",
      "99/99 [==============================] - 0s 906us/step - loss: 0.2222 - accuracy: 0.9084\n",
      "Epoch 36/50\n",
      "99/99 [==============================] - 0s 818us/step - loss: 0.2215 - accuracy: 0.9090\n",
      "Epoch 37/50\n",
      "99/99 [==============================] - 0s 898us/step - loss: 0.2210 - accuracy: 0.9096\n",
      "Epoch 38/50\n",
      "99/99 [==============================] - 0s 906us/step - loss: 0.2203 - accuracy: 0.9088\n",
      "Epoch 39/50\n",
      "99/99 [==============================] - 0s 751us/step - loss: 0.2193 - accuracy: 0.9099\n",
      "Epoch 40/50\n",
      "99/99 [==============================] - 0s 770us/step - loss: 0.2193 - accuracy: 0.9100\n",
      "Epoch 41/50\n",
      "99/99 [==============================] - 0s 838us/step - loss: 0.2184 - accuracy: 0.9100\n",
      "Epoch 42/50\n",
      "99/99 [==============================] - 0s 960us/step - loss: 0.2183 - accuracy: 0.9115\n",
      "Epoch 43/50\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.2174 - accuracy: 0.9106\n",
      "Epoch 44/50\n",
      "99/99 [==============================] - 0s 965us/step - loss: 0.2170 - accuracy: 0.9105\n",
      "Epoch 45/50\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.2166 - accuracy: 0.9121\n",
      "Epoch 46/50\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.2162 - accuracy: 0.9113\n",
      "Epoch 47/50\n",
      "99/99 [==============================] - 0s 897us/step - loss: 0.2160 - accuracy: 0.9110\n",
      "Epoch 48/50\n",
      "99/99 [==============================] - 0s 898us/step - loss: 0.2151 - accuracy: 0.9117\n",
      "Epoch 49/50\n",
      "99/99 [==============================] - 0s 898us/step - loss: 0.2152 - accuracy: 0.9121\n",
      "Epoch 50/50\n",
      "99/99 [==============================] - 0s 827us/step - loss: 0.2146 - accuracy: 0.9128\n",
      "Epoch 1/50\n",
      "99/99 [==============================] - 0s 819us/step - loss: 0.5042 - accuracy: 0.7611\n",
      "Epoch 2/50\n",
      "99/99 [==============================] - 0s 818us/step - loss: 0.3615 - accuracy: 0.8351\n",
      "Epoch 3/50\n",
      "99/99 [==============================] - 0s 818us/step - loss: 0.3202 - accuracy: 0.8558\n",
      "Epoch 4/50\n",
      "99/99 [==============================] - 0s 816us/step - loss: 0.2989 - accuracy: 0.8679\n",
      "Epoch 5/50\n",
      "99/99 [==============================] - 0s 851us/step - loss: 0.2865 - accuracy: 0.8741\n",
      "Epoch 6/50\n",
      "99/99 [==============================] - 0s 918us/step - loss: 0.2773 - accuracy: 0.8792\n",
      "Epoch 7/50\n",
      "99/99 [==============================] - 0s 716us/step - loss: 0.2693 - accuracy: 0.8840\n",
      "Epoch 8/50\n",
      "99/99 [==============================] - 0s 818us/step - loss: 0.2632 - accuracy: 0.8867\n",
      "Epoch 9/50\n",
      "99/99 [==============================] - 0s 815us/step - loss: 0.2580 - accuracy: 0.8892\n",
      "Epoch 10/50\n",
      "99/99 [==============================] - 0s 919us/step - loss: 0.2536 - accuracy: 0.8919\n",
      "Epoch 11/50\n",
      "99/99 [==============================] - 0s 915us/step - loss: 0.2506 - accuracy: 0.8956\n",
      "Epoch 12/50\n",
      "99/99 [==============================] - 0s 817us/step - loss: 0.2472 - accuracy: 0.8957\n",
      "Epoch 13/50\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.2444 - accuracy: 0.8982\n",
      "Epoch 14/50\n",
      "99/99 [==============================] - 0s 918us/step - loss: 0.2418 - accuracy: 0.9002\n",
      "Epoch 15/50\n",
      "99/99 [==============================] - 0s 919us/step - loss: 0.2404 - accuracy: 0.9013\n",
      "Epoch 16/50\n",
      "99/99 [==============================] - 0s 813us/step - loss: 0.2383 - accuracy: 0.9029\n",
      "Epoch 17/50\n",
      "99/99 [==============================] - 0s 818us/step - loss: 0.2364 - accuracy: 0.9035\n",
      "Epoch 18/50\n",
      "99/99 [==============================] - 0s 818us/step - loss: 0.2354 - accuracy: 0.9044\n",
      "Epoch 19/50\n",
      "99/99 [==============================] - 0s 812us/step - loss: 0.2341 - accuracy: 0.9041\n",
      "Epoch 20/50\n",
      "99/99 [==============================] - 0s 922us/step - loss: 0.2327 - accuracy: 0.9050\n",
      "Epoch 21/50\n",
      "99/99 [==============================] - 0s 918us/step - loss: 0.2319 - accuracy: 0.9049\n",
      "Epoch 22/50\n",
      "99/99 [==============================] - 0s 850us/step - loss: 0.2308 - accuracy: 0.9052\n",
      "Epoch 23/50\n",
      "99/99 [==============================] - 0s 920us/step - loss: 0.2298 - accuracy: 0.9051\n",
      "Epoch 24/50\n",
      "99/99 [==============================] - 0s 817us/step - loss: 0.2289 - accuracy: 0.9066\n",
      "Epoch 25/50\n",
      "99/99 [==============================] - 0s 919us/step - loss: 0.2284 - accuracy: 0.9062\n",
      "Epoch 26/50\n",
      "99/99 [==============================] - 0s 918us/step - loss: 0.2282 - accuracy: 0.9061\n",
      "Epoch 27/50\n",
      "99/99 [==============================] - 0s 816us/step - loss: 0.2273 - accuracy: 0.9067\n",
      "Epoch 28/50\n",
      "99/99 [==============================] - 0s 817us/step - loss: 0.2261 - accuracy: 0.9079\n",
      "Epoch 29/50\n",
      "99/99 [==============================] - 0s 815us/step - loss: 0.2255 - accuracy: 0.9078\n",
      "Epoch 30/50\n",
      "99/99 [==============================] - 0s 816us/step - loss: 0.2249 - accuracy: 0.9083\n",
      "Epoch 31/50\n",
      "99/99 [==============================] - 0s 920us/step - loss: 0.2242 - accuracy: 0.9085\n",
      "Epoch 32/50\n",
      "99/99 [==============================] - 0s 916us/step - loss: 0.2237 - accuracy: 0.9083\n",
      "Epoch 33/50\n",
      "99/99 [==============================] - 0s 920us/step - loss: 0.2234 - accuracy: 0.9079\n",
      "Epoch 34/50\n",
      "99/99 [==============================] - 0s 916us/step - loss: 0.2229 - accuracy: 0.9092\n",
      "Epoch 35/50\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.2219 - accuracy: 0.9096\n",
      "Epoch 36/50\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.2216 - accuracy: 0.9104\n",
      "Epoch 37/50\n",
      "99/99 [==============================] - 0s 813us/step - loss: 0.2214 - accuracy: 0.9099\n",
      "Epoch 38/50\n",
      "99/99 [==============================] - 0s 820us/step - loss: 0.2210 - accuracy: 0.9107\n",
      "Epoch 39/50\n",
      "99/99 [==============================] - 0s 919us/step - loss: 0.2206 - accuracy: 0.9096\n",
      "Epoch 40/50\n",
      "99/99 [==============================] - 0s 917us/step - loss: 0.2201 - accuracy: 0.9107\n",
      "Epoch 41/50\n",
      "99/99 [==============================] - 0s 918us/step - loss: 0.2201 - accuracy: 0.9098\n",
      "Epoch 42/50\n",
      "99/99 [==============================] - 0s 920us/step - loss: 0.2196 - accuracy: 0.9099\n",
      "Epoch 43/50\n",
      "99/99 [==============================] - 0s 917us/step - loss: 0.2193 - accuracy: 0.9110\n",
      "Epoch 44/50\n",
      "99/99 [==============================] - 0s 815us/step - loss: 0.2188 - accuracy: 0.9112\n",
      "Epoch 45/50\n",
      "99/99 [==============================] - 0s 818us/step - loss: 0.2184 - accuracy: 0.9103\n",
      "Epoch 46/50\n",
      "99/99 [==============================] - 0s 813us/step - loss: 0.2185 - accuracy: 0.9113\n",
      "Epoch 47/50\n",
      "99/99 [==============================] - 0s 820us/step - loss: 0.2180 - accuracy: 0.9110\n",
      "Epoch 48/50\n",
      "99/99 [==============================] - 0s 816us/step - loss: 0.2178 - accuracy: 0.9118\n",
      "Epoch 49/50\n",
      "99/99 [==============================] - 0s 919us/step - loss: 0.2173 - accuracy: 0.9115\n",
      "Epoch 50/50\n",
      "99/99 [==============================] - 0s 918us/step - loss: 0.2171 - accuracy: 0.9117\n",
      "Epoch 1/50\n",
      "99/99 [==============================] - 0s 815us/step - loss: 0.6664 - accuracy: 0.6224\n",
      "Epoch 2/50\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.4225 - accuracy: 0.8152\n",
      "Epoch 3/50\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.3539 - accuracy: 0.8461\n",
      "Epoch 4/50\n",
      "99/99 [==============================] - 0s 916us/step - loss: 0.3217 - accuracy: 0.8594\n",
      "Epoch 5/50\n",
      "99/99 [==============================] - 0s 797us/step - loss: 0.3028 - accuracy: 0.8676\n",
      "Epoch 6/50\n",
      "99/99 [==============================] - 0s 837us/step - loss: 0.2883 - accuracy: 0.8733\n",
      "Epoch 7/50\n",
      "99/99 [==============================] - 0s 817us/step - loss: 0.2764 - accuracy: 0.8817\n",
      "Epoch 8/50\n",
      "99/99 [==============================] - 0s 816us/step - loss: 0.2672 - accuracy: 0.8836\n",
      "Epoch 9/50\n",
      "99/99 [==============================] - 0s 817us/step - loss: 0.2596 - accuracy: 0.8883\n",
      "Epoch 10/50\n",
      "99/99 [==============================] - 0s 815us/step - loss: 0.2542 - accuracy: 0.8913\n",
      "Epoch 11/50\n",
      "99/99 [==============================] - 0s 920us/step - loss: 0.2499 - accuracy: 0.8932\n",
      "Epoch 12/50\n",
      "99/99 [==============================] - 0s 918us/step - loss: 0.2470 - accuracy: 0.8951\n",
      "Epoch 13/50\n",
      "99/99 [==============================] - 0s 815us/step - loss: 0.2446 - accuracy: 0.8962\n",
      "Epoch 14/50\n",
      "99/99 [==============================] - 0s 919us/step - loss: 0.2422 - accuracy: 0.8971\n",
      "Epoch 15/50\n",
      "99/99 [==============================] - 0s 918us/step - loss: 0.2408 - accuracy: 0.8967\n",
      "Epoch 16/50\n",
      "99/99 [==============================] - 0s 816us/step - loss: 0.2396 - accuracy: 0.8983\n",
      "Epoch 17/50\n",
      "99/99 [==============================] - 0s 816us/step - loss: 0.2385 - accuracy: 0.8980\n",
      "Epoch 18/50\n",
      "99/99 [==============================] - 0s 712us/step - loss: 0.2379 - accuracy: 0.8978\n",
      "Epoch 19/50\n",
      "99/99 [==============================] - 0s 714us/step - loss: 0.2366 - accuracy: 0.9017\n",
      "Epoch 20/50\n",
      "99/99 [==============================] - 0s 806us/step - loss: 0.2361 - accuracy: 0.8999\n",
      "Epoch 21/50\n",
      "99/99 [==============================] - 0s 814us/step - loss: 0.2352 - accuracy: 0.9028\n",
      "Epoch 22/50\n",
      "99/99 [==============================] - 0s 819us/step - loss: 0.2342 - accuracy: 0.9021\n",
      "Epoch 23/50\n",
      "99/99 [==============================] - 0s 918us/step - loss: 0.2332 - accuracy: 0.9029\n",
      "Epoch 24/50\n",
      "99/99 [==============================] - 0s 817us/step - loss: 0.2328 - accuracy: 0.9033\n",
      "Epoch 25/50\n",
      "99/99 [==============================] - 0s 917us/step - loss: 0.2323 - accuracy: 0.9030\n",
      "Epoch 26/50\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.2313 - accuracy: 0.9045\n",
      "Epoch 27/50\n",
      "99/99 [==============================] - 0s 918us/step - loss: 0.2312 - accuracy: 0.9030\n",
      "Epoch 28/50\n",
      "99/99 [==============================] - 0s 815us/step - loss: 0.2300 - accuracy: 0.9034\n",
      "Epoch 29/50\n",
      "99/99 [==============================] - 0s 818us/step - loss: 0.2296 - accuracy: 0.9048\n",
      "Epoch 30/50\n",
      "99/99 [==============================] - 0s 812us/step - loss: 0.2287 - accuracy: 0.9045\n",
      "Epoch 31/50\n",
      "99/99 [==============================] - 0s 820us/step - loss: 0.2282 - accuracy: 0.9044\n",
      "Epoch 32/50\n",
      "99/99 [==============================] - 0s 815us/step - loss: 0.2277 - accuracy: 0.9054\n",
      "Epoch 33/50\n",
      "99/99 [==============================] - 0s 814us/step - loss: 0.2271 - accuracy: 0.9058\n",
      "Epoch 34/50\n",
      "99/99 [==============================] - 0s 814us/step - loss: 0.2266 - accuracy: 0.9058\n",
      "Epoch 35/50\n",
      "99/99 [==============================] - 0s 890us/step - loss: 0.2263 - accuracy: 0.9060\n",
      "Epoch 36/50\n",
      "99/99 [==============================] - 0s 854us/step - loss: 0.2259 - accuracy: 0.9057\n",
      "Epoch 37/50\n",
      "99/99 [==============================] - 0s 777us/step - loss: 0.2252 - accuracy: 0.9060\n",
      "Epoch 38/50\n",
      "99/99 [==============================] - 0s 919us/step - loss: 0.2246 - accuracy: 0.9071\n",
      "Epoch 39/50\n",
      "99/99 [==============================] - 0s 816us/step - loss: 0.2243 - accuracy: 0.9071\n",
      "Epoch 40/50\n",
      "99/99 [==============================] - 0s 815us/step - loss: 0.2237 - accuracy: 0.9067\n",
      "Epoch 41/50\n",
      "99/99 [==============================] - 0s 746us/step - loss: 0.2232 - accuracy: 0.9075\n",
      "Epoch 42/50\n",
      "99/99 [==============================] - 0s 782us/step - loss: 0.2228 - accuracy: 0.9083\n",
      "Epoch 43/50\n",
      "99/99 [==============================] - 0s 817us/step - loss: 0.2220 - accuracy: 0.9090\n",
      "Epoch 44/50\n",
      "99/99 [==============================] - 0s 815us/step - loss: 0.2221 - accuracy: 0.9075\n",
      "Epoch 45/50\n",
      "99/99 [==============================] - 0s 920us/step - loss: 0.2216 - accuracy: 0.9085\n",
      "Epoch 46/50\n",
      "99/99 [==============================] - 0s 817us/step - loss: 0.2211 - accuracy: 0.9089\n",
      "Epoch 47/50\n",
      "99/99 [==============================] - 0s 853us/step - loss: 0.2205 - accuracy: 0.9096\n",
      "Epoch 48/50\n",
      "99/99 [==============================] - 0s 883us/step - loss: 0.2203 - accuracy: 0.9094\n",
      "Epoch 49/50\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.2196 - accuracy: 0.9091\n",
      "Epoch 50/50\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.2191 - accuracy: 0.9096\n",
      "Epoch 1/50\n",
      "99/99 [==============================] - 0s 918us/step - loss: 0.5330 - accuracy: 0.7482\n",
      "Epoch 2/50\n",
      "99/99 [==============================] - 0s 818us/step - loss: 0.3705 - accuracy: 0.8390\n",
      "Epoch 3/50\n",
      "99/99 [==============================] - 0s 918us/step - loss: 0.3298 - accuracy: 0.8563\n",
      "Epoch 4/50\n",
      "99/99 [==============================] - 0s 815us/step - loss: 0.3076 - accuracy: 0.8660\n",
      "Epoch 5/50\n",
      "99/99 [==============================] - 0s 920us/step - loss: 0.2919 - accuracy: 0.8725\n",
      "Epoch 6/50\n",
      "99/99 [==============================] - 0s 815us/step - loss: 0.2812 - accuracy: 0.8766\n",
      "Epoch 7/50\n",
      "99/99 [==============================] - 0s 818us/step - loss: 0.2726 - accuracy: 0.8833\n",
      "Epoch 8/50\n",
      "99/99 [==============================] - 0s 713us/step - loss: 0.2657 - accuracy: 0.8847\n",
      "Epoch 9/50\n",
      "99/99 [==============================] - 0s 815us/step - loss: 0.2601 - accuracy: 0.8893\n",
      "Epoch 10/50\n",
      "99/99 [==============================] - 0s 819us/step - loss: 0.2561 - accuracy: 0.8906\n",
      "Epoch 11/50\n",
      "99/99 [==============================] - 0s 816us/step - loss: 0.2525 - accuracy: 0.8942\n",
      "Epoch 12/50\n",
      "99/99 [==============================] - 0s 715us/step - loss: 0.2492 - accuracy: 0.8936\n",
      "Epoch 13/50\n",
      "99/99 [==============================] - 0s 816us/step - loss: 0.2467 - accuracy: 0.8968\n",
      "Epoch 14/50\n",
      "99/99 [==============================] - 0s 819us/step - loss: 0.2444 - accuracy: 0.8975\n",
      "Epoch 15/50\n",
      "99/99 [==============================] - 0s 715us/step - loss: 0.2430 - accuracy: 0.8986\n",
      "Epoch 16/50\n",
      "99/99 [==============================] - 0s 819us/step - loss: 0.2410 - accuracy: 0.8990\n",
      "Epoch 17/50\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.2392 - accuracy: 0.9006\n",
      "Epoch 18/50\n",
      "99/99 [==============================] - 0s 969us/step - loss: 0.2378 - accuracy: 0.9017\n",
      "Epoch 19/50\n",
      "99/99 [==============================] - 0s 867us/step - loss: 0.2363 - accuracy: 0.9025\n",
      "Epoch 20/50\n",
      "99/99 [==============================] - 0s 818us/step - loss: 0.2354 - accuracy: 0.9017\n",
      "Epoch 21/50\n",
      "99/99 [==============================] - 0s 716us/step - loss: 0.2341 - accuracy: 0.9042\n",
      "Epoch 22/50\n",
      "99/99 [==============================] - 0s 714us/step - loss: 0.2333 - accuracy: 0.9051\n",
      "Epoch 23/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 0s 714us/step - loss: 0.2323 - accuracy: 0.9040\n",
      "Epoch 24/50\n",
      "99/99 [==============================] - 0s 714us/step - loss: 0.2311 - accuracy: 0.9042\n",
      "Epoch 25/50\n",
      "99/99 [==============================] - 0s 817us/step - loss: 0.2307 - accuracy: 0.9057\n",
      "Epoch 26/50\n",
      "99/99 [==============================] - 0s 813us/step - loss: 0.2294 - accuracy: 0.9060\n",
      "Epoch 27/50\n",
      "99/99 [==============================] - 0s 815us/step - loss: 0.2285 - accuracy: 0.9051\n",
      "Epoch 28/50\n",
      "99/99 [==============================] - 0s 816us/step - loss: 0.2276 - accuracy: 0.9067\n",
      "Epoch 29/50\n",
      "99/99 [==============================] - 0s 818us/step - loss: 0.2269 - accuracy: 0.9079\n",
      "Epoch 30/50\n",
      "99/99 [==============================] - 0s 816us/step - loss: 0.2262 - accuracy: 0.9064\n",
      "Epoch 31/50\n",
      "99/99 [==============================] - 0s 817us/step - loss: 0.2255 - accuracy: 0.9071\n",
      "Epoch 32/50\n",
      "99/99 [==============================] - 0s 714us/step - loss: 0.2250 - accuracy: 0.9063\n",
      "Epoch 33/50\n",
      "99/99 [==============================] - 0s 814us/step - loss: 0.2239 - accuracy: 0.9084\n",
      "Epoch 34/50\n",
      "99/99 [==============================] - 0s 771us/step - loss: 0.2232 - accuracy: 0.9083\n",
      "Epoch 35/50\n",
      "99/99 [==============================] - 0s 761us/step - loss: 0.2228 - accuracy: 0.9081\n",
      "Epoch 36/50\n",
      "99/99 [==============================] - 0s 816us/step - loss: 0.2217 - accuracy: 0.9096\n",
      "Epoch 37/50\n",
      "99/99 [==============================] - 0s 813us/step - loss: 0.2214 - accuracy: 0.9079\n",
      "Epoch 38/50\n",
      "99/99 [==============================] - 0s 819us/step - loss: 0.2209 - accuracy: 0.9088\n",
      "Epoch 39/50\n",
      "99/99 [==============================] - 0s 813us/step - loss: 0.2201 - accuracy: 0.9090\n",
      "Epoch 40/50\n",
      "99/99 [==============================] - 0s 820us/step - loss: 0.2199 - accuracy: 0.9106\n",
      "Epoch 41/50\n",
      "99/99 [==============================] - 0s 816us/step - loss: 0.2197 - accuracy: 0.9102\n",
      "Epoch 42/50\n",
      "99/99 [==============================] - 0s 816us/step - loss: 0.2187 - accuracy: 0.9090\n",
      "Epoch 43/50\n",
      "99/99 [==============================] - 0s 816us/step - loss: 0.2185 - accuracy: 0.9108\n",
      "Epoch 44/50\n",
      "99/99 [==============================] - 0s 909us/step - loss: 0.2178 - accuracy: 0.9111\n",
      "Epoch 45/50\n",
      "99/99 [==============================] - 0s 815us/step - loss: 0.2177 - accuracy: 0.9102\n",
      "Epoch 46/50\n",
      "99/99 [==============================] - 0s 816us/step - loss: 0.2173 - accuracy: 0.9117\n",
      "Epoch 47/50\n",
      "99/99 [==============================] - 0s 817us/step - loss: 0.2166 - accuracy: 0.9106\n",
      "Epoch 48/50\n",
      "99/99 [==============================] - 0s 819us/step - loss: 0.2163 - accuracy: 0.9121\n",
      "Epoch 49/50\n",
      "99/99 [==============================] - 0s 815us/step - loss: 0.2156 - accuracy: 0.9119\n",
      "Epoch 50/50\n",
      "99/99 [==============================] - 0s 817us/step - loss: 0.2158 - accuracy: 0.9129\n",
      "Epoch 1/50\n",
      "99/99 [==============================] - 0s 815us/step - loss: 0.5712 - accuracy: 0.7288\n",
      "Epoch 2/50\n",
      "99/99 [==============================] - 0s 919us/step - loss: 0.4086 - accuracy: 0.8135\n",
      "Epoch 3/50\n",
      "99/99 [==============================] - 0s 921us/step - loss: 0.3406 - accuracy: 0.8445\n",
      "Epoch 4/50\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.3092 - accuracy: 0.8623\n",
      "Epoch 5/50\n",
      "99/99 [==============================] - 0s 917us/step - loss: 0.2914 - accuracy: 0.8712\n",
      "Epoch 6/50\n",
      "99/99 [==============================] - 0s 918us/step - loss: 0.2778 - accuracy: 0.8802\n",
      "Epoch 7/50\n",
      "99/99 [==============================] - 0s 816us/step - loss: 0.2677 - accuracy: 0.8829\n",
      "Epoch 8/50\n",
      "99/99 [==============================] - 0s 866us/step - loss: 0.2604 - accuracy: 0.8875\n",
      "Epoch 9/50\n",
      "99/99 [==============================] - 0s 712us/step - loss: 0.2554 - accuracy: 0.8910\n",
      "Epoch 10/50\n",
      "99/99 [==============================] - 0s 819us/step - loss: 0.2510 - accuracy: 0.8925\n",
      "Epoch 11/50\n",
      "99/99 [==============================] - 0s 917us/step - loss: 0.2478 - accuracy: 0.8953\n",
      "Epoch 12/50\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.2454 - accuracy: 0.8972\n",
      "Epoch 13/50\n",
      "99/99 [==============================] - 0s 917us/step - loss: 0.2432 - accuracy: 0.8992\n",
      "Epoch 14/50\n",
      "99/99 [==============================] - 0s 918us/step - loss: 0.2415 - accuracy: 0.8987\n",
      "Epoch 15/50\n",
      "99/99 [==============================] - 0s 919us/step - loss: 0.2394 - accuracy: 0.8998\n",
      "Epoch 16/50\n",
      "99/99 [==============================] - 0s 817us/step - loss: 0.2380 - accuracy: 0.8999\n",
      "Epoch 17/50\n",
      "99/99 [==============================] - 0s 917us/step - loss: 0.2370 - accuracy: 0.9008\n",
      "Epoch 18/50\n",
      "99/99 [==============================] - 0s 715us/step - loss: 0.2357 - accuracy: 0.9002\n",
      "Epoch 19/50\n",
      "99/99 [==============================] - 0s 817us/step - loss: 0.2345 - accuracy: 0.9021\n",
      "Epoch 20/50\n",
      "99/99 [==============================] - 0s 816us/step - loss: 0.2336 - accuracy: 0.9021\n",
      "Epoch 21/50\n",
      "99/99 [==============================] - 0s 817us/step - loss: 0.2323 - accuracy: 0.9022\n",
      "Epoch 22/50\n",
      "99/99 [==============================] - 0s 814us/step - loss: 0.2318 - accuracy: 0.9020\n",
      "Epoch 23/50\n",
      "99/99 [==============================] - 0s 918us/step - loss: 0.2312 - accuracy: 0.9022\n",
      "Epoch 24/50\n",
      "99/99 [==============================] - 0s 819us/step - loss: 0.2305 - accuracy: 0.9038\n",
      "Epoch 25/50\n",
      "99/99 [==============================] - 0s 971us/step - loss: 0.2295 - accuracy: 0.9044\n",
      "Epoch 26/50\n",
      "99/99 [==============================] - 0s 865us/step - loss: 0.2292 - accuracy: 0.9033\n",
      "Epoch 27/50\n",
      "99/99 [==============================] - 0s 817us/step - loss: 0.2286 - accuracy: 0.9043\n",
      "Epoch 28/50\n",
      "99/99 [==============================] - 0s 817us/step - loss: 0.2281 - accuracy: 0.9045\n",
      "Epoch 29/50\n",
      "99/99 [==============================] - 0s 817us/step - loss: 0.2273 - accuracy: 0.9051\n",
      "Epoch 30/50\n",
      "99/99 [==============================] - 0s 816us/step - loss: 0.2269 - accuracy: 0.9067\n",
      "Epoch 31/50\n",
      "99/99 [==============================] - 0s 816us/step - loss: 0.2263 - accuracy: 0.9065\n",
      "Epoch 32/50\n",
      "99/99 [==============================] - 0s 813us/step - loss: 0.2254 - accuracy: 0.9060\n",
      "Epoch 33/50\n",
      "99/99 [==============================] - 0s 820us/step - loss: 0.2246 - accuracy: 0.9075\n",
      "Epoch 34/50\n",
      "99/99 [==============================] - 0s 918us/step - loss: 0.2245 - accuracy: 0.9062\n",
      "Epoch 35/50\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.2241 - accuracy: 0.9068\n",
      "Epoch 36/50\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.2234 - accuracy: 0.9077\n",
      "Epoch 37/50\n",
      "99/99 [==============================] - 0s 919us/step - loss: 0.2229 - accuracy: 0.9083\n",
      "Epoch 38/50\n",
      "99/99 [==============================] - 0s 815us/step - loss: 0.2223 - accuracy: 0.9076\n",
      "Epoch 39/50\n",
      "99/99 [==============================] - 0s 818us/step - loss: 0.2218 - accuracy: 0.9087\n",
      "Epoch 40/50\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.2178 - accuracy: 0.90 - 0s 713us/step - loss: 0.2211 - accuracy: 0.9084\n",
      "Epoch 41/50\n",
      "99/99 [==============================] - 0s 817us/step - loss: 0.2211 - accuracy: 0.9093\n",
      "Epoch 42/50\n",
      "99/99 [==============================] - 0s 817us/step - loss: 0.2209 - accuracy: 0.9085\n",
      "Epoch 43/50\n",
      "99/99 [==============================] - 0s 714us/step - loss: 0.2202 - accuracy: 0.9082\n",
      "Epoch 44/50\n",
      "99/99 [==============================] - 0s 815us/step - loss: 0.2199 - accuracy: 0.9090\n",
      "Epoch 45/50\n",
      "99/99 [==============================] - 0s 715us/step - loss: 0.2194 - accuracy: 0.9094\n",
      "Epoch 46/50\n",
      "99/99 [==============================] - 0s 817us/step - loss: 0.2192 - accuracy: 0.9094\n",
      "Epoch 47/50\n",
      "99/99 [==============================] - 0s 816us/step - loss: 0.2185 - accuracy: 0.9090\n",
      "Epoch 48/50\n",
      "99/99 [==============================] - 0s 817us/step - loss: 0.2180 - accuracy: 0.9102\n",
      "Epoch 49/50\n",
      "99/99 [==============================] - 0s 865us/step - loss: 0.2177 - accuracy: 0.9100\n",
      "Epoch 50/50\n",
      "99/99 [==============================] - 0s 820us/step - loss: 0.2173 - accuracy: 0.9098\n",
      "Epoch 1/50\n",
      "99/99 [==============================] - 1s 717us/step - loss: 0.5318 - accuracy: 0.7310\n",
      "Epoch 2/50\n",
      "99/99 [==============================] - 0s 919us/step - loss: 0.3900 - accuracy: 0.8187\n",
      "Epoch 3/50\n",
      "99/99 [==============================] - 0s 919us/step - loss: 0.3398 - accuracy: 0.8468\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 0s 865us/step - loss: 0.3131 - accuracy: 0.8643\n",
      "Epoch 5/50\n",
      "99/99 [==============================] - 0s 783us/step - loss: 0.2951 - accuracy: 0.8721\n",
      "Epoch 6/50\n",
      "99/99 [==============================] - 0s 919us/step - loss: 0.2809 - accuracy: 0.8775\n",
      "Epoch 7/50\n",
      "99/99 [==============================] - 0s 916us/step - loss: 0.2701 - accuracy: 0.8830\n",
      "Epoch 8/50\n",
      "99/99 [==============================] - 0s 820us/step - loss: 0.2626 - accuracy: 0.8871\n",
      "Epoch 9/50\n",
      "99/99 [==============================] - 0s 918us/step - loss: 0.2571 - accuracy: 0.8887\n",
      "Epoch 10/50\n",
      "99/99 [==============================] - 0s 915us/step - loss: 0.2531 - accuracy: 0.8920\n",
      "Epoch 11/50\n",
      "99/99 [==============================] - 0s 922us/step - loss: 0.2496 - accuracy: 0.8919\n",
      "Epoch 12/50\n",
      "99/99 [==============================] - 0s 916us/step - loss: 0.2466 - accuracy: 0.8953\n",
      "Epoch 13/50\n",
      "99/99 [==============================] - 0s 817us/step - loss: 0.2440 - accuracy: 0.8970\n",
      "Epoch 14/50\n",
      "99/99 [==============================] - 0s 815us/step - loss: 0.2423 - accuracy: 0.8977\n",
      "Epoch 15/50\n",
      "99/99 [==============================] - 0s 715us/step - loss: 0.2403 - accuracy: 0.8997\n",
      "Epoch 16/50\n",
      "99/99 [==============================] - 0s 816us/step - loss: 0.2387 - accuracy: 0.8999\n",
      "Epoch 17/50\n",
      "99/99 [==============================] - 0s 818us/step - loss: 0.2370 - accuracy: 0.8998\n",
      "Epoch 18/50\n",
      "99/99 [==============================] - 0s 818us/step - loss: 0.2358 - accuracy: 0.9009\n",
      "Epoch 19/50\n",
      "99/99 [==============================] - 0s 816us/step - loss: 0.2344 - accuracy: 0.9008\n",
      "Epoch 20/50\n",
      "99/99 [==============================] - 0s 919us/step - loss: 0.2334 - accuracy: 0.9024\n",
      "Epoch 21/50\n",
      "99/99 [==============================] - 0s 918us/step - loss: 0.2327 - accuracy: 0.9023\n",
      "Epoch 22/50\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.2308 - accuracy: 0.9051\n",
      "Epoch 23/50\n",
      "99/99 [==============================] - 0s 873us/step - loss: 0.2304 - accuracy: 0.9037\n",
      "Epoch 24/50\n",
      "99/99 [==============================] - 0s 813us/step - loss: 0.2296 - accuracy: 0.9037\n",
      "Epoch 25/50\n",
      "99/99 [==============================] - 0s 919us/step - loss: 0.2286 - accuracy: 0.9052\n",
      "Epoch 26/50\n",
      "99/99 [==============================] - 0s 916us/step - loss: 0.2281 - accuracy: 0.9056\n",
      "Epoch 27/50\n",
      "99/99 [==============================] - 0s 820us/step - loss: 0.2268 - accuracy: 0.9054\n",
      "Epoch 28/50\n",
      "99/99 [==============================] - 0s 818us/step - loss: 0.2263 - accuracy: 0.9047\n",
      "Epoch 29/50\n",
      "99/99 [==============================] - 0s 962us/step - loss: 0.2257 - accuracy: 0.9059\n",
      "Epoch 30/50\n",
      "99/99 [==============================] - 0s 873us/step - loss: 0.2247 - accuracy: 0.9064\n",
      "Epoch 31/50\n",
      "99/99 [==============================] - 0s 814us/step - loss: 0.2244 - accuracy: 0.9063\n",
      "Epoch 32/50\n",
      "99/99 [==============================] - 0s 920us/step - loss: 0.2237 - accuracy: 0.9079\n",
      "Epoch 33/50\n",
      "99/99 [==============================] - 0s 817us/step - loss: 0.2229 - accuracy: 0.9071\n",
      "Epoch 34/50\n",
      "99/99 [==============================] - 0s 816us/step - loss: 0.2228 - accuracy: 0.9068\n",
      "Epoch 35/50\n",
      "99/99 [==============================] - 0s 915us/step - loss: 0.2222 - accuracy: 0.9087\n",
      "Epoch 36/50\n",
      "99/99 [==============================] - 0s 818us/step - loss: 0.2218 - accuracy: 0.9073\n",
      "Epoch 37/50\n",
      "99/99 [==============================] - 0s 920us/step - loss: 0.2209 - accuracy: 0.9080\n",
      "Epoch 38/50\n",
      "99/99 [==============================] - 0s 815us/step - loss: 0.2203 - accuracy: 0.9084\n",
      "Epoch 39/50\n",
      "99/99 [==============================] - 0s 920us/step - loss: 0.2199 - accuracy: 0.9097\n",
      "Epoch 40/50\n",
      "99/99 [==============================] - 0s 918us/step - loss: 0.2195 - accuracy: 0.9101\n",
      "Epoch 41/50\n",
      "99/99 [==============================] - 0s 921us/step - loss: 0.2188 - accuracy: 0.9088\n",
      "Epoch 42/50\n",
      "99/99 [==============================] - 0s 917us/step - loss: 0.2190 - accuracy: 0.9104\n",
      "Epoch 43/50\n",
      "99/99 [==============================] - 0s 915us/step - loss: 0.2183 - accuracy: 0.9094\n",
      "Epoch 44/50\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.2179 - accuracy: 0.9098\n",
      "Epoch 45/50\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.2173 - accuracy: 0.9092\n",
      "Epoch 46/50\n",
      "99/99 [==============================] - 0s 918us/step - loss: 0.2167 - accuracy: 0.9098\n",
      "Epoch 47/50\n",
      "99/99 [==============================] - 0s 816us/step - loss: 0.2164 - accuracy: 0.9110\n",
      "Epoch 48/50\n",
      "99/99 [==============================] - 0s 923us/step - loss: 0.2162 - accuracy: 0.9101\n",
      "Epoch 49/50\n",
      "99/99 [==============================] - 0s 968us/step - loss: 0.2155 - accuracy: 0.9123\n",
      "Epoch 50/50\n",
      "99/99 [==============================] - 0s 918us/step - loss: 0.2148 - accuracy: 0.9107\n",
      "Epoch 1/50\n",
      "99/99 [==============================] - 0s 865us/step - loss: 0.5206 - accuracy: 0.7557\n",
      "Epoch 2/50\n",
      "99/99 [==============================] - 0s 819us/step - loss: 0.3715 - accuracy: 0.8337\n",
      "Epoch 3/50\n",
      "99/99 [==============================] - 0s 814us/step - loss: 0.3234 - accuracy: 0.8564\n",
      "Epoch 4/50\n",
      "99/99 [==============================] - 0s 818us/step - loss: 0.3007 - accuracy: 0.8690\n",
      "Epoch 5/50\n",
      "99/99 [==============================] - 0s 908us/step - loss: 0.2866 - accuracy: 0.8744\n",
      "Epoch 6/50\n",
      "99/99 [==============================] - 0s 827us/step - loss: 0.2762 - accuracy: 0.8803\n",
      "Epoch 7/50\n",
      "99/99 [==============================] - 0s 918us/step - loss: 0.2688 - accuracy: 0.8843\n",
      "Epoch 8/50\n",
      "99/99 [==============================] - 0s 919us/step - loss: 0.2632 - accuracy: 0.8867\n",
      "Epoch 9/50\n",
      "99/99 [==============================] - 0s 816us/step - loss: 0.2590 - accuracy: 0.8877\n",
      "Epoch 10/50\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.2584 - accuracy: 0.88 - 0s 867us/step - loss: 0.2553 - accuracy: 0.8901\n",
      "Epoch 11/50\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.2517 - accuracy: 0.8936\n",
      "Epoch 12/50\n",
      "99/99 [==============================] - 0s 919us/step - loss: 0.2491 - accuracy: 0.8929\n",
      "Epoch 13/50\n",
      "99/99 [==============================] - 0s 917us/step - loss: 0.2461 - accuracy: 0.8940\n",
      "Epoch 14/50\n",
      "99/99 [==============================] - 0s 817us/step - loss: 0.2443 - accuracy: 0.8948\n",
      "Epoch 15/50\n",
      "99/99 [==============================] - 0s 814us/step - loss: 0.2421 - accuracy: 0.8969\n",
      "Epoch 16/50\n",
      "99/99 [==============================] - 0s 816us/step - loss: 0.2403 - accuracy: 0.8974\n",
      "Epoch 17/50\n",
      "99/99 [==============================] - 0s 920us/step - loss: 0.2387 - accuracy: 0.8977\n",
      "Epoch 18/50\n",
      "99/99 [==============================] - 0s 915us/step - loss: 0.2376 - accuracy: 0.8993\n",
      "Epoch 19/50\n",
      "99/99 [==============================] - 0s 920us/step - loss: 0.2364 - accuracy: 0.8984\n",
      "Epoch 20/50\n",
      "99/99 [==============================] - 0s 813us/step - loss: 0.2352 - accuracy: 0.8994\n",
      "Epoch 21/50\n",
      "99/99 [==============================] - 0s 922us/step - loss: 0.2342 - accuracy: 0.9002\n",
      "Epoch 22/50\n",
      "99/99 [==============================] - 0s 919us/step - loss: 0.2340 - accuracy: 0.9004\n",
      "Epoch 23/50\n",
      "99/99 [==============================] - 0s 917us/step - loss: 0.2323 - accuracy: 0.9016\n",
      "Epoch 24/50\n",
      "99/99 [==============================] - 0s 817us/step - loss: 0.2317 - accuracy: 0.9013\n",
      "Epoch 25/50\n",
      "99/99 [==============================] - 0s 817us/step - loss: 0.2310 - accuracy: 0.9021\n",
      "Epoch 26/50\n",
      "99/99 [==============================] - 0s 815us/step - loss: 0.2303 - accuracy: 0.9021\n",
      "Epoch 27/50\n",
      "99/99 [==============================] - 0s 918us/step - loss: 0.2296 - accuracy: 0.9028\n",
      "Epoch 28/50\n",
      "99/99 [==============================] - 0s 818us/step - loss: 0.2291 - accuracy: 0.9037\n",
      "Epoch 29/50\n",
      "99/99 [==============================] - 0s 817us/step - loss: 0.2285 - accuracy: 0.9044\n",
      "Epoch 30/50\n",
      "99/99 [==============================] - 0s 915us/step - loss: 0.2275 - accuracy: 0.9041\n",
      "Epoch 31/50\n",
      "99/99 [==============================] - 0s 818us/step - loss: 0.2272 - accuracy: 0.9043\n",
      "Epoch 32/50\n",
      "99/99 [==============================] - 0s 814us/step - loss: 0.2263 - accuracy: 0.9048\n",
      "Epoch 33/50\n",
      "99/99 [==============================] - 0s 920us/step - loss: 0.2260 - accuracy: 0.9056\n",
      "Epoch 34/50\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.2254 - accuracy: 0.9056\n",
      "Epoch 35/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 0s 815us/step - loss: 0.2244 - accuracy: 0.9056\n",
      "Epoch 36/50\n",
      "99/99 [==============================] - 0s 817us/step - loss: 0.2237 - accuracy: 0.9061\n",
      "Epoch 37/50\n",
      "99/99 [==============================] - 0s 816us/step - loss: 0.2233 - accuracy: 0.9065\n",
      "Epoch 38/50\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.2230 - accuracy: 0.9075\n",
      "Epoch 39/50\n",
      "99/99 [==============================] - 0s 815us/step - loss: 0.2228 - accuracy: 0.9064\n",
      "Epoch 40/50\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.2221 - accuracy: 0.9071\n",
      "Epoch 41/50\n",
      "99/99 [==============================] - 0s 815us/step - loss: 0.2218 - accuracy: 0.9083\n",
      "Epoch 42/50\n",
      "99/99 [==============================] - 0s 915us/step - loss: 0.2208 - accuracy: 0.9088\n",
      "Epoch 43/50\n",
      "99/99 [==============================] - 0s 919us/step - loss: 0.2206 - accuracy: 0.9085\n",
      "Epoch 44/50\n",
      "99/99 [==============================] - 0s 818us/step - loss: 0.2203 - accuracy: 0.9081\n",
      "Epoch 45/50\n",
      "99/99 [==============================] - 0s 918us/step - loss: 0.2197 - accuracy: 0.9094\n",
      "Epoch 46/50\n",
      "99/99 [==============================] - 0s 919us/step - loss: 0.2189 - accuracy: 0.9094\n",
      "Epoch 47/50\n",
      "99/99 [==============================] - 0s 918us/step - loss: 0.2190 - accuracy: 0.9101\n",
      "Epoch 48/50\n",
      "99/99 [==============================] - 0s 919us/step - loss: 0.2190 - accuracy: 0.9099\n",
      "Epoch 49/50\n",
      "99/99 [==============================] - 0s 866us/step - loss: 0.2182 - accuracy: 0.9101\n",
      "Epoch 50/50\n",
      "99/99 [==============================] - 0s 919us/step - loss: 0.2182 - accuracy: 0.9090\n",
      "Feature Engineered: 81.68% (1.32%)\n"
     ]
    }
   ],
   "source": [
    "estimator = KerasClassifier(build_fn=create_feature_model, epochs= 50, batch_size= 128, verbose= 1)\n",
    "kfold = StratifiedKFold(n_splits= 10, shuffle=True)\n",
    "results = cross_val_score(estimator, X_mean_imputed, encoded_Y, cv=kfold, \n",
    "                          scoring = make_scorer(f1_score, pos_label = 1, labels=[1, 0]))\n",
    "print(\"Feature Engineered: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1794d6c",
   "metadata": {},
   "source": [
    "## Let's Try Imputing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb108350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing: 10695\n",
      "Missing: 0\n"
     ]
    }
   ],
   "source": [
    "# Maybe we should try a better imputing? Let's see what happens with imputing. \n",
    "from numpy import isnan\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Convert to numpy array\n",
    "features = np.array(X)\n",
    "\n",
    "# print total missing\n",
    "print('Missing: %d' % sum(isnan(features).flatten()))\n",
    "# define imputer\n",
    "imputer = KNNImputer(missing_values=np.nan)\n",
    "# fit on the dataset\n",
    "imputer.fit(features)\n",
    "# transform the dataset\n",
    "features_trans = imputer.transform(features)\n",
    "# print total missing\n",
    "print('Missing: %d' % sum(isnan(features_trans).flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c1f2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_imputed_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, input_dim = 44, activation='relu')) # 2 Layers Right Now\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "        model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e604022f",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = KerasClassifier(build_fn=create_feature_model, epochs= 50, batch_size= 128, verbose= 1)\n",
    "kfold = StratifiedKFold(n_splits= 10, shuffle=True)\n",
    "results = cross_val_score(estimator, features_trans, encoded_Y, cv=kfold, \n",
    "                          scoring = make_scorer(f1_score, pos_label = 1, labels=[1, 0]))\n",
    "print(\"Feature Engineered: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
